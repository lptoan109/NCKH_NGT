{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12870874,"sourceType":"datasetVersion","datasetId":8141736}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":10270.969784,"end_time":"2025-10-14T18:01:03.434542","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-14T15:09:52.464758","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"f7bf3f54","cell_type":"code","source":"# 0.1. Cài đặt các thư viện cần thiết\n!pip install -q fpdf2 noisereduce librosa tensorflow scikit-learn matplotlib seaborn pytz PyDrive2 imbalanced-learn ","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-10-14T15:09:57.552454Z","iopub.status.busy":"2025-10-14T15:09:57.552257Z","iopub.status.idle":"2025-10-14T15:10:10.070936Z","shell.execute_reply":"2025-10-14T15:10:10.069963Z"},"papermill":{"duration":12.524878,"end_time":"2025-10-14T15:10:10.072424","exception":false,"start_time":"2025-10-14T15:09:57.547546","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.7/72.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n","category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\r\n","cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n","\u001b[0m"]}],"execution_count":1},{"id":"ce817a70","cell_type":"code","source":"# CÀI ĐẶT & CẤU HÌNH \n# 0.2. Import thư viện\n\n# --- Thư viện chuẩn của Python ---\nimport os\nimport glob \nimport random\nimport datetime\nimport pytz\nimport shutil\nfrom itertools import cycle\nfrom tqdm import tqdm\nimport gc\n\n# --- Thư viện xử lý dữ liệu và tính toán ---\nimport numpy as np\nimport pandas as pd\nfrom imblearn.over_sampling import SMOTE\n\n# --- Thư viện trực quan hóa ---\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# --- Thư viện xử lý âm thanh ---\nimport librosa\nimport noisereduce as nr\n\n# --- Thư viện Machine Learning (Scikit-learn) ---\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc as sklearn_auc\nfrom sklearn.utils import class_weight\n\n# --- TensorFlow & Keras ---\nimport tensorflow as tf\nfrom tensorflow.keras import mixed_precision\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.applications import EfficientNetV2B2\nfrom tensorflow.keras.applications.efficientnet_v2 import preprocess_input\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.utils import register_keras_serializable\n\n# Import tất cả các lớp (Layers) cần thiết cho cả CNN và CRNN\nfrom tensorflow.keras.layers import (\n    Input, \n    Dense, \n    Dropout, \n    GlobalAveragePooling2D, \n    GlobalMaxPooling2D,  \n    Concatenate,          \n    BatchNormalization, \n    Activation,\n    Reshape,              # Thêm cho CRNN\n    LSTM,                 # Thêm cho CRNN\n    Bidirectional         # Thêm cho CRNN\n)\n\n# --- Thư viện khác ---\nfrom fpdf import FPDF \n\nprint(f\"TensorFlow Version: {tf.__version__}\")\nprint(\"Tất cả các thư viện đã được import thành công.\")\n\n\ntry:\n    # --- 1. ƯU TIÊN KẾT NỐI VỚI TPU ---\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    strategy = tf.distribute.TPUStrategy(tpu)\n    policy = 'mixed_bfloat16'\n    mixed_precision.set_global_policy(policy)\n    print(\" KẾT NỐI TPU THÀNH CÔNG!\")\n    print(f\"   - Số lượng nhân (replicas): {strategy.num_replicas_in_sync}\")\n    print(f\"   - Kiểu dữ liệu (DType Policy): {policy}\")\n\nexcept Exception:\n    print(\" Không tìm thấy TPU. Đang kiểm tra GPU...\")\n    \n    # --- 2. SỬA LỖI: CHỈ SỬ DỤNG 1 GPU ĐỂ GỠ LỖI ---\n    gpus = tf.config.list_physical_devices('GPU')\n    if gpus:\n        try:\n            print(f\"Tìm thấy {len(gpus)} GPU. Sẽ chỉ sử dụng GPU:0 để gỡ lỗi.\")\n            # Chỉ cho phép TensorFlow nhìn thấy GPU đầu tiên\n            tf.config.set_visible_devices(gpus[0], 'GPU')\n            \n            # Sử dụng chiến lược mặc định, nó sẽ tự động chọn GPU duy nhất có sẵn\n            strategy = tf.distribute.get_strategy()\n            \n            policy = 'mixed_float16'\n            mixed_precision.set_global_policy(policy)\n            \n            print(\" KẾT NỐI 1-GPU THÀNH CÔNG!\")\n            print(f\"   - Số lượng nhân (replicas): {strategy.num_replicas_in_sync}\")\n            print(f\"   - Kiểu dữ liệu (DType Policy): {policy}\")\n\n        except RuntimeError as e:\n            # Lỗi này có thể xảy ra nếu visible devices đã được set trước đó\n            print(e)\n            print(\"Không thể thay đổi thiết bị GPU. Sử dụng chiến lược mặc định.\")\n            strategy = tf.distribute.get_strategy()\n\n    else:\n        # --- 3. NẾU KHÔNG CÓ GPU, SỬ DỤNG CPU ---\n        print(\" Không tìm thấy GPU. Sử dụng CPU.\")\n        strategy = tf.distribute.get_strategy()\n        print(\" Sử dụng chiến lược mặc định cho CPU.\")\n        print(f\"   - Số lượng nhân (replicas): {strategy.num_replicas_in_sync}\")\n","metadata":{"execution":{"iopub.execute_input":"2025-10-14T15:10:10.082209Z","iopub.status.busy":"2025-10-14T15:10:10.081951Z","iopub.status.idle":"2025-10-14T15:10:41.917214Z","shell.execute_reply":"2025-10-14T15:10:41.916356Z"},"papermill":{"duration":31.846101,"end_time":"2025-10-14T15:10:41.922430","exception":false,"start_time":"2025-10-14T15:10:10.076329","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-10-14 15:10:25.402267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1760454625.789462      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1760454625.913868      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"name":"stdout","output_type":"stream","text":["TensorFlow Version: 2.18.0\n","Tất cả các thư viện đã được import thành công.\n"," Không tìm thấy TPU. Đang kiểm tra GPU...\n","Tìm thấy 2 GPU. Sẽ chỉ sử dụng GPU:0 để gỡ lỗi.\n"," KẾT NỐI 1-GPU THÀNH CÔNG!\n","   - Số lượng nhân (replicas): 1\n","   - Kiểu dữ liệu (DType Policy): mixed_float16\n"]}],"execution_count":2},{"id":"0046bb12","cell_type":"code","source":"# THIẾT LẬP CẤU HÌNH (PHIÊN BẢN CRNN)\n\n# --- Cấu hình chung ---\nSEED = 42\ndef set_seed(seed_value):\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    tf.random.set_seed(seed_value)\nset_seed(SEED)\n\nKAGGLE_PROCESSED_DATA_PATH = \"/kaggle/input/ngt-spectrogram-id/\"\nKAGGLE_OUTPUT_PATH = \"/kaggle/working/output_results\"\nCHECKPOINT_PATH = \"/kaggle/working/checkpoints\"\nTFRECORD_OUTPUT_PATH = \"/kaggle/working/tfrecords\"\nos.makedirs(CHECKPOINT_PATH, exist_ok=True)\nos.makedirs(KAGGLE_OUTPUT_PATH, exist_ok=True)\nos.makedirs(TFRECORD_OUTPUT_PATH, exist_ok=True)\n\nCLASSES_TO_TRAIN = ['covid', 'asthma', 'healthy', 'tuberculosis']\nALL_CLASSES = ['healthy', 'asthma', 'covid', 'tuberculosis']\nN_SPLITS = 5\nTEST_SPLIT_RATIO = 0.15\nMODEL_ID = f'CRNN_EfficientNetB2_CV' # Cập nhật tên model\n\n# --- Cấu hình Kiến trúc CRNN ---\n# Số lượng units trong lớp LSTM. Giá trị lớn hơn giúp học các chuỗi phức tạp hơn.\nLSTM_UNITS = 256 \n\n# --- Cấu hình Data Augmentation & Regularization ---\n# Giữ các giá trị đã được cân bằng từ lần trước\nAUG_FREQ_MASKS = 2\nAUG_TIME_MASKS = 2\nAUG_FREQ_MASK_SIZE = 40\nAUG_TIME_MASK_SIZE = 50\nDROPOUT_RATE_1 = 0.5\nDROPOUT_RATE_2 = 0.3\nWEIGHT_DECAY = 1e-4\nLABEL_SMOOTHING_VALUE = 0.1\n\n# --- Các công tắc Bật/Tắt ---\nUSE_DATA_AUGMENTATION = True \nUSE_FOCAL_LOSS = True        \nUSE_COSINE_DECAY_RESTARTS = True \n\n# --- Cấu hình pipeline dữ liệu ---\nBATCH_SIZE = 64 # Giảm BATCH_SIZE vì CRNN tốn nhiều bộ nhớ hơn\nGLOBAL_BATCH_SIZE = BATCH_SIZE * strategy.num_replicas_in_sync\nSHUFFLE_BUFFER_SIZE = 2048\nINPUT_SHAPE = (260, 260, 3)\n\n# --- Cấu hình Huấn luyện (Quy trình Fine-tuning) ---\nprint(\"--- CÁC THAM SỐ HUẤN LUYỆN CHO CRNN ---\")\nSTAGE1_HEAD_EPOCHS = 20\nSTAGE1_HEAD_LR = 5e-5\nSTAGE1_HEAD_PATIENCE = 5\nprint(f\"Giai đoạn 1 (Head): {STAGE1_HEAD_EPOCHS} epochs, LR={STAGE1_HEAD_LR}\")\n\nSTAGE1_FINETUNE_TOTAL_EPOCHS = 150\nSTAGE1_FINETUNE_LR_INITIAL = 1e-5 \nSTAGE1_FINETUNE_PATIENCE = 30\nRESTART_CYCLE_1_EPOCHS = 25\nprint(f\"Giai đoạn 2 (Finetune): Tối đa {STAGE1_FINETUNE_TOTAL_EPOCHS} epochs, LR ban đầu={STAGE1_FINETUNE_LR_INITIAL}\")\n\n# --- Các tham số khác ---\nGAMMA = 2.0 \nMIN_DELTA = 1e-4\n","metadata":{"execution":{"iopub.execute_input":"2025-10-14T15:10:41.931882Z","iopub.status.busy":"2025-10-14T15:10:41.931139Z","iopub.status.idle":"2025-10-14T15:10:41.942810Z","shell.execute_reply":"2025-10-14T15:10:41.942148Z"},"papermill":{"duration":0.017937,"end_time":"2025-10-14T15:10:41.943882","exception":false,"start_time":"2025-10-14T15:10:41.925945","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["--- CÁC THAM SỐ HUẤN LUYỆN ---\n","Giai đoạn 1A (Head): 20 epochs, LR=5e-05\n","Giai đoạn 1B (Finetune): Tối đa 175 epochs, LR ban đầu=1e-05\n","Giai đoạn 2 (SMOTE Head): 50 epochs, LR=1e-05\n"]}],"execution_count":3},{"id":"5302705f","cell_type":"code","source":"# KHỞI TẠO CÁC HÀM CẦN THIẾT \n\ndef get_patient_id(filepath, class_name):\n    filename = os.path.basename(filepath)\n    if class_name.lower() in ['asthma', 'covid', 'healthy']:\n        return filename.split('_')[0]\n    elif class_name.lower() == 'tuberculosis':\n        return '_'.join(filename.split('_')[:-1]).replace('.npy', '')\n    else:\n        return filename.split('_')[0]\n\n@register_keras_serializable()\nclass MacroF1Score(tf.keras.metrics.Metric):\n    \"\"\"\n    Lớp metric để tính toán Macro F1-Score một cách chính xác trên toàn bộ epoch.\n    \"\"\"\n    def __init__(self, num_classes, name='f1_macro', **kwargs):\n        super(MacroF1Score, self).__init__(name=name, **kwargs)\n        self.num_classes = num_classes\n        self.true_positives = self.add_weight(name='tp', shape=(num_classes,), initializer='zeros')\n        self.false_positives = self.add_weight(name='fp', shape=(num_classes,), initializer='zeros')\n        self.false_negatives = self.add_weight(name='fn', shape=(num_classes,), initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_pred_labels = tf.argmax(tf.nn.softmax(y_pred), axis=1)\n        y_true_labels = tf.argmax(y_true, axis=1)\n        cm = tf.math.confusion_matrix(y_true_labels, y_pred_labels, num_classes=self.num_classes, dtype=tf.float32)\n        tp = tf.linalg.diag_part(cm)\n        fp = tf.reduce_sum(cm, axis=0) - tp\n        fn = tf.reduce_sum(cm, axis=1) - tp\n        self.true_positives.assign_add(tp)\n        self.false_positives.assign_add(fp)\n        self.false_negatives.assign_add(fn)\n\n    def result(self):\n        precision = self.true_positives / (self.true_positives + self.false_positives + tf.keras.backend.epsilon())\n        recall = self.true_positives / (self.true_positives + self.false_negatives + tf.keras.backend.epsilon())\n        f1 = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n        macro_f1 = tf.reduce_mean(f1)\n        return macro_f1\n\n    def reset_state(self):\n        self.true_positives.assign(tf.zeros(self.num_classes))\n        self.false_positives.assign(tf.zeros(self.num_classes))\n        self.false_negatives.assign(tf.zeros(self.num_classes))\n\n    # Thêm phương thức get_config\n    def get_config(self):\n        config = super(MacroF1Score, self).get_config()\n        config.update({'num_classes': self.num_classes})\n        return config\n\n    def reset_state(self):\n        # Reset các biến trạng thái về 0 ở đầu mỗi epoch\n        self.true_positives.assign(tf.zeros(self.num_classes))\n        self.false_positives.assign(tf.zeros(self.num_classes))\n        self.false_negatives.assign(tf.zeros(self.num_classes))\n        \ndef parse_tfrecord_fn(example):\n    \"\"\"\n    Hàm parse TFRecord hoàn chỉnh, giải quyết triệt để lỗi NaN bằng cách:\n    1. Làm sạch các giá trị NaN/inf trong tensor đầu vào.\n    2. Sử dụng phép toán an toàn (tf.maximum) để tránh chia cho 0.\n    \"\"\"\n    # 1. Định nghĩa cấu trúc của TFRecord\n    feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'label': tf.io.FixedLenFeature([], tf.int64),\n    }\n    example = tf.io.parse_single_example(example, feature_description)\n    \n    # 2. Đọc và định hình lại tensor ảnh\n    image = tf.io.parse_tensor(example['image'], out_type=tf.float32)\n    # QUAN TRỌNG: Đảm bảo kích thước này khớp với dữ liệu gốc của bạn\n    image.set_shape([256, 126]) \n    \n    # 3. Thay đổi kích thước và thêm kênh màu\n    image_3d = tf.stack([image, image, image], axis=-1)\n    image_resized = tf.image.resize(image_3d, [INPUT_SHAPE[0], INPUT_SHAPE[1]])\n    \n    # 4. LÀM SẠCH DỮ LIỆU (Bước quan trọng nhất)\n    # Thay thế bất kỳ giá trị NaN hoặc Inf nào bằng số 0.0\n    image_sanitized = tf.where(tf.math.is_finite(image_resized), image_resized, 0.0)\n    \n    # 5. CHUẨN HÓA (SCALING) MỘT CÁCH AN TOÀN\n    min_val = tf.reduce_min(image_sanitized)\n    max_val = tf.reduce_max(image_sanitized)\n    \n    denominator = max_val - min_val\n    \n    # Sử dụng tf.maximum để đảm bảo mẫu số không bao giờ bằng 0.\n    # Đây là cách an toàn để thực hiện 'if denominator == 0' trong đồ thị TensorFlow.\n    denominator = tf.maximum(denominator, 1e-7)\n        \n    image_scaled_01 = (image_sanitized - min_val) / denominator\n    image_scaled_255 = image_scaled_01 * 255.0\n    \n    # 6. Áp dụng tiền xử lý của model\n    image_preprocessed = preprocess_input(image_scaled_255)\n    \n    # 7. Chuyển nhãn sang dạng one-hot\n    label = tf.one_hot(tf.cast(example['label'], tf.int32), depth=len(ALL_CLASSES))\n    \n    return image_preprocessed, label\n\ndef spec_augment(spectrogram):\n    \"\"\"\n    Sử dụng các tham số từ ô cấu hình để áp dụng SpecAugment.\n    \"\"\"\n    spectrogram_aug = spectrogram\n    freq_bins = tf.shape(spectrogram)[0]\n    time_steps = tf.shape(spectrogram)[1]\n    \n    # Frequency Masking\n    for _ in range(AUG_FREQ_MASKS):\n        f = tf.random.uniform(shape=(), minval=0, maxval=AUG_FREQ_MASK_SIZE, dtype=tf.int32)\n        f0 = tf.random.uniform(shape=(), minval=0, maxval=freq_bins - f, dtype=tf.int32)\n        freq_mask_1d = tf.concat([tf.ones((f0,), dtype=spectrogram.dtype), tf.zeros((f,), dtype=spectrogram.dtype), tf.ones((freq_bins - f0 - f,), dtype=spectrogram.dtype)], axis=0)\n        freq_mask_3d = tf.reshape(freq_mask_1d, (freq_bins, 1, 1))\n        spectrogram_aug *= freq_mask_3d\n        \n    # Time Masking\n    for _ in range(AUG_TIME_MASKS):\n        t = tf.random.uniform(shape=(), minval=0, maxval=AUG_TIME_MASK_SIZE, dtype=tf.int32)\n        t0 = tf.random.uniform(shape=(), minval=0, maxval=time_steps - t, dtype=tf.int32)\n        time_mask_1d = tf.concat([tf.ones((t0,), dtype=spectrogram.dtype), tf.zeros((t,), dtype=spectrogram.dtype), tf.ones((time_steps - t0 - t,), dtype=spectrogram.dtype)], axis=0)\n        time_mask_3d = tf.reshape(time_mask_1d, (1, time_steps, 1))\n        spectrogram_aug *= time_mask_3d\n        \n    return spectrogram_aug\n\ndef augment(image, label):\n    image = spec_augment(image)\n    return image, label\n\n# === KIẾN TRÚC MÔ HÌNH CRNN MỚI ===\n@register_keras_serializable()\nclass FinalModelCRNN(tf.keras.Model):\n    def __init__(self, input_shape_config, num_classes_config, lstm_units_config, **kwargs):\n        super(FinalModelCRNN, self).__init__(**kwargs)\n        self.input_shape_config = input_shape_config\n        self.num_classes_config = num_classes_config\n        self.lstm_units_config = lstm_units_config\n\n        # 1. Phần CNN: Vẫn là EfficientNet làm bộ trích xuất đặc trưng\n        self.base_model = EfficientNetV2B2(\n            weights='imagenet',\n            include_top=False, \n            input_shape=self.input_shape_config\n        )\n        # Output shape của base_model sẽ là (None, height, width, channels)\n        # Ví dụ: (None, 8, 8, 1280)\n        \n        # 2. Lớp Reshape: Chuyển feature map thành chuỗi (sequence)\n        # Ta sẽ coi chiều 'width' là các bước thời gian (timesteps)\n        # Shape (None, 8, 8, 1280) -> (None, 8, 8 * 1280)\n        output_shape = self.base_model.output_shape\n        # target_shape = (timesteps, features_per_step)\n        target_shape = (output_shape[1], output_shape[2] * output_shape[3]) \n        self.reshape = tf.keras.layers.Reshape(target_shape=target_shape, name=\"reshape_to_sequence\")\n\n        # 3. Phần RNN: Sử dụng Bidirectional LSTM để học cả hai chiều của chuỗi\n        # Bidirectional làm tăng gấp đôi sức mạnh của LSTM\n        self.lstm = tf.keras.layers.Bidirectional(\n            tf.keras.layers.LSTM(self.lstm_units_config, return_sequences=False), # return_sequences=False vì chỉ cần output cuối cùng\n            name=\"bidirectional_lstm\"\n        )\n        \n        # 4. Phần Phân loại (Head): Tương tự như trước\n        self.dense1 = Dense(512, use_bias=False, kernel_regularizer=l2(WEIGHT_DECAY), name=\"dense_layer_1\")\n        self.bn1 = BatchNormalization(name=\"batch_norm_1\")\n        self.act1 = Activation('relu', name=\"activation_1\")\n        self.dropout1 = Dropout(DROPOUT_RATE_1, name=\"dropout_layer_1\")\n        \n        self.dense_output = Dense(self.num_classes_config, activation='linear', dtype='float32', name=\"output_layer\")\n\n    def call(self, inputs, training=None):\n        # 1. Trích xuất feature map bằng CNN\n        x = self.base_model(inputs, training=training)\n        \n        # 2. Chuyển đổi thành chuỗi\n        x = self.reshape(x)\n        \n        # 3. Xử lý chuỗi bằng LSTM\n        x = self.lstm(x, training=training)\n        \n        # 4. Phân loại\n        x = self.dense1(x)\n        x = self.bn1(x, training=training)\n        x = self.act1(x)\n        x = self.dropout1(x, training=training)\n        \n        outputs = self.dense_output(x)\n        return outputs\n\n    def get_config(self):\n        config = super(FinalModelCRNN, self).get_config()\n        config.update({\n            'input_shape_config': self.input_shape_config,\n            'num_classes_config': self.num_classes_config,\n            'lstm_units_config': self.lstm_units_config,\n        })\n        return config\n\n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\n\n        \ndef load_data_from_df(df):\n    X, y = [], []\n    for _, row in df.iterrows():\n        X.append(np.load(row['filepath']))\n        y.append(row['label'])\n    return np.array(X), np.array(y)\n\ndef get_grad_cam_final(model, img_array, last_conv_layer_name, pred_index=None):\n    \"\"\"\n    Tạo Grad-CAM cho một subclassed model.\n    Lưu ý: Model phải được build (chạy qua dữ liệu một lần) trước khi gọi hàm này.\n    \"\"\"\n    # Tạo một model trung gian với input là input của model chính,\n    # và output là lớp conv cuối và output cuối cùng của model chính.\n    grad_model = Model(\n        inputs=model.inputs,\n        outputs=[model.base_model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    # Tính toán gradient\n    with tf.GradientTape() as tape:\n        # Đưa ảnh vào grad_model để lấy 2 output đã định nghĩa ở trên\n        last_conv_layer_output, preds = grad_model(img_array)\n        \n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # Lấy gradient của lớp được dự đoán đối với feature map của lớp conv cuối\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # Tính trung bình gradient và tạo heatmap\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    \n    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + tf.keras.backend.epsilon())\n    \n    return heatmap.numpy()\n\ndef overlay_grad_cam(spec, heatmap, alpha=0.6):\n    heatmap_resized = tf.image.resize(heatmap[..., np.newaxis], (spec.shape[0], spec.shape[1]))\n    heatmap_resized = np.uint8(255 * heatmap_resized)\n    jet = plt.cm.get_cmap(\"jet\")\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap_resized.squeeze()]\n    spec_display = np.stack([spec]*3, axis=-1)\n    spec_display = (spec_display - spec_display.min()) / (spec_display.max() - spec_display.min())\n    superimposed_img = jet_heatmap * alpha + spec_display\n    superimposed_img = np.clip(superimposed_img, 0, 1)\n    return superimposed_img\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy()\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef serialize_example(image, label):\n    \"\"\"Creates a tf.train.Example message ready to be written to a file.\"\"\"\n    feature = {\n        'image': _bytes_feature(tf.io.serialize_tensor(image)),\n        'label': _int64_feature(label)\n    }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()\nclass LearningRateLogger(tf.keras.callbacks.Callback):\n    def on_epoch_begin(self, epoch, logs=None):\n        current_lr = tf.keras.backend.get_value(self.model.optimizer.learning_rate)\n        print(f\"\\nEpoch {epoch+1}: Learning Rate is {current_lr:.2e}\")\n\n# CHUẨN BỊ DỮ LIỆU VÀ TẠO TFRECORD \n\nsuspicious_files_to_remove = [\n    '/kaggle/input/ngt-spectrogram-id/healthy/P0030101_123370_Dkwg3F7jMGaR7kbc-seg2.npy',\n    '/kaggle/input/ngt-spectrogram-id/covid/P0032202_15897_PcbyJQWemBfghUYp-seg2.npy',\n    '/kaggle/input/ngt-spectrogram-id/covid/P0027142_5701_hupBI5CxKMNCfe8b-seg1.npy',\n    '/kaggle/input/ngt-spectrogram-id/covid/P0056214_89533_0WsmNRSKuQFGodg1-seg1.npy',\n]\n# --- BƯỚC 1: TẢI VÀ PHÂN CHIA DỮ LIỆU BAN ĐẦU ---\nprint(\"Bắt đầu chuẩn bị và phân chia dữ liệu...\")\nall_files_to_split = []\nfor class_name in ALL_CLASSES:\n    source_dir = os.path.join(KAGGLE_PROCESSED_DATA_PATH, class_name)\n    if os.path.exists(source_dir):\n        files = glob.glob(os.path.join(source_dir, '*.npy'))\n        for f in files:\n            all_files_to_split.append({'filepath': f, 'label': class_name})\n\nall_data_df = pd.DataFrame(all_files_to_split)\nall_data_df['patient_id'] = all_data_df.apply(lambda row: get_patient_id(row['filepath'], row['label']), axis=1)\n\nprint(f\"Số lượng mẫu ban đầu: {len(all_data_df)}\")\nall_data_df = all_data_df[~all_data_df['filepath'].isin(suspicious_files_to_remove)].reset_index(drop=True)\nprint(f\"Số lượng mẫu sau khi lọc bỏ file 'im lặng': {len(all_data_df)}\")\n\nprint(\"Tách tập Test cuối cùng (Hold-out set)...\")\npatient_ids = all_data_df['patient_id'].unique()\nnp.random.shuffle(patient_ids)\ntest_patient_count = int(len(patient_ids) * TEST_SPLIT_RATIO)\ntest_patients = patient_ids[:test_patient_count]\ntrain_val_patients = patient_ids[test_patient_count:]\n\ntest_df = all_data_df[all_data_df['patient_id'].isin(test_patients)].reset_index(drop=True)\ntrain_val_df = all_data_df[all_data_df['patient_id'].isin(train_val_patients)].reset_index(drop=True)\n\nprint(f\"Đã tách: {len(train_val_df)} mẫu cho Train/Validation (CV) và {len(test_df)} mẫu cho Test cuối cùng.\")\n\n# --- BƯỚC 2: KHỞI TẠO LABEL ENCODER ---\nle = LabelEncoder().fit(ALL_CLASSES)\n\n# --- BƯỚC 3: CHỈ TẠO FILE TFRECORD CHO TẬP TEST ---\nTFRECORD_OUTPUT_PATH = \"/kaggle/working/tfrecords\"\nos.makedirs(TFRECORD_OUTPUT_PATH, exist_ok=True)\nprint(f\"Bắt đầu chuyển đổi dữ liệu sang TFRecord tại: {TFRECORD_OUTPUT_PATH}\")\n\nprint(\"--- Đang xử lý và tạo file cho tập test ---\")\ntest_tfrecord_path = os.path.join(TFRECORD_OUTPUT_PATH, \"test.tfrec\")\nwith tf.io.TFRecordWriter(test_tfrecord_path) as writer:\n    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Creating test.tfrec\"):\n        spectrogram = np.load(row['filepath']).astype(np.float32)\n        \n        image_tensor = tf.convert_to_tensor(spectrogram)\n        image_3d = tf.stack([image_tensor]*3, axis=-1)\n        image_resized = tf.image.resize(image_3d, [INPUT_SHAPE[0], INPUT_SHAPE[1]])\n        min_val = tf.reduce_min(image_resized)\n        max_val = tf.reduce_max(image_resized)\n        image_scaled_01 = (image_resized - min_val) / (max_val - min_val + 1e-7)\n        image_to_serialize = image_scaled_01 * 255.0\n\n        label_encoded = le.transform([row['label']])[0]\n        example = serialize_example(image_to_serialize, label_encoded)\n        writer.write(example)\n\nprint(\"\\\\nChuẩn bị dữ liệu ban đầu hoàn tất!\")","metadata":{"execution":{"iopub.execute_input":"2025-10-14T15:10:41.951956Z","iopub.status.busy":"2025-10-14T15:10:41.951681Z","iopub.status.idle":"2025-10-14T15:12:03.977518Z","shell.execute_reply":"2025-10-14T15:12:03.976664Z"},"papermill":{"duration":82.031719,"end_time":"2025-10-14T15:12:03.979030","exception":false,"start_time":"2025-10-14T15:10:41.947311","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Bắt đầu chuẩn bị và phân chia dữ liệu...\n","Số lượng mẫu ban đầu: 33084\n","Số lượng mẫu sau khi lọc bỏ file 'im lặng': 33080\n","Tách tập Test cuối cùng (Hold-out set)...\n","Đã tách: 28060 mẫu cho Train/Validation (CV) và 5020 mẫu cho Test cuối cùng.\n","Bắt đầu chuyển đổi dữ liệu sang TFRecord tại: /kaggle/working/tfrecords\n","--- Đang xử lý và tạo file cho tập test ---\n"]},{"name":"stderr","output_type":"stream","text":["Creating test.tfrec:   0%|          | 0/5020 [00:00<?, ?it/s]I0000 00:00:1760454643.577508      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","Creating test.tfrec: 100%|██████████| 5020/5020 [01:20<00:00, 62.29it/s]"]},{"name":"stdout","output_type":"stream","text":["\\nChuẩn bị dữ liệu ban đầu hoàn tất!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"execution_count":4},{"id":"7041b821","cell_type":"code","source":"# --- Ô CODE HUẤN LUYỆN ---\n\n# === HÀM HỖ TRỢ VẼ BIỂU ĐỒ (giữ nguyên) ===\ndef plot_training_history(history, title_prefix, fold_number, output_dir):\n    # (Nội dung hàm không thay đổi, giữ nguyên như trước)\n    plt.figure(figsize=(18, 6))\n    full_title = f\"{title_prefix} - Fold {fold_number}\"\n    plt.suptitle(full_title, fontsize=16)\n    plt.subplot(1, 2, 1)\n    metrics_to_plot = ['accuracy', 'auc', 'f1_macro']\n    colors = {'accuracy': 'blue', 'auc': 'green', 'f1_macro': 'red'}\n    for metric in metrics_to_plot:\n        if history.history.get(metric):\n            plt.plot(history.history[metric], label=f'Training {metric.capitalize()}', color=colors[metric], linestyle='-')\n        val_metric = f'val_{metric}'\n        if history.history.get(val_metric):\n            plt.plot(history.history[val_metric], label=f'Validation {metric.capitalize()}', color=colors[metric], linestyle='--')\n    plt.title('Biểu đồ các chỉ số'); plt.xlabel('Epoch'); plt.ylabel('Giá trị')\n    if any(metric in history.history for metric in metrics_to_plot):\n        plt.legend(loc='lower left')\n    plt.grid(True)\n    plt.subplot(1, 2, 2)\n    if history.history.get('loss'):\n        plt.plot(history.history['loss'], label='Training Loss', color='orange')\n    if history.history.get('val_loss'):\n        plt.plot(history.history['val_loss'], label='Validation Loss', color='purple')\n    plt.title('Biểu đồ Loss'); plt.xlabel('Epoch'); plt.ylabel('Loss')\n    if history.history.get('loss') or history.history.get('val_loss'):\n        plt.legend(loc='upper right')\n    plt.grid(True)\n    filename_prefix = title_prefix.replace(' ', '_').replace('-', '_').replace(':', '')\n    filename = f\"fold_{fold_number}_{filename_prefix}_metrics.png\"\n    filepath = os.path.join(output_dir, filename)\n    plt.savefig(filepath)\n    plt.close()\n    print(f\"Đã lưu biểu đồ: {os.path.basename(filepath)}\")\n\n# --- BƯỚC 1: KHỞI TẠO CÁC BIẾN CẦN THIẾT ---\nprint(\"Đang khởi tạo các biến cho Cross-Validation...\")\nAUTOTUNE = tf.data.AUTOTUNE\nskf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\ny_labels_for_split = le.transform(train_val_df['label'])\ngroups_for_split = train_val_df['patient_id'].values\nfold_accuracies, fold_losses, fold_aucs, fold_f1s = [], [], [], []\n\nif USE_FOCAL_LOSS:\n    print(\"Đang tính toán trọng số alpha cho Focal Loss...\")\n    class_weights_array = class_weight.compute_class_weight('balanced', classes=np.unique(y_labels_for_split), y=y_labels_for_split)\n    alpha_weights_list = class_weights_array.tolist()\n    for i, w in enumerate(alpha_weights_list):\n        class_name = le.inverse_transform([i])[0]\n        print(f\"- Lớp '{class_name}': {w:.2f}\")\nelse:\n    alpha_weights_list = []\n\n# --- BƯỚC 2: BẮT ĐẦU VÒNG LẶP CROSS-VALIDATION ---\nfor fold, (train_indices, val_indices) in enumerate(skf.split(train_val_df, y_labels_for_split, groups_for_split)):\n    fold_number = fold + 1\n    print(\"-\" * 60 + f\"\\nBắt đầu Fold {fold_number}/{N_SPLITS}\\n\" + \"-\" * 60)\n\n    train_fold_df = train_val_df.iloc[train_indices]\n    val_fold_df = train_val_df.iloc[val_indices]\n\n    # === QUY TRÌNH HUẤN LUYỆN FINE-TUNING CHO CRNN ===\n    print(\"\\n\" + \"#\" * 20 + f\" HUẤN LUYỆN CRNN (Fold {fold_number}) \" + \"#\" * 20)\n    \n    # --- 1A: Tạo pipeline dữ liệu ---\n    train_tfrec_path = os.path.join(TFRECORD_OUTPUT_PATH, f\"train_fold_{fold_number}.tfrec\")\n    val_tfrec_path = os.path.join(TFRECORD_OUTPUT_PATH, f\"val_fold_{fold_number}.tfrec\")\n    def write_raw_tfrecord(df, path, desc):\n        with tf.io.TFRecordWriter(path) as writer:\n            for _, row in tqdm(df.iterrows(), total=len(df), desc=desc):\n                spectrogram = np.load(row['filepath']).astype(np.float32)\n                label_encoded = le.transform([row['label']])[0]\n                example = serialize_example(spectrogram, label_encoded)\n                writer.write(example)\n    if not os.path.exists(train_tfrec_path):\n        write_raw_tfrecord(train_fold_df, train_tfrec_path, f\"Writing Raw Train Fold {fold_number}\")\n    if not os.path.exists(val_tfrec_path):\n        write_raw_tfrecord(val_fold_df, val_tfrec_path, f\"Writing Raw Val Fold {fold_number}\")\n\n    train_ds = tf.data.TFRecordDataset(train_tfrec_path).map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n    val_ds = tf.data.TFRecordDataset(val_tfrec_path).map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE).cache().batch(GLOBAL_BATCH_SIZE).prefetch(AUTOTUNE)\n    \n    if USE_DATA_AUGMENTATION:\n        train_ds = train_ds.map(augment, num_parallel_calls=AUTOTUNE)\n        \n    train_ds = train_ds.shuffle(SHUFFLE_BUFFER_SIZE).repeat().batch(GLOBAL_BATCH_SIZE, drop_remainder=True).prefetch(AUTOTUNE)\n    \n    steps_per_epoch = len(train_indices) // GLOBAL_BATCH_SIZE\n    validation_steps = len(val_indices) // GLOBAL_BATCH_SIZE\n    \n    # --- 1B: Huấn luyện 2 bước trên mô hình CRNN ---\n    with strategy.scope():\n        # Gọi kiến trúc CRNN mới\n        model = FinalModelCRNN(\n            input_shape_config=INPUT_SHAPE, \n            num_classes_config=len(ALL_CLASSES),\n            lstm_units_config=LSTM_UNITS \n        )\n        \n        if USE_FOCAL_LOSS:\n            loss_function = tf.keras.losses.CategoricalFocalCrossentropy(from_logits=True, alpha=alpha_weights_list, gamma=GAMMA, label_smoothing=LABEL_SMOOTHING_VALUE)\n        else:\n            loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=LABEL_SMOOTHING_VALUE)\n            \n        # Giai đoạn 1: Huấn luyện Head (LSTM + Dense)\n        print(\"\\n--- Giai đoạn 1: Huấn luyện Head (LSTM + Dense) ---\")\n        model.base_model.trainable = False\n        optimizer_head = tf.keras.optimizers.AdamW(learning_rate=STAGE1_HEAD_LR, weight_decay=WEIGHT_DECAY, epsilon=1e-7)\n        model.compile(optimizer=optimizer_head, loss=loss_function, metrics=['accuracy'])\n        history_head = model.fit(train_ds, validation_data=val_ds, epochs=STAGE1_HEAD_EPOCHS, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, callbacks=[EarlyStopping(monitor='val_loss', patience=STAGE1_HEAD_PATIENCE, restore_best_weights=True)], verbose=1)\n        \n        # Giai đoạn 2: Huấn luyện chính (Fine-tuning toàn bộ CRNN)\n        print(\"\\n--- Giai đoạn 2: Huấn luyện chính (Fine-tuning toàn bộ CRNN) ---\")\n        model.base_model.trainable = True\n        \n        if USE_COSINE_DECAY_RESTARTS:\n            print(\"Sử dụng scheduler: CosineDecayRestarts\")\n            first_decay_steps = RESTART_CYCLE_1_EPOCHS * steps_per_epoch\n            lr_scheduler = tf.keras.optimizers.schedules.CosineDecayRestarts(initial_learning_rate=STAGE1_FINETUNE_LR_INITIAL, first_decay_steps=first_decay_steps, t_mul=2.0, m_mul=0.9, alpha=0.1)\n            optimizer_finetune = tf.keras.optimizers.AdamW(learning_rate=lr_scheduler, weight_decay=WEIGHT_DECAY, epsilon=1e-7)\n            callbacks = [EarlyStopping(monitor='val_f1_macro', mode='max', patience=STAGE1_FINETUNE_PATIENCE, restore_best_weights=True, min_delta=MIN_DELTA, verbose=1), LearningRateLogger()]\n        else:\n            print(\"Không sử dụng CosineDecayRestarts\")\n            optimizer_finetune = tf.keras.optimizers.AdamW(learning_rate=STAGE1_FINETUNE_LR_INITIAL, weight_decay=WEIGHT_DECAY, epsilon=1e-7)\n            callbacks = [EarlyStopping(monitor='val_f1_macro', mode='max', patience=STAGE1_FINETUNE_PATIENCE, restore_best_weights=True, verbose=1)]\n        \n        f1_macro = MacroF1Score(num_classes=len(ALL_CLASSES))\n        model.compile(optimizer=optimizer_finetune, loss=loss_function, metrics=['accuracy', tf.keras.metrics.AUC(name='auc'), f1_macro])\n        \n        history_finetune = model.fit(train_ds, validation_data=val_ds, epochs=STAGE1_FINETUNE_TOTAL_EPOCHS, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, callbacks=callbacks, verbose=1)\n    \n    # === BƯỚC CUỐI: LƯU, VẼ BIỂU ĐỒ, ĐÁNH GIÁ, DỌN DẸP ===\n    model_save_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_fold_{fold_number}.keras')\n    model.save(model_save_path)\n    print(f\"\\nĐã lưu model cuối cùng cho Fold {fold_number} tại: {model_save_path}\")\n\n    print(\"\\n--- Vẽ và lưu các biểu đồ huấn luyện ---\")\n    plot_training_history(history_head, \"Giai doan 1 - CRNN Head Training\", fold_number, KAGGLE_OUTPUT_PATH)\n    plot_training_history(history_finetune, \"Giai doan 2 - CRNN Fine-tuning\", fold_number, KAGGLE_OUTPUT_PATH)\n\n    print(\"\\n--- Đánh giá trên tập Validation và dọn dẹp ---\")\n    with strategy.scope():\n        # Tải lại model đã lưu để đảm bảo tính nhất quán\n        model_to_evaluate = tf.keras.models.load_model(model_save_path, custom_objects={'FinalModelCRNN': FinalModelCRNN, 'MacroF1Score': MacroF1Score})\n        model_to_evaluate.compile(loss=loss_function, metrics=['accuracy', tf.keras.metrics.AUC(name='auc'), f1_macro])\n    \n    val_results = model_to_evaluate.evaluate(val_ds, verbose=0, return_dict=True)\n    loss, accuracy, auc, f1 = val_results.get('loss', 0), val_results.get('accuracy', 0), val_results.get('auc', 0), val_results.get('f1_macro', 0)\n    print(f\"Fold {fold_number} - Validation Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, AUC: {auc:.4f}, F1-Macro: {f1:.4f}\")\n    \n    fold_accuracies.append(accuracy)\n    fold_losses.append(loss)\n    fold_aucs.append(auc)\n    fold_f1s.append(f1)\n    \n    print(\"=\" * 60 + \"\\nKết quả Cross-Validation Tạm thời:\\n\" \n          + f\"  - Accuracy trung bình: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\\n\"\n          + f\"  - Loss trung bình: {np.mean(fold_losses):.4f} +/- {np.std(fold_losses):.4f}\\n\"\n          + f\"  - AUC trung bình: {np.mean(fold_aucs):.4f} +/- {np.std(fold_aucs):.4f}\\n\"\n          + f\"  - F1-Macro trung bình: {np.mean(fold_f1s):.4f} +/- {np.std(fold_f1s):.4f}\\n\"\n          + \"=\" * 60)\n          \n    print(\"\\n--- Dọn dẹp file TFRecord tạm thời ---\")\n    try:\n        files_to_remove = glob.glob(os.path.join(TFRECORD_OUTPUT_PATH, f\"*fold_{fold_number}*\"))\n        for f in files_to_remove:\n            os.remove(f)\n            print(f\"Đã xóa: {os.path.basename(f)}\")\n    except OSError as e:\n        print(f\"Lỗi khi xóa file: {e}\")\n\n    print(\"\\n--- Dọn dẹp bộ nhớ RAM và đồ thị Keras ---\")\n    try:\n        del model, model_to_evaluate, train_ds, val_ds\n        tf.keras.backend.clear_session()\n        gc.collect()\n        print(\"Đã dọn dẹp bộ nhớ thành công.\")\n    except NameError as e:\n        print(f\"Một số biến có thể đã được dọn dẹp, bỏ qua lỗi: {e}\")\n\n# --- IN KẾT QUẢ TỔNG KẾT CUỐI CÙNG ---\nprint(\"\\n\\n\" + \"=\" * 60 + \"\\nKẾT QUẢ CROSS-VALIDATION CUỐI CÙNG:\\n\" \n      + f\"  - Validation Accuracy trung bình: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\\n\"\n      + f\"  - Validation Loss trung bình: {np.mean(fold_losses):.4f} +/- {np.std(fold_losses):.4f}\\n\"\n      + f\"  - Validation AUC trung bình: {np.mean(fold_aucs):.4f} +/- {np.std(fold_aucs):.4f}\\n\"\n      + f\"  - Validation F1-Macro trung bình: {np.mean(fold_f1s):.4f} +/- {np.std(fold_f1s):.4f}\\n\"\n      + \"=\" * 60)\n","metadata":{"execution":{"iopub.execute_input":"2025-10-14T15:12:04.041829Z","iopub.status.busy":"2025-10-14T15:12:04.041470Z"},"papermill":{"duration":10137.541687,"end_time":"2025-10-14T18:01:01.552134","exception":false,"start_time":"2025-10-14T15:12:04.010447","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Đang khởi tạo các biến cho Cross-Validation...\n","Đang tính toán trọng số alpha cho Focal Loss...\n","- Lớp 'asthma': 1.82\n","- Lớp 'covid': 0.80\n","- Lớp 'healthy': 0.87\n","- Lớp 'tuberculosis': 0.96\n","------------------------------------------------------------\n","Bắt đầu Fold 1/5\n","------------------------------------------------------------\n","\n","#################### GIAI ĐOẠN 1: FINE-TUNING TRÊN DỮ LIỆU GỐC (Fold 1) ####################\n"]},{"name":"stderr","output_type":"stream","text":["Writing Raw Train Fold 1: 100%|██████████| 22453/22453 [04:43<00:00, 79.23it/s]\n","Writing Raw Val Fold 1: 100%|██████████| 5607/5607 [01:12<00:00, 77.20it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b2_notop.h5\n","\u001b[1m35839040/35839040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","\n","--- Giai đoạn 1A: Huấn luyện Head trên dữ liệu gốc ---\n","Epoch 1/20\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1760455123.170494      72 service.cc:148] XLA service 0x7f66b001a9e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","I0000 00:00:1760455123.173400      72 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","I0000 00:00:1760455126.161185      72 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","2025-10-14 15:18:57.360760: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f16[128,33,33,224]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,33,33,56]{3,2,1,0}, f16[224,3,3,56]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:18:57.372258: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.011602399s\n","Trying algorithm eng0{} for conv (f16[128,33,33,224]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,33,33,56]{3,2,1,0}, f16[224,3,3,56]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m  1/175\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59:42\u001b[0m 62s/step - accuracy: 0.2344 - loss: 1.4372"]},{"name":"stderr","output_type":"stream","text":["I0000 00:00:1760455151.951139      72 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 395ms/step - accuracy: 0.2751 - loss: 1.5035 - val_accuracy: 0.3181 - val_loss: 1.1866\n","Epoch 2/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 299ms/step - accuracy: 0.2526 - loss: 1.4955 - val_accuracy: 0.4326 - val_loss: 0.9533\n","Epoch 3/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 303ms/step - accuracy: 0.2460 - loss: 1.4628 - val_accuracy: 0.4669 - val_loss: 0.9350\n","Epoch 4/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 296ms/step - accuracy: 0.2424 - loss: 1.4589 - val_accuracy: 0.4669 - val_loss: 0.9317\n","Epoch 5/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 296ms/step - accuracy: 0.2344 - loss: 1.4287 - val_accuracy: 0.4809 - val_loss: 0.9261\n","Epoch 6/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 291ms/step - accuracy: 0.2489 - loss: 1.4100 - val_accuracy: 0.4829 - val_loss: 0.9432\n","Epoch 7/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 293ms/step - accuracy: 0.2471 - loss: 1.3827 - val_accuracy: 0.4935 - val_loss: 0.9375\n","Epoch 8/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 295ms/step - accuracy: 0.2478 - loss: 1.3604 - val_accuracy: 0.4902 - val_loss: 0.9427\n","Epoch 9/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 295ms/step - accuracy: 0.2578 - loss: 1.3379 - val_accuracy: 0.4924 - val_loss: 0.9386\n","Epoch 10/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 293ms/step - accuracy: 0.2591 - loss: 1.3210 - val_accuracy: 0.4878 - val_loss: 0.9420\n","\n","--- Giai đoạn 1B: Huấn luyện chính (Fine-tuning) trên dữ liệu gốc ---\n","\n","Epoch 1: Learning Rate is 1.00e-05\n","Epoch 1/175\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1760455793.013409      72 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Assert\n","W0000 00:00:1760455794.181518      72 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Assert\n","W0000 00:00:1760455794.184498      72 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_less/Assert/AssertGuard/Assert\n","W0000 00:00:1760455794.187875      72 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_less_1/Assert/AssertGuard/Assert\n","2025-10-14 15:30:17.036250: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f16[128,33,33,56]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,33,33,224]{3,2,1,0}, f16[224,3,3,56]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:17.512615: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.476456738s\n","Trying algorithm eng0{} for conv (f16[128,33,33,56]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,33,33,224]{3,2,1,0}, f16[224,3,3,56]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:20.543161: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f16[128,65,65,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,65,65,128]{3,2,1,0}, f16[128,3,3,32]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:21.817436: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.274454552s\n","Trying algorithm eng0{} for conv (f16[128,65,65,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,65,65,128]{3,2,1,0}, f16[128,3,3,32]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:29.696243: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng19{k2=3} for conv (f16[16,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,130,130,32]{3,2,1,0}, f16[128,130,130,16]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:29.873427: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.177370841s\n","Trying algorithm eng19{k2=3} for conv (f16[16,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,130,130,32]{3,2,1,0}, f16[128,130,130,16]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:30.873620: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng19{k2=2} for conv (f16[16,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,130,130,32]{3,2,1,0}, f16[128,130,130,16]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:30.946484: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.072967926s\n","Trying algorithm eng19{k2=2} for conv (f16[16,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,130,130,32]{3,2,1,0}, f16[128,130,130,16]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:31.946695: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng19{k2=0} for conv (f16[16,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,130,130,32]{3,2,1,0}, f16[128,130,130,16]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:32.280178: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.333598468s\n","Trying algorithm eng19{k2=0} for conv (f16[16,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,130,130,32]{3,2,1,0}, f16[128,130,130,16]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:33.280369: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f16[16,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,130,130,32]{3,2,1,0}, f16[128,130,130,16]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:40.184667: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 7.904392769s\n","Trying algorithm eng0{} for conv (f16[16,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,130,130,32]{3,2,1,0}, f16[128,130,130,16]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:42.807564: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f16[16,3,3,16]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,130,130,16]{3,2,1,0}, f16[128,130,130,16]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:44.109776: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.302397005s\n","Trying algorithm eng0{} for conv (f16[16,3,3,16]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,130,130,16]{3,2,1,0}, f16[128,130,130,16]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:45.349141: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng19{k2=0} for conv (f16[64,3,3,16]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,131,131,16]{3,2,1,0}, f16[128,65,65,64]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:45.573445: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.224425295s\n","Trying algorithm eng19{k2=0} for conv (f16[64,3,3,16]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,131,131,16]{3,2,1,0}, f16[128,65,65,64]{3,2,1,0}), window={size=3x3 stride=2x2}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:47.797918: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng19{k2=2} for conv (f16[128,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,65,65,32]{3,2,1,0}, f16[128,65,65,128]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:50.225893: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.42809983s\n","Trying algorithm eng19{k2=2} for conv (f16[128,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,65,65,32]{3,2,1,0}, f16[128,65,65,128]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:51.226169: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng19{k2=3} for conv (f16[128,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,65,65,32]{3,2,1,0}, f16[128,65,65,128]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:53.629143: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.403104214s\n","Trying algorithm eng19{k2=3} for conv (f16[128,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,65,65,32]{3,2,1,0}, f16[128,65,65,128]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:54.741027: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng19{k2=0} for conv (f16[128,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,65,65,32]{3,2,1,0}, f16[128,65,65,128]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:57.853474: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 4.112629619s\n","Trying algorithm eng19{k2=0} for conv (f16[128,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,65,65,32]{3,2,1,0}, f16[128,65,65,128]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:30:59.316025: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng19{k2=0} for conv (f16[128,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,65,65,32]{3,2,1,0}, f16[128,33,33,128]{3,2,1,0}), window={size=3x3 stride=2x2 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:31:00.170598: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.854803109s\n","Trying algorithm eng19{k2=0} for conv (f16[128,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,65,65,32]{3,2,1,0}, f16[128,33,33,128]{3,2,1,0}), window={size=3x3 stride=2x2 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:31:01.916898: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng19{k2=2} for conv (f16[224,3,3,56]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,33,33,56]{3,2,1,0}, f16[128,33,33,224]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:31:03.509936: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.593123023s\n","Trying algorithm eng19{k2=2} for conv (f16[224,3,3,56]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,33,33,56]{3,2,1,0}, f16[128,33,33,224]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:31:04.510170: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng19{k2=3} for conv (f16[224,3,3,56]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,33,33,56]{3,2,1,0}, f16[128,33,33,224]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:31:06.332820: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.822762049s\n","Trying algorithm eng19{k2=3} for conv (f16[224,3,3,56]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,33,33,56]{3,2,1,0}, f16[128,33,33,224]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:31:07.333044: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng19{k2=0} for conv (f16[224,3,3,56]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,33,33,56]{3,2,1,0}, f16[128,33,33,224]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n","2025-10-14 15:31:09.540108: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.207169428s\n","Trying algorithm eng19{k2=0} for conv (f16[224,3,3,56]{3,2,1,0}, u8[0]{0}) custom-call(f16[128,33,33,56]{3,2,1,0}, f16[128,33,33,224]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.2253 - auc: 0.4883 - f1_macro: 0.1695 - loss: 1.4334"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1760455988.662473      73 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Assert\n","W0000 00:00:1760455989.554521      73 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Assert\n","W0000 00:00:1760455989.557146      73 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_less/Assert/AssertGuard/Assert\n","W0000 00:00:1760455989.560226      73 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_less_1/Assert/AssertGuard/Assert\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 458ms/step - accuracy: 0.2255 - auc: 0.4884 - f1_macro: 0.1700 - loss: 1.4332 - val_accuracy: 0.4257 - val_auc: 0.6307 - val_f1_macro: 0.3460 - val_loss: 0.9641\n","\n","Epoch 2: Learning Rate is 9.97e-06\n","Epoch 2/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 389ms/step - accuracy: 0.2324 - auc: 0.4933 - f1_macro: 0.1811 - loss: 1.4224 - val_accuracy: 0.4457 - val_auc: 0.6444 - val_f1_macro: 0.3499 - val_loss: 0.9630\n","\n","Epoch 3: Learning Rate is 9.86e-06\n","Epoch 3/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 383ms/step - accuracy: 0.2286 - auc: 0.4956 - f1_macro: 0.1808 - loss: 1.4106 - val_accuracy: 0.4586 - val_auc: 0.6479 - val_f1_macro: 0.3448 - val_loss: 0.9679\n","\n","Epoch 4: Learning Rate is 9.69e-06\n","Epoch 4/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 385ms/step - accuracy: 0.2340 - auc: 0.4998 - f1_macro: 0.1856 - loss: 1.3905 - val_accuracy: 0.4588 - val_auc: 0.6467 - val_f1_macro: 0.3539 - val_loss: 0.9688\n","\n","Epoch 5: Learning Rate is 9.45e-06\n","Epoch 5/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 385ms/step - accuracy: 0.2348 - auc: 0.5005 - f1_macro: 0.1886 - loss: 1.3862 - val_accuracy: 0.4662 - val_auc: 0.6499 - val_f1_macro: 0.3573 - val_loss: 0.9758\n","\n","Epoch 6: Learning Rate is 9.15e-06\n","Epoch 6/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 385ms/step - accuracy: 0.2372 - auc: 0.5060 - f1_macro: 0.1934 - loss: 1.3631 - val_accuracy: 0.4689 - val_auc: 0.6500 - val_f1_macro: 0.3633 - val_loss: 0.9846\n","\n","Epoch 7: Learning Rate is 8.79e-06\n","Epoch 7/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 385ms/step - accuracy: 0.2329 - auc: 0.5040 - f1_macro: 0.1911 - loss: 1.3528 - val_accuracy: 0.4713 - val_auc: 0.6575 - val_f1_macro: 0.3599 - val_loss: 0.9849\n","\n","Epoch 8: Learning Rate is 8.38e-06\n","Epoch 8/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 384ms/step - accuracy: 0.2548 - auc: 0.5155 - f1_macro: 0.2080 - loss: 1.3296 - val_accuracy: 0.4751 - val_auc: 0.6573 - val_f1_macro: 0.3659 - val_loss: 0.9832\n","\n","Epoch 9: Learning Rate is 7.92e-06\n","Epoch 9/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 385ms/step - accuracy: 0.2552 - auc: 0.5114 - f1_macro: 0.2088 - loss: 1.3266 - val_accuracy: 0.4762 - val_auc: 0.6573 - val_f1_macro: 0.3689 - val_loss: 0.9767\n","\n","Epoch 10: Learning Rate is 7.43e-06\n","Epoch 10/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 386ms/step - accuracy: 0.2610 - auc: 0.5186 - f1_macro: 0.2148 - loss: 1.3046 - val_accuracy: 0.4795 - val_auc: 0.6596 - val_f1_macro: 0.3754 - val_loss: 0.9654\n","\n","Epoch 11: Learning Rate is 6.90e-06\n","Epoch 11/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 384ms/step - accuracy: 0.2590 - auc: 0.5166 - f1_macro: 0.2126 - loss: 1.3006 - val_accuracy: 0.4844 - val_auc: 0.6613 - val_f1_macro: 0.3826 - val_loss: 0.9637\n","\n","Epoch 12: Learning Rate is 6.36e-06\n","Epoch 12/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 385ms/step - accuracy: 0.2622 - auc: 0.5234 - f1_macro: 0.2195 - loss: 1.2831 - val_accuracy: 0.4737 - val_auc: 0.6601 - val_f1_macro: 0.3793 - val_loss: 0.9615\n","\n","Epoch 13: Learning Rate is 5.80e-06\n","Epoch 13/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 386ms/step - accuracy: 0.2656 - auc: 0.5282 - f1_macro: 0.2206 - loss: 1.2682 - val_accuracy: 0.4762 - val_auc: 0.6602 - val_f1_macro: 0.3837 - val_loss: 0.9642\n","\n","Epoch 14: Learning Rate is 5.23e-06\n","Epoch 14/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 386ms/step - accuracy: 0.2729 - auc: 0.5311 - f1_macro: 0.2272 - loss: 1.2516 - val_accuracy: 0.4786 - val_auc: 0.6618 - val_f1_macro: 0.3889 - val_loss: 0.9556\n","\n","Epoch 15: Learning Rate is 4.67e-06\n","Epoch 15/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 385ms/step - accuracy: 0.2773 - auc: 0.5331 - f1_macro: 0.2328 - loss: 1.2469 - val_accuracy: 0.4795 - val_auc: 0.6645 - val_f1_macro: 0.3837 - val_loss: 0.9490\n","\n","Epoch 16: Learning Rate is 4.12e-06\n","Epoch 16/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 386ms/step - accuracy: 0.2779 - auc: 0.5329 - f1_macro: 0.2332 - loss: 1.2310 - val_accuracy: 0.4804 - val_auc: 0.6661 - val_f1_macro: 0.3912 - val_loss: 0.9473\n","\n","Epoch 17: Learning Rate is 3.60e-06\n","Epoch 17/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 384ms/step - accuracy: 0.2798 - auc: 0.5350 - f1_macro: 0.2345 - loss: 1.2282 - val_accuracy: 0.4786 - val_auc: 0.6638 - val_f1_macro: 0.3881 - val_loss: 0.9486\n","\n","Epoch 18: Learning Rate is 3.10e-06\n","Epoch 18/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 385ms/step - accuracy: 0.2724 - auc: 0.5314 - f1_macro: 0.2285 - loss: 1.2268 - val_accuracy: 0.4793 - val_auc: 0.6638 - val_f1_macro: 0.3940 - val_loss: 0.9493\n","\n","Epoch 19: Learning Rate is 2.64e-06\n","Epoch 19/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 385ms/step - accuracy: 0.2860 - auc: 0.5438 - f1_macro: 0.2434 - loss: 1.1989 - val_accuracy: 0.4824 - val_auc: 0.6663 - val_f1_macro: 0.3941 - val_loss: 0.9474\n","\n","Epoch 20: Learning Rate is 2.23e-06\n","Epoch 20/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 384ms/step - accuracy: 0.2848 - auc: 0.5395 - f1_macro: 0.2402 - loss: 1.2053 - val_accuracy: 0.4757 - val_auc: 0.6653 - val_f1_macro: 0.3882 - val_loss: 0.9500\n","\n","Epoch 21: Learning Rate is 1.87e-06\n","Epoch 21/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 384ms/step - accuracy: 0.2856 - auc: 0.5412 - f1_macro: 0.2407 - loss: 1.2003 - val_accuracy: 0.4740 - val_auc: 0.6645 - val_f1_macro: 0.3888 - val_loss: 0.9523\n","\n","Epoch 22: Learning Rate is 1.56e-06\n","Epoch 22/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 383ms/step - accuracy: 0.2932 - auc: 0.5489 - f1_macro: 0.2521 - loss: 1.1884 - val_accuracy: 0.4660 - val_auc: 0.6614 - val_f1_macro: 0.3836 - val_loss: 0.9556\n","\n","Epoch 23: Learning Rate is 1.32e-06\n","Epoch 23/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 384ms/step - accuracy: 0.2982 - auc: 0.5500 - f1_macro: 0.2526 - loss: 1.1880 - val_accuracy: 0.4666 - val_auc: 0.6612 - val_f1_macro: 0.3846 - val_loss: 0.9570\n","\n","Epoch 24: Learning Rate is 1.15e-06\n","Epoch 24/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 383ms/step - accuracy: 0.2797 - auc: 0.5402 - f1_macro: 0.2388 - loss: 1.1989 - val_accuracy: 0.4686 - val_auc: 0.6625 - val_f1_macro: 0.3846 - val_loss: 0.9540\n","\n","Epoch 25: Learning Rate is 1.04e-06\n","Epoch 25/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 385ms/step - accuracy: 0.2937 - auc: 0.5462 - f1_macro: 0.2467 - loss: 1.1828 - val_accuracy: 0.4651 - val_auc: 0.6597 - val_f1_macro: 0.3856 - val_loss: 0.9565\n","\n","Epoch 26: Learning Rate is 1.00e-06\n","Epoch 26/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 384ms/step - accuracy: 0.3017 - auc: 0.5516 - f1_macro: 0.2526 - loss: 1.1696 - val_accuracy: 0.4239 - val_auc: 0.6418 - val_f1_macro: 0.3526 - val_loss: 0.9766\n","\n","Epoch 27: Learning Rate is 9.09e-06\n","Epoch 27/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 384ms/step - accuracy: 0.3069 - auc: 0.5571 - f1_macro: 0.2574 - loss: 1.1502 - val_accuracy: 0.4179 - val_auc: 0.6416 - val_f1_macro: 0.3479 - val_loss: 0.9747\n","\n","Epoch 28: Learning Rate is 9.07e-06\n","Epoch 28/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 385ms/step - accuracy: 0.3283 - auc: 0.5731 - f1_macro: 0.2763 - loss: 1.1137 - val_accuracy: 0.4124 - val_auc: 0.6360 - val_f1_macro: 0.3464 - val_loss: 0.9708\n","\n","Epoch 29: Learning Rate is 9.03e-06\n","Epoch 29/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 384ms/step - accuracy: 0.3453 - auc: 0.5815 - f1_macro: 0.2852 - loss: 1.0995 - val_accuracy: 0.3670 - val_auc: 0.6242 - val_f1_macro: 0.3118 - val_loss: 0.9697\n","\n","Epoch 30: Learning Rate is 8.97e-06\n","Epoch 30/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 384ms/step - accuracy: 0.3520 - auc: 0.5913 - f1_macro: 0.2939 - loss: 1.0718 - val_accuracy: 0.3924 - val_auc: 0.6350 - val_f1_macro: 0.3335 - val_loss: 0.9599\n","\n","Epoch 31: Learning Rate is 8.90e-06\n","Epoch 31/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 383ms/step - accuracy: 0.3617 - auc: 0.6007 - f1_macro: 0.2968 - loss: 1.0663 - val_accuracy: 0.3599 - val_auc: 0.6136 - val_f1_macro: 0.3125 - val_loss: 0.9612\n","\n","Epoch 32: Learning Rate is 8.82e-06\n","Epoch 32/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 382ms/step - accuracy: 0.3800 - auc: 0.6078 - f1_macro: 0.3177 - loss: 1.0424 - val_accuracy: 0.3452 - val_auc: 0.6129 - val_f1_macro: 0.2973 - val_loss: 0.9603\n","\n","Epoch 33: Learning Rate is 8.72e-06\n","Epoch 33/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 383ms/step - accuracy: 0.3889 - auc: 0.6128 - f1_macro: 0.3199 - loss: 1.0418 - val_accuracy: 0.3378 - val_auc: 0.6133 - val_f1_macro: 0.2891 - val_loss: 0.9592\n","\n","Epoch 34: Learning Rate is 8.60e-06\n","Epoch 34/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 383ms/step - accuracy: 0.3981 - auc: 0.6193 - f1_macro: 0.3242 - loss: 1.0233 - val_accuracy: 0.3955 - val_auc: 0.6289 - val_f1_macro: 0.3396 - val_loss: 0.9453\n","\n","Epoch 35: Learning Rate is 8.47e-06\n","Epoch 35/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 383ms/step - accuracy: 0.4041 - auc: 0.6254 - f1_macro: 0.3304 - loss: 1.0104 - val_accuracy: 0.3939 - val_auc: 0.6311 - val_f1_macro: 0.3408 - val_loss: 0.9436\n","\n","Epoch 36: Learning Rate is 8.33e-06\n","Epoch 36/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 381ms/step - accuracy: 0.4216 - auc: 0.6434 - f1_macro: 0.3441 - loss: 0.9846 - val_accuracy: 0.3674 - val_auc: 0.6215 - val_f1_macro: 0.3245 - val_loss: 0.9428\n","\n","Epoch 37: Learning Rate is 8.18e-06\n","Epoch 37/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 383ms/step - accuracy: 0.4286 - auc: 0.6424 - f1_macro: 0.3435 - loss: 0.9775 - val_accuracy: 0.3790 - val_auc: 0.6199 - val_f1_macro: 0.3402 - val_loss: 0.9423\n","\n","Epoch 38: Learning Rate is 8.01e-06\n","Epoch 38/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 382ms/step - accuracy: 0.4254 - auc: 0.6474 - f1_macro: 0.3437 - loss: 0.9812 - val_accuracy: 0.3576 - val_auc: 0.6135 - val_f1_macro: 0.3133 - val_loss: 0.9428\n","\n","Epoch 39: Learning Rate is 7.83e-06\n","Epoch 39/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 382ms/step - accuracy: 0.4408 - auc: 0.6594 - f1_macro: 0.3599 - loss: 0.9605 - val_accuracy: 0.3636 - val_auc: 0.6178 - val_f1_macro: 0.3179 - val_loss: 0.9381\n","\n","Epoch 40: Learning Rate is 7.64e-06\n","Epoch 40/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 382ms/step - accuracy: 0.4534 - auc: 0.6667 - f1_macro: 0.3693 - loss: 0.9505 - val_accuracy: 0.3786 - val_auc: 0.6206 - val_f1_macro: 0.3373 - val_loss: 0.9364\n","\n","Epoch 41: Learning Rate is 7.44e-06\n","Epoch 41/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 384ms/step - accuracy: 0.4574 - auc: 0.6658 - f1_macro: 0.3695 - loss: 0.9501 - val_accuracy: 0.3792 - val_auc: 0.6199 - val_f1_macro: 0.3387 - val_loss: 0.9378\n","\n","Epoch 42: Learning Rate is 7.23e-06\n","Epoch 42/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 384ms/step - accuracy: 0.4641 - auc: 0.6772 - f1_macro: 0.3772 - loss: 0.9404 - val_accuracy: 0.3592 - val_auc: 0.6129 - val_f1_macro: 0.3235 - val_loss: 0.9380\n","\n","Epoch 43: Learning Rate is 7.01e-06\n","Epoch 43/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 383ms/step - accuracy: 0.4864 - auc: 0.6884 - f1_macro: 0.3858 - loss: 0.9295 - val_accuracy: 0.3590 - val_auc: 0.6167 - val_f1_macro: 0.3176 - val_loss: 0.9324\n","\n","Epoch 44: Learning Rate is 6.78e-06\n","Epoch 44/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 382ms/step - accuracy: 0.4876 - auc: 0.6924 - f1_macro: 0.3947 - loss: 0.9223 - val_accuracy: 0.3737 - val_auc: 0.6221 - val_f1_macro: 0.3338 - val_loss: 0.9294\n","\n","Epoch 45: Learning Rate is 6.55e-06\n","Epoch 45/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 382ms/step - accuracy: 0.4835 - auc: 0.6875 - f1_macro: 0.3847 - loss: 0.9139 - val_accuracy: 0.3754 - val_auc: 0.6177 - val_f1_macro: 0.3324 - val_loss: 0.9313\n","\n","Epoch 46: Learning Rate is 6.31e-06\n","Epoch 46/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 384ms/step - accuracy: 0.4899 - auc: 0.6923 - f1_macro: 0.3909 - loss: 0.9054 - val_accuracy: 0.3864 - val_auc: 0.6225 - val_f1_macro: 0.3367 - val_loss: 0.9291\n","\n","Epoch 47: Learning Rate is 6.07e-06\n","Epoch 47/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 383ms/step - accuracy: 0.5113 - auc: 0.7071 - f1_macro: 0.4094 - loss: 0.8929 - val_accuracy: 0.3552 - val_auc: 0.6104 - val_f1_macro: 0.3128 - val_loss: 0.9313\n","\n","Epoch 48: Learning Rate is 5.82e-06\n","Epoch 48/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 383ms/step - accuracy: 0.5100 - auc: 0.7092 - f1_macro: 0.4053 - loss: 0.8967 - val_accuracy: 0.3318 - val_auc: 0.6034 - val_f1_macro: 0.2954 - val_loss: 0.9323\n","\n","Epoch 49: Learning Rate is 5.57e-06\n","Epoch 49/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 382ms/step - accuracy: 0.5284 - auc: 0.7226 - f1_macro: 0.4198 - loss: 0.8806 - val_accuracy: 0.3114 - val_auc: 0.5900 - val_f1_macro: 0.2762 - val_loss: 0.9365\n","Epoch 49: early stopping\n","Restoring model weights from the end of the best epoch: 19.\n","\n","### KẾT THÚC GIAI ĐOẠN 1 (Fold 1) ###\n","\n","#################### GIAI ĐOẠN 2: TINH CHỈNH HEAD BẰNG SMOTE (Fold 1) ####################\n","\n","--- Bước 2A: Trích xuất đặc trưng (Tiết kiệm bộ nhớ bằng Batch Iteration) ---\n"]},{"name":"stderr","output_type":"stream","text":["Extracting features batch by batch: 100%|██████████| 176/176 [02:31<00:00,  1.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","--- Bước 2B: Áp dụng SMOTE ---\n","\n","--- Bước 2C: Huấn luyện lại các lớp Dense trên dữ liệu SMOTE ---\n","Epoch 1/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.1722 - loss: 0.7159\n","Epoch 2/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1829 - loss: 0.6929\n","Epoch 3/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1925 - loss: 0.6610\n","Epoch 4/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1966 - loss: 0.6304\n","Epoch 5/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2145 - loss: 0.6065\n","Epoch 6/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2193 - loss: 0.5825\n","Epoch 7/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2338 - loss: 0.5618\n","Epoch 8/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2350 - loss: 0.5511\n","Epoch 9/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2539 - loss: 0.5342\n","Epoch 10/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2582 - loss: 0.5189\n","Epoch 11/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2685 - loss: 0.5031\n","Epoch 12/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2845 - loss: 0.4955\n","Epoch 13/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2815 - loss: 0.4859\n","Epoch 14/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2914 - loss: 0.4806\n","Epoch 15/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2946 - loss: 0.4708\n","Epoch 16/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3081 - loss: 0.4605\n","Epoch 17/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3138 - loss: 0.4596\n","Epoch 18/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3209 - loss: 0.4473\n","Epoch 19/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3227 - loss: 0.4427\n","Epoch 20/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3236 - loss: 0.4404\n","Epoch 21/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3312 - loss: 0.4340\n","Epoch 22/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3406 - loss: 0.4267\n","Epoch 23/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3371 - loss: 0.4229\n","Epoch 24/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3394 - loss: 0.4202\n","Epoch 25/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3394 - loss: 0.4156\n","Epoch 26/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3437 - loss: 0.4112\n","Epoch 27/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3517 - loss: 0.4055\n","Epoch 28/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3485 - loss: 0.4061\n","Epoch 29/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3525 - loss: 0.4006\n","Epoch 30/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3534 - loss: 0.3984\n","Epoch 31/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3504 - loss: 0.3948\n","Epoch 32/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3526 - loss: 0.3921\n","Epoch 33/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3544 - loss: 0.3896\n","Epoch 34/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3686 - loss: 0.3840\n","Epoch 35/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3656 - loss: 0.3815\n","Epoch 36/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3644 - loss: 0.3801\n","Epoch 37/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3583 - loss: 0.3774\n","Epoch 38/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3635 - loss: 0.3756\n","Epoch 39/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3682 - loss: 0.3730\n","Epoch 40/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3640 - loss: 0.3700\n","Epoch 41/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3739 - loss: 0.3679\n","Epoch 42/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3693 - loss: 0.3669\n","Epoch 43/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3737 - loss: 0.3656\n","Epoch 44/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3677 - loss: 0.3630\n","Epoch 45/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3807 - loss: 0.3601\n","Epoch 46/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3710 - loss: 0.3607\n","Epoch 47/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3781 - loss: 0.3557\n","Epoch 48/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3701 - loss: 0.3548\n","Epoch 49/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3718 - loss: 0.3538\n","Epoch 50/50\n","\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3808 - loss: 0.3480\n","\n","--- Bước 2D: Lắp ráp model cuối cùng ---\n","Đã lưu model cuối cùng cho Fold 1 tại: /kaggle/working/output_results/EfficienetV2B2_CV_SMOTE_fold_1.keras\n","\n","--- Bước E: Vẽ và lưu các biểu đồ huấn luyện chi tiết ---\n","Đã lưu biểu đồ: fold_1_Giai_doan_1A___Head_Training_metrics.png\n","Đã lưu biểu đồ: fold_1_Giai_doan_1B___Fine_tuning_metrics.png\n","Đã lưu biểu đồ: fold_1_Giai_doan_2C___SMOTE_Head_metrics.png\n","\n","--- Bước F: Đánh giá trên tập Validation và dọn dẹp ---\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1760459439.856147      71 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Assert\n","W0000 00:00:1760459440.713492      71 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Assert\n","W0000 00:00:1760459440.716119      71 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_less/Assert/AssertGuard/Assert\n","W0000 00:00:1760459440.719099      71 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_less_1/Assert/AssertGuard/Assert\n","W0000 00:00:1760459449.565416      71 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Assert\n","W0000 00:00:1760459450.252142      71 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Assert\n","W0000 00:00:1760459450.253696      71 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_less/Assert/AssertGuard/Assert\n","W0000 00:00:1760459450.255318      71 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_less_1/Assert/AssertGuard/Assert\n","/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self._interrupted_warning()\n"]},{"name":"stdout","output_type":"stream","text":["Fold 1 - Validation Loss: 0.8210, Accuracy: 0.4163, AUC: 0.6994, F1-Macro: 0.3580\n","============================================================\n","Kết quả Cross-Validation Tạm thời:\n","  - Accuracy trung bình: 0.4163 +/- 0.0000\n","  - Loss trung bình: 0.8210 +/- 0.0000\n","  - AUC trung bình: 0.6994 +/- 0.0000\n","  - F1-Macro trung bình: 0.3580 +/- 0.0000\n","============================================================\n","\n","--- Dọn dẹp file TFRecord tạm thời ---\n","Đã xóa: train_fold_1.tfrec\n","Đã xóa: val_fold_1.tfrec\n","\n","--- Dọn dẹp bộ nhớ RAM và đồ thị Keras ---\n","Một số biến đã được dọn dẹp trước đó, bỏ qua.\n","------------------------------------------------------------\n","Bắt đầu Fold 2/5\n","------------------------------------------------------------\n","\n","#################### GIAI ĐOẠN 1: FINE-TUNING TRÊN DỮ LIỆU GỐC (Fold 2) ####################\n"]},{"name":"stderr","output_type":"stream","text":["Writing Raw Train Fold 2: 100%|██████████| 22404/22404 [01:27<00:00, 257.41it/s]\n","Writing Raw Val Fold 2: 100%|██████████| 5656/5656 [00:21<00:00, 257.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","--- Giai đoạn 1A: Huấn luyện Head trên dữ liệu gốc ---\n","Epoch 1/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 430ms/step - accuracy: 0.1289 - loss: 2.2336 - val_accuracy: 0.2942 - val_loss: 1.2973\n","Epoch 2/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 321ms/step - accuracy: 0.1557 - loss: 1.9281 - val_accuracy: 0.4020 - val_loss: 1.0686\n","Epoch 3/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 324ms/step - accuracy: 0.1797 - loss: 1.7377 - val_accuracy: 0.4604 - val_loss: 0.9823\n","Epoch 4/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 470ms/step - accuracy: 0.1997 - loss: 1.6103 - val_accuracy: 0.4755 - val_loss: 0.9480\n","Epoch 5/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 324ms/step - accuracy: 0.2147 - loss: 1.5510 - val_accuracy: 0.4950 - val_loss: 0.9313\n","Epoch 6/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 326ms/step - accuracy: 0.2208 - loss: 1.4853 - val_accuracy: 0.5146 - val_loss: 0.9188\n","Epoch 7/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 312ms/step - accuracy: 0.2217 - loss: 1.4612 - val_accuracy: 0.5027 - val_loss: 0.9043\n","Epoch 8/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 468ms/step - accuracy: 0.2161 - loss: 1.4372 - val_accuracy: 0.5149 - val_loss: 0.9243\n","Epoch 9/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 312ms/step - accuracy: 0.2238 - loss: 1.4075 - val_accuracy: 0.5094 - val_loss: 0.9149\n","Epoch 10/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 470ms/step - accuracy: 0.2319 - loss: 1.3831 - val_accuracy: 0.5194 - val_loss: 0.9241\n","Epoch 11/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 313ms/step - accuracy: 0.2345 - loss: 1.3663 - val_accuracy: 0.5103 - val_loss: 0.9251\n","Epoch 12/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 314ms/step - accuracy: 0.2237 - loss: 1.3668 - val_accuracy: 0.5172 - val_loss: 0.9246\n","\n","--- Giai đoạn 1B: Huấn luyện chính (Fine-tuning) trên dữ liệu gốc ---\n","\n","Epoch 1: Learning Rate is 1.00e-05\n","Epoch 1/175\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1760460499.572028      73 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Assert\n","W0000 00:00:1760460501.201206      73 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Assert\n","W0000 00:00:1760460501.203869      73 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_less/Assert/AssertGuard/Assert\n","W0000 00:00:1760460501.206578      73 assert_op.cc:38] Ignoring Assert operator confusion_matrix/assert_less_1/Assert/AssertGuard/Assert\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 473ms/step - accuracy: 0.2133 - auc: 0.4825 - f1_macro: 0.1652 - loss: 1.4789 - val_accuracy: 0.4332 - val_auc: 0.5988 - val_f1_macro: 0.3548 - val_loss: 0.9698\n","\n","Epoch 2: Learning Rate is 9.97e-06\n","Epoch 2/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 395ms/step - accuracy: 0.2114 - auc: 0.4809 - f1_macro: 0.1664 - loss: 1.4624 - val_accuracy: 0.4588 - val_auc: 0.6359 - val_f1_macro: 0.3714 - val_loss: 0.9784\n","\n","Epoch 3: Learning Rate is 9.86e-06\n","Epoch 3/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 389ms/step - accuracy: 0.2204 - auc: 0.4877 - f1_macro: 0.1720 - loss: 1.4380 - val_accuracy: 0.4719 - val_auc: 0.6572 - val_f1_macro: 0.3723 - val_loss: 0.9924\n","\n","Epoch 4: Learning Rate is 9.69e-06\n","Epoch 4/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 393ms/step - accuracy: 0.2105 - auc: 0.4824 - f1_macro: 0.1670 - loss: 1.4334 - val_accuracy: 0.4714 - val_auc: 0.6626 - val_f1_macro: 0.3719 - val_loss: 1.0115\n","\n","Epoch 5: Learning Rate is 9.45e-06\n","Epoch 5/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 393ms/step - accuracy: 0.2235 - auc: 0.4903 - f1_macro: 0.1753 - loss: 1.4016 - val_accuracy: 0.4771 - val_auc: 0.6749 - val_f1_macro: 0.3618 - val_loss: 1.0294\n","\n","Epoch 6: Learning Rate is 9.15e-06\n","Epoch 6/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 391ms/step - accuracy: 0.2291 - auc: 0.4915 - f1_macro: 0.1780 - loss: 1.3839 - val_accuracy: 0.4872 - val_auc: 0.6837 - val_f1_macro: 0.3663 - val_loss: 1.0101\n","\n","Epoch 7: Learning Rate is 8.79e-06\n","Epoch 7/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 391ms/step - accuracy: 0.2311 - auc: 0.4968 - f1_macro: 0.1818 - loss: 1.3573 - val_accuracy: 0.4911 - val_auc: 0.6828 - val_f1_macro: 0.3652 - val_loss: 0.9884\n","\n","Epoch 8: Learning Rate is 8.38e-06\n","Epoch 8/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 390ms/step - accuracy: 0.2314 - auc: 0.4934 - f1_macro: 0.1805 - loss: 1.3365 - val_accuracy: 0.4911 - val_auc: 0.6821 - val_f1_macro: 0.3689 - val_loss: 0.9872\n","\n","Epoch 9: Learning Rate is 7.92e-06\n","Epoch 9/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 390ms/step - accuracy: 0.2349 - auc: 0.5009 - f1_macro: 0.1844 - loss: 1.3202 - val_accuracy: 0.4970 - val_auc: 0.6816 - val_f1_macro: 0.3713 - val_loss: 0.9874\n","\n","Epoch 10: Learning Rate is 7.43e-06\n","Epoch 10/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 391ms/step - accuracy: 0.2423 - auc: 0.5029 - f1_macro: 0.1900 - loss: 1.2959 - val_accuracy: 0.4959 - val_auc: 0.6802 - val_f1_macro: 0.3691 - val_loss: 0.9765\n","\n","Epoch 11: Learning Rate is 6.90e-06\n","Epoch 11/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 391ms/step - accuracy: 0.2400 - auc: 0.5022 - f1_macro: 0.1868 - loss: 1.2932 - val_accuracy: 0.4966 - val_auc: 0.6806 - val_f1_macro: 0.3734 - val_loss: 0.9791\n","\n","Epoch 12: Learning Rate is 6.36e-06\n","Epoch 12/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 389ms/step - accuracy: 0.2386 - auc: 0.5051 - f1_macro: 0.1875 - loss: 1.2772 - val_accuracy: 0.4996 - val_auc: 0.6782 - val_f1_macro: 0.3709 - val_loss: 0.9705\n","\n","Epoch 13: Learning Rate is 5.80e-06\n","Epoch 13/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 470ms/step - accuracy: 0.2498 - auc: 0.5088 - f1_macro: 0.1964 - loss: 1.2513 - val_accuracy: 0.4991 - val_auc: 0.6769 - val_f1_macro: 0.3748 - val_loss: 0.9624\n","\n","Epoch 14: Learning Rate is 5.23e-06\n","Epoch 14/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 398ms/step - accuracy: 0.2490 - auc: 0.5110 - f1_macro: 0.1960 - loss: 1.2346 - val_accuracy: 0.4933 - val_auc: 0.6712 - val_f1_macro: 0.3674 - val_loss: 0.9651\n","\n","Epoch 15: Learning Rate is 4.67e-06\n","Epoch 15/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 394ms/step - accuracy: 0.2464 - auc: 0.5075 - f1_macro: 0.1941 - loss: 1.2242 - val_accuracy: 0.4870 - val_auc: 0.6689 - val_f1_macro: 0.3609 - val_loss: 0.9591\n","\n","Epoch 16: Learning Rate is 4.12e-06\n","Epoch 16/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 392ms/step - accuracy: 0.2522 - auc: 0.5166 - f1_macro: 0.1989 - loss: 1.2063 - val_accuracy: 0.4877 - val_auc: 0.6663 - val_f1_macro: 0.3617 - val_loss: 0.9548\n","\n","Epoch 17: Learning Rate is 3.60e-06\n","Epoch 17/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 393ms/step - accuracy: 0.2617 - auc: 0.5161 - f1_macro: 0.2074 - loss: 1.1978 - val_accuracy: 0.4879 - val_auc: 0.6657 - val_f1_macro: 0.3618 - val_loss: 0.9510\n","\n","Epoch 18: Learning Rate is 3.10e-06\n","Epoch 18/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 395ms/step - accuracy: 0.2673 - auc: 0.5218 - f1_macro: 0.2098 - loss: 1.1751 - val_accuracy: 0.4801 - val_auc: 0.6553 - val_f1_macro: 0.3547 - val_loss: 0.9530\n","\n","Epoch 19: Learning Rate is 2.64e-06\n","Epoch 19/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 393ms/step - accuracy: 0.2658 - auc: 0.5204 - f1_macro: 0.2057 - loss: 1.1727 - val_accuracy: 0.4806 - val_auc: 0.6563 - val_f1_macro: 0.3527 - val_loss: 0.9550\n","\n","Epoch 20: Learning Rate is 2.23e-06\n","Epoch 20/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 392ms/step - accuracy: 0.2532 - auc: 0.5205 - f1_macro: 0.2041 - loss: 1.1700 - val_accuracy: 0.4782 - val_auc: 0.6515 - val_f1_macro: 0.3461 - val_loss: 0.9529\n","\n","Epoch 21: Learning Rate is 1.87e-06\n","Epoch 21/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 389ms/step - accuracy: 0.2755 - auc: 0.5255 - f1_macro: 0.2171 - loss: 1.1625 - val_accuracy: 0.4760 - val_auc: 0.6502 - val_f1_macro: 0.3479 - val_loss: 0.9504\n","\n","Epoch 22: Learning Rate is 1.56e-06\n","Epoch 22/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 388ms/step - accuracy: 0.2724 - auc: 0.5271 - f1_macro: 0.2162 - loss: 1.1652 - val_accuracy: 0.4714 - val_auc: 0.6494 - val_f1_macro: 0.3439 - val_loss: 0.9482\n","\n","Epoch 23: Learning Rate is 1.32e-06\n","Epoch 23/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 390ms/step - accuracy: 0.2759 - auc: 0.5287 - f1_macro: 0.2193 - loss: 1.1387 - val_accuracy: 0.4723 - val_auc: 0.6487 - val_f1_macro: 0.3404 - val_loss: 0.9489\n","\n","Epoch 24: Learning Rate is 1.15e-06\n","Epoch 24/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 392ms/step - accuracy: 0.2727 - auc: 0.5295 - f1_macro: 0.2181 - loss: 1.1439 - val_accuracy: 0.4721 - val_auc: 0.6470 - val_f1_macro: 0.3432 - val_loss: 0.9489\n","\n","Epoch 25: Learning Rate is 1.04e-06\n","Epoch 25/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 392ms/step - accuracy: 0.2596 - auc: 0.5205 - f1_macro: 0.2071 - loss: 1.1633 - val_accuracy: 0.4723 - val_auc: 0.6458 - val_f1_macro: 0.3437 - val_loss: 0.9496\n","\n","Epoch 26: Learning Rate is 1.00e-06\n","Epoch 26/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 392ms/step - accuracy: 0.2742 - auc: 0.5263 - f1_macro: 0.2182 - loss: 1.1406 - val_accuracy: 0.4494 - val_auc: 0.6284 - val_f1_macro: 0.3259 - val_loss: 0.9644\n","\n","Epoch 27: Learning Rate is 9.09e-06\n","Epoch 27/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 393ms/step - accuracy: 0.2884 - auc: 0.5386 - f1_macro: 0.2295 - loss: 1.1265 - val_accuracy: 0.4416 - val_auc: 0.6157 - val_f1_macro: 0.3158 - val_loss: 0.9657\n","\n","Epoch 28: Learning Rate is 9.07e-06\n","Epoch 28/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 392ms/step - accuracy: 0.2813 - auc: 0.5323 - f1_macro: 0.2264 - loss: 1.1142 - val_accuracy: 0.4327 - val_auc: 0.6031 - val_f1_macro: 0.3131 - val_loss: 0.9588\n","\n","Epoch 29: Learning Rate is 9.03e-06\n","Epoch 29/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 390ms/step - accuracy: 0.2953 - auc: 0.5457 - f1_macro: 0.2380 - loss: 1.1027 - val_accuracy: 0.4391 - val_auc: 0.6131 - val_f1_macro: 0.3076 - val_loss: 0.9544\n","\n","Epoch 30: Learning Rate is 8.97e-06\n","Epoch 30/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 393ms/step - accuracy: 0.2969 - auc: 0.5445 - f1_macro: 0.2391 - loss: 1.0883 - val_accuracy: 0.4451 - val_auc: 0.6128 - val_f1_macro: 0.3103 - val_loss: 0.9502\n","\n","Epoch 31: Learning Rate is 8.90e-06\n","Epoch 31/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 391ms/step - accuracy: 0.3023 - auc: 0.5521 - f1_macro: 0.2455 - loss: 1.0724 - val_accuracy: 0.4487 - val_auc: 0.6193 - val_f1_macro: 0.3132 - val_loss: 0.9419\n","\n","Epoch 32: Learning Rate is 8.82e-06\n","Epoch 32/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 392ms/step - accuracy: 0.3177 - auc: 0.5567 - f1_macro: 0.2552 - loss: 1.0637 - val_accuracy: 0.4524 - val_auc: 0.6229 - val_f1_macro: 0.3079 - val_loss: 0.9382\n","\n","Epoch 33: Learning Rate is 8.72e-06\n","Epoch 33/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 391ms/step - accuracy: 0.3059 - auc: 0.5564 - f1_macro: 0.2506 - loss: 1.0596 - val_accuracy: 0.4533 - val_auc: 0.6212 - val_f1_macro: 0.3062 - val_loss: 0.9357\n","\n","Epoch 34: Learning Rate is 8.60e-06\n","Epoch 34/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 391ms/step - accuracy: 0.3130 - auc: 0.5600 - f1_macro: 0.2569 - loss: 1.0526 - val_accuracy: 0.4460 - val_auc: 0.6260 - val_f1_macro: 0.3001 - val_loss: 0.9356\n","\n","Epoch 35: Learning Rate is 8.47e-06\n","Epoch 35/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 389ms/step - accuracy: 0.3289 - auc: 0.5674 - f1_macro: 0.2708 - loss: 1.0479 - val_accuracy: 0.4474 - val_auc: 0.6287 - val_f1_macro: 0.3022 - val_loss: 0.9305\n","\n","Epoch 36: Learning Rate is 8.33e-06\n","Epoch 36/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 392ms/step - accuracy: 0.3276 - auc: 0.5708 - f1_macro: 0.2746 - loss: 1.0385 - val_accuracy: 0.4474 - val_auc: 0.6282 - val_f1_macro: 0.3013 - val_loss: 0.9276\n","\n","Epoch 37: Learning Rate is 8.18e-06\n","Epoch 37/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 391ms/step - accuracy: 0.3276 - auc: 0.5696 - f1_macro: 0.2771 - loss: 1.0347 - val_accuracy: 0.4478 - val_auc: 0.6212 - val_f1_macro: 0.2985 - val_loss: 0.9273\n","\n","Epoch 38: Learning Rate is 8.01e-06\n","Epoch 38/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 390ms/step - accuracy: 0.3312 - auc: 0.5755 - f1_macro: 0.2869 - loss: 1.0280 - val_accuracy: 0.4412 - val_auc: 0.6116 - val_f1_macro: 0.2983 - val_loss: 0.9336\n","\n","Epoch 39: Learning Rate is 7.83e-06\n","Epoch 39/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 391ms/step - accuracy: 0.3360 - auc: 0.5806 - f1_macro: 0.2846 - loss: 1.0368 - val_accuracy: 0.4490 - val_auc: 0.6268 - val_f1_macro: 0.2974 - val_loss: 0.9307\n","\n","Epoch 40: Learning Rate is 7.64e-06\n","Epoch 40/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 391ms/step - accuracy: 0.3399 - auc: 0.5815 - f1_macro: 0.2951 - loss: 1.0230 - val_accuracy: 0.4451 - val_auc: 0.6147 - val_f1_macro: 0.3068 - val_loss: 0.9318\n","\n","Epoch 41: Learning Rate is 7.44e-06\n","Epoch 41/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 393ms/step - accuracy: 0.3263 - auc: 0.5722 - f1_macro: 0.2852 - loss: 1.0292 - val_accuracy: 0.4466 - val_auc: 0.6210 - val_f1_macro: 0.2981 - val_loss: 0.9271\n","\n","Epoch 42: Learning Rate is 7.23e-06\n","Epoch 42/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 391ms/step - accuracy: 0.3365 - auc: 0.5838 - f1_macro: 0.2933 - loss: 1.0186 - val_accuracy: 0.4448 - val_auc: 0.6233 - val_f1_macro: 0.2921 - val_loss: 0.9262\n","\n","Epoch 43: Learning Rate is 7.01e-06\n","Epoch 43/175\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 391ms/step - accuracy: 0.3320 - auc: 0.5816 - f1_macro: 0.2928 - loss: 1.0086 - val_accuracy: 0.4428 - val_auc: 0.6189 - val_f1_macro: 0.2985 - val_loss: 0.9266\n","Epoch 43: early stopping\n","Restoring model weights from the end of the best epoch: 13.\n","\n","### KẾT THÚC GIAI ĐOẠN 1 (Fold 2) ###\n","\n","#################### GIAI ĐOẠN 2: TINH CHỈNH HEAD BẰNG SMOTE (Fold 2) ####################\n","\n","--- Bước 2A: Trích xuất đặc trưng (Tiết kiệm bộ nhớ bằng Batch Iteration) ---\n"]},{"name":"stderr","output_type":"stream","text":["Extracting features batch by batch: 100%|██████████| 176/176 [02:40<00:00,  1.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","--- Bước 2B: Áp dụng SMOTE ---\n","\n","--- Bước 2C: Huấn luyện lại các lớp Dense trên dữ liệu SMOTE ---\n","Epoch 1/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.3076 - loss: 0.5332\n","Epoch 2/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2892 - loss: 0.5371\n","Epoch 3/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2911 - loss: 0.5244\n","Epoch 4/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2909 - loss: 0.5162\n","Epoch 5/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2959 - loss: 0.5106\n","Epoch 6/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3045 - loss: 0.5026\n","Epoch 7/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2978 - loss: 0.4948\n","Epoch 8/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2991 - loss: 0.4929\n","Epoch 9/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3027 - loss: 0.4840\n","Epoch 10/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3076 - loss: 0.4746\n","Epoch 11/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3080 - loss: 0.4749\n","Epoch 12/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3122 - loss: 0.4679\n","Epoch 13/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3178 - loss: 0.4614\n","Epoch 14/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3252 - loss: 0.4562\n","Epoch 15/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3230 - loss: 0.4537\n","Epoch 16/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3303 - loss: 0.4477\n","Epoch 17/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3228 - loss: 0.4443\n","Epoch 18/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3267 - loss: 0.4369\n","Epoch 19/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3335 - loss: 0.4335\n","Epoch 20/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3347 - loss: 0.4314\n","Epoch 21/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3322 - loss: 0.4270\n","Epoch 22/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3380 - loss: 0.4192\n","Epoch 23/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3452 - loss: 0.4145\n","Epoch 24/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3359 - loss: 0.4151\n","Epoch 25/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3427 - loss: 0.4091\n","Epoch 26/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3483 - loss: 0.4079\n","Epoch 27/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3437 - loss: 0.4051\n","Epoch 28/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3449 - loss: 0.4020\n","Epoch 29/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3497 - loss: 0.3970\n","Epoch 30/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3429 - loss: 0.3958\n","Epoch 31/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3583 - loss: 0.3904\n","Epoch 32/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3508 - loss: 0.3898\n","Epoch 33/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3571 - loss: 0.3834\n","Epoch 34/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3580 - loss: 0.3834\n","Epoch 35/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3619 - loss: 0.3787\n","Epoch 36/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3615 - loss: 0.3750\n","Epoch 37/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3577 - loss: 0.3757\n","Epoch 38/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3590 - loss: 0.3730\n","Epoch 39/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3625 - loss: 0.3687\n","Epoch 40/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3599 - loss: 0.3674\n","Epoch 41/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3654 - loss: 0.3653\n","Epoch 42/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3739 - loss: 0.3636\n","Epoch 43/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3730 - loss: 0.3576\n","Epoch 44/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3731 - loss: 0.3594\n","Epoch 45/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3746 - loss: 0.3564\n","Epoch 46/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3770 - loss: 0.3547\n","Epoch 47/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3684 - loss: 0.3537\n","Epoch 48/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3694 - loss: 0.3510\n","Epoch 49/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3779 - loss: 0.3483\n","Epoch 50/50\n","\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3680 - loss: 0.3469\n","\n","--- Bước 2D: Lắp ráp model cuối cùng ---\n","Đã lưu model cuối cùng cho Fold 2 tại: /kaggle/working/output_results/EfficienetV2B2_CV_SMOTE_fold_2.keras\n","\n","--- Bước E: Vẽ và lưu các biểu đồ huấn luyện chi tiết ---\n","Đã lưu biểu đồ: fold_2_Giai_doan_1A___Head_Training_metrics.png\n","Đã lưu biểu đồ: fold_2_Giai_doan_1B___Fine_tuning_metrics.png\n","Đã lưu biểu đồ: fold_2_Giai_doan_2C___SMOTE_Head_metrics.png\n","\n","--- Bước F: Đánh giá trên tập Validation và dọn dẹp ---\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self._interrupted_warning()\n"]},{"name":"stdout","output_type":"stream","text":["Fold 2 - Validation Loss: 0.8342, Accuracy: 0.4091, AUC: 0.7225, F1-Macro: 0.3703\n","============================================================\n","Kết quả Cross-Validation Tạm thời:\n","  - Accuracy trung bình: 0.4127 +/- 0.0036\n","  - Loss trung bình: 0.8276 +/- 0.0066\n","  - AUC trung bình: 0.7109 +/- 0.0115\n","  - F1-Macro trung bình: 0.3641 +/- 0.0062\n","============================================================\n","\n","--- Dọn dẹp file TFRecord tạm thời ---\n","Đã xóa: train_fold_2.tfrec\n","Đã xóa: val_fold_2.tfrec\n","\n","--- Dọn dẹp bộ nhớ RAM và đồ thị Keras ---\n","Một số biến đã được dọn dẹp trước đó, bỏ qua.\n","------------------------------------------------------------\n","Bắt đầu Fold 3/5\n","------------------------------------------------------------\n","\n","#################### GIAI ĐOẠN 1: FINE-TUNING TRÊN DỮ LIỆU GỐC (Fold 3) ####################\n"]},{"name":"stderr","output_type":"stream","text":["Writing Raw Train Fold 3: 100%|██████████| 22432/22432 [03:11<00:00, 117.23it/s]\n","Writing Raw Val Fold 3: 100%|██████████| 5628/5628 [00:44<00:00, 125.80it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","--- Giai đoạn 1A: Huấn luyện Head trên dữ liệu gốc ---\n","Epoch 1/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 425ms/step - accuracy: 0.2953 - loss: 1.4959 - val_accuracy: 0.3199 - val_loss: 1.1744\n","Epoch 2/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 320ms/step - accuracy: 0.2603 - loss: 1.5076 - val_accuracy: 0.4211 - val_loss: 0.9782\n","Epoch 3/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 319ms/step - accuracy: 0.2476 - loss: 1.5043 - val_accuracy: 0.4484 - val_loss: 0.9444\n","Epoch 4/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 322ms/step - accuracy: 0.2396 - loss: 1.4830 - val_accuracy: 0.4617 - val_loss: 0.9345\n","Epoch 5/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 322ms/step - accuracy: 0.2389 - loss: 1.4586 - val_accuracy: 0.4704 - val_loss: 0.9163\n","Epoch 6/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 317ms/step - accuracy: 0.2436 - loss: 1.4352 - val_accuracy: 0.4836 - val_loss: 0.9225\n","Epoch 7/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 469ms/step - accuracy: 0.2405 - loss: 1.4202 - val_accuracy: 0.4915 - val_loss: 0.9267\n","Epoch 8/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 470ms/step - accuracy: 0.2374 - loss: 1.3983 - val_accuracy: 0.4902 - val_loss: 0.9292\n","Epoch 9/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 317ms/step - accuracy: 0.2355 - loss: 1.3797 - val_accuracy: 0.4895 - val_loss: 0.9293\n","Epoch 10/20\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 470ms/step - accuracy: 0.2436 - loss: 1.3620 - val_accuracy: 0.4909 - val_loss: 0.9417\n","\n","--- Giai đoạn 1B: Huấn luyện chính (Fine-tuning) trên dữ liệu gốc ---\n","\n","Epoch 1: Learning Rate is 1.00e-05\n","Epoch 1/175\n"]}],"execution_count":5},{"id":"c09430d3","cell_type":"code","source":"# --- Bắt đầu quy trình đánh giá tổng hợp 5-Fold trên tập test ---\n\nprint(\"--- Chuẩn bị dữ liệu Test cho việc đánh giá ---\")\n\n# 1. Tạo Test Dataset từ file TFRecord đã được xử lý trước\nTEST_TFREC_PATH = os.path.join(TFRECORD_OUTPUT_PATH, \"test.tfrec\")\nif not os.path.exists(TEST_TFREC_PATH):\n    print(f\"Lỗi: Không tìm thấy file test.tfrec tại {TEST_TFREC_PATH}. Vui lòng chạy lại ô chuẩn bị dữ liệu.\")\nelse:\n    # Tạo dataset đã được batch để đưa vào model.evaluate\n    test_ds_batched = tf.data.TFRecordDataset(TEST_TFREC_PATH)\n    test_ds_batched = test_ds_batched.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n    test_ds_batched = test_ds_batched.batch(GLOBAL_BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\n    # --- Bắt đầu quá trình đánh giá ---\n    evaluation_results = []\n    output_filename = \"teacher_models_evaluation_summary.csv\"\n    output_filepath = os.path.join(KAGGLE_OUTPUT_PATH, output_filename)\n    n_classes = len(ALL_CLASSES)\n\n    # Vòng lặp qua 5 Fold để tải và đánh giá từng mô hình\n    for fold_number in range(1, N_SPLITS + 1):\n        print(f\"\\\\n---> Đang đánh giá Fold {fold_number}/{N_SPLITS}...\")\n        \n        model_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_fold_{fold_number}.keras')\n        \n        if not os.path.exists(model_path):\n            print(f\"!!! Cảnh báo: Không tìm thấy file model cho Fold {fold_number} tại '{model_path}'. Bỏ qua fold này.\")\n            continue\n\n        try:\n            with strategy.scope():\n                # Tải lại mô hình đã huấn luyện\n                model = tf.keras.models.load_model(\n                model_path,\n                    custom_objects={\n                        'MacroF1Score': MacroF1Score,\n                        'FinalModel': FinalModel  # <-- THÊM DÒNG NÀY VÀO\n                    }\n                )\n                # Biên dịch lại mô hình để đảm bảo các metrics được tính đúng\n                model.compile(\n                    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n                    optimizer='adam', # Optimizer ở đây không quan trọng vì không huấn luyện lại\n                    metrics=[\n                        'accuracy', \n                        tf.keras.metrics.AUC(name='auc'), \n                        MacroF1Score(num_classes=n_classes, name='f1_macro')\n                    ]\n                )\n\n            # Đánh giá mô hình trên tập Test đã được batch\n            print(f\"Bắt đầu tính toán các chỉ số cho Fold {fold_number}...\")\n            results = model.evaluate(test_ds_batched, return_dict=True, verbose=0)\n            \n            # Lưu kết quả của fold hiện tại\n            fold_summary = {\n                'Fold': fold_number,\n                'Loss': results.get('loss', 0),\n                'Accuracy': results.get('accuracy', 0),\n                'AUC': results.get('auc', 0),\n                'F1-Macro': results.get('f1_macro', 0)\n            }\n            evaluation_results.append(fold_summary)\n            print(f\"Kết quả Fold {fold_number}: {fold_summary}\")\n\n        except Exception as e:\n            print(f\"!!! Lỗi khi xử lý Fold {fold_number}: {e}\")\n\n    # --- Tổng hợp và Lưu kết quả ra file CSV ---\n    if evaluation_results:\n        results_df = pd.DataFrame(evaluation_results)\n        \n        # Tính toán giá trị trung bình và độ lệch chuẩn\n        summary_stats = results_df.drop('Fold', axis=1).agg(['mean', 'std'])\n        print(\"\\\\n\\\\n--- Thống kê tổng hợp (5 Folds) trên tập Test ---\")\n        print(summary_stats)\n        \n        # Tạo dòng tổng kết để thêm vào file CSV\n        summary_stats_df = summary_stats.reset_index().rename(columns={'index': 'Fold'})\n        \n        # Ghép kết quả chi tiết và kết quả tổng hợp\n        final_df_to_save = pd.concat([results_df, summary_stats_df], ignore_index=True)\n        \n        final_df_to_save.to_csv(output_filepath, index=False, float_format='%.4f')\n        print(f\"\\\\n--- HOÀN TẤT ---\")\n        print(f\"Bảng kết quả tổng hợp đã được lưu tại: {output_filepath}\")\n        \n        print(\"\\\\nNội dung file CSV:\")\n        print(final_df_to_save.to_string(index=False))\n    else:\n        print(\"\\\\nKhông có fold nào được đánh giá thành công. Không có file CSV nào được tạo.\")","metadata":{"execution":{"execution_failed":"2025-10-10T02:21:58.705Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"8e9c296a","cell_type":"code","source":"# --- Bắt đầu quy trình vẽ đường cong ROC trung bình 5-Fold ---\n\nprint(\"--- Chuẩn bị dữ liệu Test cho việc vẽ ROC ---\")\n\n# 1. Tạo Test Dataset và trích xuất nhãn thật\nTEST_TFREC_PATH = os.path.join(TFRECORD_OUTPUT_PATH, \"test.tfrec\")\nif not os.path.exists(TEST_TFREC_PATH):\n    print(f\"Lỗi: Không tìm thấy file test.tfrec tại {TEST_TFREC_PATH}. Vui lòng chạy lại ô chuẩn bị dữ liệu.\")\nelse:\n    # Tạo dataset gốc để lấy nhãn\n    test_ds_unbatched = tf.data.TFRecordDataset(TEST_TFREC_PATH)\n    test_ds_unbatched = test_ds_unbatched.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n    \n    # Tạo dataset đã được batch để lấy dự đoán\n    test_ds_batched = test_ds_unbatched.batch(GLOBAL_BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\n    print(\"Đang trích xuất nhãn từ tập test...\")\n    y_test_onehot = np.concatenate([y.numpy() for x, y in test_ds_unbatched], axis=0)\n    print(f\"Đã trích xuất xong {len(y_test_onehot)} nhãn.\")\n\n    # --- Bắt đầu quá trình lấy dự đoán và vẽ biểu đồ ---\n    y_test_binarized = y_test_onehot\n    n_classes = y_test_binarized.shape[1]\n    class_names = le.classes_\n    \n    all_y_preds_probs = []\n    print(\"\\\\nĐang tải 5 model và lấy dự đoán từ 5 folds...\")\n    for fold_number in tqdm(range(1, N_SPLITS + 1), desc=\"Processing Folds for ROC\"):\n        model_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_fold_{fold_number}.keras')\n        if not os.path.exists(model_path):\n            continue\n        \n        with strategy.scope():\n            model = tf.keras.models.load_model(\n                model_path,\n                custom_objects={\n                    'MacroF1Score': MacroF1Score,\n                    'FinalModel': FinalModel\n                }\n            )\n        \n        all_logits = []\n        for images_batch, _ in test_ds_batched:\n            batch_logits = model(images_batch, training=False)\n            all_logits.append(batch_logits.numpy())\n        \n        y_pred_logits = np.concatenate(all_logits, axis=0)\n        y_pred_probs = tf.nn.softmax(y_pred_logits).numpy()\n        all_y_preds_probs.append(y_pred_probs)\n\n    # --- Tính toán ROC và nội suy ---\n    print(\"\\\\nĐang tính toán ROC và nội suy...\")\n    tprs_per_class = [[] for _ in range(n_classes)]\n    aucs_per_class = [[] for _ in range(n_classes)]\n    mean_fpr = np.linspace(0, 1, 100)\n\n    for y_pred_probs in all_y_preds_probs:\n        for i in range(n_classes):\n            fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_pred_probs[:, i])\n            interp_tpr = np.interp(mean_fpr, fpr, tpr)\n            interp_tpr[0] = 0.0\n            tprs_per_class[i].append(interp_tpr)\n            aucs_per_class[i].append(sklearn_auc(fpr, tpr))\n\n    # --- Vẽ biểu đồ ---\n    print(\"Đang vẽ biểu đồ...\")\n    plt.figure(figsize=(12, 10))\n    colors = plt.cm.get_cmap('tab10', n_classes)\n\n    for i in range(n_classes):\n        mean_tpr = np.mean(tprs_per_class[i], axis=0)\n        mean_tpr[-1] = 1.0\n        std_tpr = np.std(tprs_per_class[i], axis=0)\n        mean_auc = np.mean(aucs_per_class[i])\n        std_auc = np.std(aucs_per_class[i])\n\n        plt.plot(mean_fpr, mean_tpr, color=colors(i),\n                 label=f'Lớp: {class_names[i]} (AUC = {mean_auc:.2f} $\\\\pm$ {std_auc:.2f})',\n                 lw=2)\n        \n        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n        plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color=colors(i), alpha=.2)\n\n    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate', fontsize=14)\n    plt.ylabel('True Positive Rate', fontsize=14)\n    plt.title('Đường cong ROC trung bình (5-Fold Cross-Validation)', fontsize=16)\n    plt.legend(loc=\"lower right\", fontsize=12)\n    plt.grid(True)\n    \n    output_filename = \"roc_curve_5_folds_average.png\"\n    output_filepath = os.path.join(KAGGLE_OUTPUT_PATH, output_filename)\n    plt.savefig(output_filepath, dpi=300)\n    print(f\"\\\\nHoàn tất! Biểu đồ đã được lưu tại: {output_filepath}\")\n    \n    plt.show()","metadata":{"execution":{"execution_failed":"2025-10-10T02:21:58.705Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"cc56407e","cell_type":"code","source":"# --- Bắt đầu quy trình phân tích Grad-CAM chi tiết cho 5 Folds ---\n\nprint(\"--- Chuẩn bị dữ liệu Test cho việc phân tích Grad-CAM ---\")\n\n# 1. Tạo Test Dataset từ file TFRecord đã được xử lý trước\n# Lưu ý: Các biến TFRECORD_OUTPUT_PATH, parse_tfrecord_fn, GLOBAL_BATCH_SIZE, AUTOTUNE\n# đã được định nghĩa ở các ô code phía trên.\nTEST_TFREC_PATH = os.path.join(TFRECORD_OUTPUT_PATH, \"test.tfrec\")\nif not os.path.exists(TEST_TFREC_PATH):\n    print(f\"Lỗi: Không tìm thấy file test.tfrec tại {TEST_TFREC_PATH}. Vui lòng chạy lại ô chuẩn bị dữ liệu.\")\nelse:\n    test_ds_batched = tf.data.TFRecordDataset(TEST_TFREC_PATH)\n    test_ds_batched = test_ds_batched.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n    test_ds_batched = test_ds_batched.batch(GLOBAL_BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\n    # --- Định nghĩa các hàm cần thiết cho Grad-CAM ---\n    target_names = le.classes_\n    grad_cam_main_path = os.path.join(KAGGLE_OUTPUT_PATH, \"grad_cam_detailed_analysis\")\n    os.makedirs(grad_cam_main_path, exist_ok=True)\n\n    def find_last_conv_layer(model):\n        for layer in reversed(model.layers):\n            if isinstance(layer, tf.keras.layers.Conv2D):\n                return layer\n            if isinstance(layer, tf.keras.Model):\n                return find_last_conv_layer(layer)\n        return None\n\n    @tf.function\n    def get_grad_cam_batched(model, img_batch):\n        if hasattr(model, 'base_model'):\n            inp = model.base_model.input\n            last_conv_layer = model.base_model.get_layer(\"top_conv\")\n            x = model.pooling(model.base_model.output)\n            x = model.dense1(x)\n            if hasattr(model, 'dense2'): # Thích ứng với head phức tạp hơn\n                x = model.dense2(x)\n            final_output = model.dense_output(x)\n            grad_model = Model(inp, [last_conv_layer.output, final_output])\n        else:\n            last_conv_layer = find_last_conv_layer(model)\n            grad_model = Model([model.inputs], [last_conv_layer.output, model.output])\n        \n        with tf.GradientTape() as tape:\n            last_conv_layer_output_value, preds = grad_model(img_batch)\n            pred_indices = tf.argmax(preds, axis=1)\n            class_channels = tf.gather(preds, pred_indices, axis=1, batch_dims=1)\n\n        grads = tape.gradient(class_channels, last_conv_layer_output_value)\n        pooled_grads = tf.reduce_mean(grads, axis=(1, 2))\n        heatmap_batch = tf.einsum('bhwc,bc->bhw', last_conv_layer_output_value, pooled_grads)\n        heatmap_batch = tf.maximum(heatmap_batch, 0)\n        max_vals = tf.reduce_max(heatmap_batch, axis=(1, 2), keepdims=True)\n        heatmap_batch = heatmap_batch / (max_vals + tf.keras.backend.epsilon())\n        return heatmap_batch, preds\n\n    def run_grad_cam_analysis_final(model, model_name, output_base_path, test_dataset):\n        print(f\"\\\\n--- Bắt đầu phân tích cho mô hình: {model_name} ---\")\n        results_by_class = { name: {'correct_heatmaps': [], 'correct_confidences': [], 'correct_images': [],\n                                    'incorrect_heatmaps': [], 'incorrect_confidences': [], 'incorrect_images': []}\n                            for name in target_names }\n\n        print(\"  - Xử lý các batch trên TPU...\")\n        for images_batch, labels_batch in tqdm(test_dataset, desc=f\"Analyzing {model_name}\"):\n            heatmap_batch, preds_batch = get_grad_cam_batched(model, images_batch)\n            y_pred_probs_batch = tf.nn.softmax(preds_batch).numpy()\n            y_pred_batch = np.argmax(y_pred_probs_batch, axis=1)\n            y_true_batch = np.argmax(labels_batch.numpy(), axis=1)\n\n            for i in range(images_batch.shape[0]):\n                y_pred, y_true = y_pred_batch[i], y_true_batch[i]\n                true_class_name = target_names[y_true]\n                \n                if y_pred == y_true:\n                    results_by_class[true_class_name]['correct_heatmaps'].append(heatmap_batch[i].numpy())\n                    results_by_class[true_class_name]['correct_confidences'].append(y_pred_probs_batch[i, y_pred])\n                    results_by_class[true_class_name]['correct_images'].append(images_batch[i].numpy())\n                else:\n                    results_by_class[true_class_name]['incorrect_heatmaps'].append(heatmap_batch[i].numpy())\n                    results_by_class[true_class_name]['incorrect_confidences'].append(y_pred_probs_batch[i, y_pred])\n                    results_by_class[true_class_name]['incorrect_images'].append(images_batch[i].numpy())\n\n        print(\"  - Đang lưu ảnh Grad-CAM và ảnh spectrogram cho các mẫu tiêu biểu...\")\n        for class_name in target_names:\n            class_output_path = os.path.join(output_base_path, class_name)\n            os.makedirs(class_output_path, exist_ok=True)\n            class_results = results_by_class[class_name]\n\n            if class_results['correct_confidences']:\n                best_idx = np.argmax(class_results['correct_confidences'])\n                image = class_results['correct_images'][best_idx]\n                heatmap = class_results['correct_heatmaps'][best_idx]\n                overlay = overlay_grad_cam(image[:, :, 0], heatmap)\n                gradcam_filename = f\"{model_name}_{class_name}_exemplar_correct_gradcam.png\"\n                plt.imsave(os.path.join(class_output_path, gradcam_filename), overlay)\n                spectrogram_filename = f\"{model_name}_{class_name}_exemplar_correct_spectrogram.png\"\n                plt.imsave(os.path.join(class_output_path, spectrogram_filename), image[:, :, 0], cmap='viridis')\n\n            if class_results['incorrect_confidences']:\n                worst_idx = np.argmax(class_results['incorrect_confidences'])\n                image = class_results['incorrect_images'][worst_idx]\n                heatmap = class_results['incorrect_heatmaps'][worst_idx]\n                overlay = overlay_grad_cam(image[:, :, 0], heatmap)\n                gradcam_filename = f\"{model_name}_{class_name}_exemplar_incorrect_gradcam.png\"\n                plt.imsave(os.path.join(class_output_path, gradcam_filename), overlay)\n                spectrogram_filename = f\"{model_name}_{class_name}_exemplar_incorrect_spectrogram.png\"\n                plt.imsave(os.path.join(class_output_path, spectrogram_filename), image[:, :, 0], cmap='viridis')\n\n    # --- VÒNG LẶP CHÍNH ĐỂ PHÂN TÍCH 5 FOLDS ---\n    teacher_models_main_path = os.path.join(grad_cam_main_path, \"teacher_models\")\n    os.makedirs(teacher_models_main_path, exist_ok=True)\n\n    for fold_number in range(1, N_SPLITS + 1):\n        print(f\"\\\\n---> Bắt đầu phân tích Grad-CAM cho Fold {fold_number}/{N_SPLITS}...\")\n        model_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_fold_{fold_number}.keras')\n        \n        if not os.path.exists(model_path):\n            print(f\"Bỏ qua Fold {fold_number}, không tìm thấy file: {model_path}\")\n            continue\n        \n        try:\n            with strategy.scope():\n                teacher_model = tf.keras.models.load_model(\n                    model_path,\n                    custom_objects={\n                        'focal_loss_fixed': focal_loss_from_logits_optimized(alpha=alpha_weights_list),\n                        'MacroF1Score': MacroF1Score \n                    }\n                )\n            \n            model_name = f\"fold_{fold_number}\"\n            fold_output_path = os.path.join(teacher_models_main_path, model_name)\n            os.makedirs(fold_output_path, exist_ok=True)\n            \n            # Gọi hàm phân tích với dataset đã được chuẩn bị\n            run_grad_cam_analysis_final(teacher_model, model_name, fold_output_path, test_ds_batched)\n        \n        except Exception as e:\n            print(f\"!!! Lỗi khi phân tích Grad-CAM cho Fold {fold_number}: {e}\")\n\n    print(\"\\\\n--- Toàn bộ quá trình phân tích Grad-CAM đã hoàn tất ---\")","metadata":{"execution":{"execution_failed":"2025-10-10T02:21:58.706Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"id":"918d90b0","cell_type":"code","source":"# --- BƯỚC TỐI ƯU & CHUYỂN ĐỔI CẢ 5 MÔ HÌNH SANG TFLITE (POST-TRAINING) ---\n\nprint(\"--- Bắt đầu quy trình chuyển đổi 5-Fold sang TFLite ---\")\n\n# Kiểm tra xem quá trình huấn luyện đã hoàn tất và có đủ kết quả chưa\nif 'fold_f1s' in locals() and len(fold_f1s) == N_SPLITS:\n    \n    # Lấy thông tin chia fold một lần để tái sử dụng\n    skf_split = list(skf.split(train_val_df, y_labels_for_split, groups_for_split))\n\n    # === BẮT ĐẦU VÒNG LẶP QUA 5 FOLDS ===\n    for fold_index in range(N_SPLITS):\n        fold_number = fold_index + 1\n        print(\"=\" * 60)\n        print(f\"--- Bắt đầu chuyển đổi cho Fold {fold_number} ---\")\n        \n        # 1. Xác định đường dẫn cho fold hiện tại\n        SAVED_MODEL_PATH = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_fold_{fold_number}')\n        TFLITE_MODEL_PATH = os.path.join(KAGGLE_OUTPUT_PATH, f'model_fold_{fold_number}_quantized.tflite')\n\n        if not os.path.exists(SAVED_MODEL_PATH):\n            print(f\"Lỗi: Không tìm thấy thư mục model tại '{SAVED_MODEL_PATH}'. Bỏ qua fold này.\")\n            continue\n\n        # 2. Tạo Representative Dataset từ tập validation của CHÍNH FOLD NÀY\n        print(f\"Đang tạo representative dataset cho Fold {fold_number}...\")\n        _, val_indices = skf_split[fold_index]\n        val_df_for_calib = train_val_df.iloc[val_indices]\n\n        def representative_data_gen():\n            for _, row in val_df_for_calib.sample(n=min(150, len(val_df_for_calib)), random_state=SEED).iterrows():\n                spectrogram = np.load(row['filepath']).astype(np.float32)\n                \n                image_tensor = tf.convert_to_tensor(spectrogram)\n                image_3d = tf.stack([image_tensor]*3, axis=-1)\n                image_resized = tf.image.resize(image_3d, [INPUT_SHAPE[0], INPUT_SHAPE[1]])\n                min_val = tf.reduce_min(image_resized)\n                max_val = tf.reduce_max(image_resized)\n                image_scaled_01 = (image_resized - min_val) / (max_val - min_val + 1e-7)\n                image_scaled_255 = image_scaled_01 * 255.0\n                image_preprocessed = preprocess_input(image_scaled_255)\n                \n                yield [tf.expand_dims(image_preprocessed, axis=0)]\n\n        # 3. Chuyển đổi và Lượng tử hóa\n        print(f\"Đang chuyển đổi mô hình của Fold {fold_number}...\")\n        converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_PATH)\n        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n        converter.representative_dataset = representative_data_gen\n        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n        \n        tflite_quant_model = converter.convert()\n\n        # 4. Lưu file TFLite\n        with open(TFLITE_MODEL_PATH, 'wb') as f:\n            f.write(tflite_quant_model)\n        \n        print(f\"Đã lưu thành công model TFLite cho Fold {fold_number} tại: {TFLITE_MODEL_PATH}\")\n        print(f\"Kích thước file: {len(tflite_quant_model) / (1024 * 1024):.2f} MB\")\n\n    print(\"=\" * 60)\n    print(\"\\\\n Hoàn tất chuyển đổi cho cả 5 mô hình!\")\n\nelse:\n    print(\"Lỗi: Không tìm thấy kết quả của 5 fold ('fold_f1s'). Vui lòng chạy ô huấn luyện trước khi chạy ô này.\")","metadata":{"execution":{"execution_failed":"2025-10-10T02:21:58.706Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"completed"},"tags":[]},"outputs":[],"execution_count":null}]}