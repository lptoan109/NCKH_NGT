{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.18","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":12870874,"sourceType":"datasetVersion","datasetId":8141736}],"dockerImageVersionId":31091,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 0.1. Cài đặt các thư viện cần thiết\n!pip install -q fpdf2 noisereduce librosa tensorflow scikit-learn matplotlib seaborn pytz PyDrive2 ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CÀI ĐẶT & CẤU HÌNH (SETUP & CONFIGURATION)\n# 0.2. Import thư viện\nimport os\nimport glob\nimport random\nimport datetime\nimport pytz\nimport shutil\nimport joblib\nimport zipfile\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\nfrom fpdf import FPDF\nfrom tqdm import tqdm\nimport librosa\nimport noisereduce as nr\nimport tensorflow as tf\nfrom tensorflow.keras import mixed_precision\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D, AveragePooling2D\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.utils import class_weight\nfrom pydrive2.auth import GoogleAuth\nfrom pydrive2.drive import GoogleDrive\nfrom kaggle_secrets import UserSecretsClient\nfrom oauth2client.service_account import ServiceAccountCredentials\nfrom tensorflow.keras.regularizers import l2\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.metrics import roc_curve, auc as sklearn_auc\nfrom sklearn.preprocessing import label_binarize\nfrom itertools import cycle\nmixed_precision.set_global_policy('mixed_bfloat16')\n\ntry:\n    # Cố gắng kết nối với TPU bằng cách chỉ định tpu='local'\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\n    print('Đã tìm thấy TPU Resolver.')\n    \n    # Kết nối và khởi tạo hệ thống TPU\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    print('Đã khởi tạo hệ thống TPU.')\n\n    # Tạo strategy\n    strategy = tf.distribute.TPUStrategy(tpu)\n    print('THÀNH CÔNG: Đã tạo TPUStrategy!')\n    print(f'Số lượng nhân (replicas): {strategy.num_replicas_in_sync}')\n    \nexcept (ValueError, RuntimeError) as e:\n    # Nếu vẫn không tìm thấy TPU, tự động chuyển về chiến lược mặc định\n    print(f'Lỗi kết nối TPU: {e}')\n    print('Không tìm thấy TPU. Sử dụng chiến lược mặc định cho GPU/CPU.')\n    strategy = tf.distribute.get_strategy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# THIẾT LẬP CẤU HÌNH \n# --- Các cấu hình cơ bản ---\nSEED = 42\ndef set_seed(seed_value):\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    #os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    tf.random.set_seed(seed_value)\nset_seed(SEED)\n\nKAGGLE_PROCESSED_DATA_PATH = \"/kaggle/input/ngt-spectrogram-id/\"\nKAGGLE_OUTPUT_PATH = \"/kaggle/working/output_results\"\nos.makedirs(KAGGLE_OUTPUT_PATH, exist_ok=True)\n\nCLASSES_TO_TRAIN = ['covid', 'asthma', 'healthy', 'tuberculosis']\nALL_CLASSES = ['healthy', 'asthma', 'covid', 'tuberculosis']\nN_SPLITS = 5\nTEST_SPLIT_RATIO = 0.15\nUSE_DATA_AUGMENTATION = True # Bật/tắt augmentation ở đây\nUSE_FOCAL_LOSS = True\n\nMODEL_ID = f'EfficienetB0_CV_TPU'\nMIN_DELTA = 1e-4\nSHUFFLE_BUFFER_SIZE = 2048 \nGAMMA = 2.0 # Giữ nguyên giá trị tiêu chuẩn\n\n# --- CÁC THAY ĐỔI CHÍNH ---\nLEARNING_RATE = 5e-6              # Thay đổi: Giảm LR để ổn định hơn\nWEIGHT_DECAY = 3e-3               # Thay đổi: Tăng để chống overfitting mạnh hơn\n\n# Cấu hình cho Cross-Validation\nTOTAL_EPOCHS = 180                # Giữ nguyên tổng số epochs tối đa\nWARMUP_EPOCHS = 3                 # Thay đổi: Rút ngắn Warmup cho hiệu quả\nRESTART_CYCLE_1_EPOCHS = 20       # Thay đổi: Chu kỳ ngắn hơn để khám phá nhiều hơn\nPATIENCE_EPOCHS = RESTART_CYCLE_1_EPOCHS + 10 # Thay đổi: Patience = 50\n\n# --- ĐỊNH NGHĨA BATCH SIZE ---\n# BATCH_SIZE này là batch size cho mỗi nhân TPU (per-replica)\nBATCH_SIZE = 32\n# Tính toán GLOBAL_BATCH_SIZE để dùng trong pipeline\n# Biến 'strategy' được lấy từ ô code đầu tiên\nGLOBAL_BATCH_SIZE = BATCH_SIZE * strategy.num_replicas_in_sync\nprint(f\"Batch size mỗi nhân: {BATCH_SIZE}\")\nprint(f\"Global batch size (tổng cộng): {GLOBAL_BATCH_SIZE}\")\n\n# INPUT_SHAPE sẽ được cập nhật lại ở ô chuẩn bị dữ liệu\nINPUT_SHAPE = (224, 224, 3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# KHỞI TẠO CÁC HÀM CẦN THIẾT (PHIÊN BẢN ĐÚNG)\n\ndef get_patient_id(filepath, class_name):\n    filename = os.path.basename(filepath)\n    if class_name.lower() in ['asthma', 'covid', 'healthy']:\n        return filename.split('_')[0]\n    elif class_name.lower() == 'tuberculosis':\n        return '_'.join(filename.split('_')[:-1]).replace('.npy', '')\n    else:\n        return filename.split('_')[0]\n\nclass MacroF1Score(tf.keras.metrics.Metric):\n    \"\"\"\n    Lớp metric để tính toán Macro F1-Score một cách chính xác trên toàn bộ epoch.\n    \"\"\"\n    def __init__(self, num_classes, name='f1_macro', **kwargs):\n        super(MacroF1Score, self).__init__(name=name, **kwargs)\n        self.num_classes = num_classes\n        # Tạo các biến để lưu trữ các giá trị TP, FP, FN qua các batch\n        self.true_positives = self.add_weight(name='tp', shape=(num_classes,), initializer='zeros')\n        self.false_positives = self.add_weight(name='fp', shape=(num_classes,), initializer='zeros')\n        self.false_negatives = self.add_weight(name='fn', shape=(num_classes,), initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        # Chuyển đổi đầu ra của model (logits) và nhãn thật\n        y_pred_labels = tf.argmax(tf.nn.softmax(y_pred), axis=1)\n        y_true_labels = tf.argmax(y_true, axis=1)\n        \n        # Tính ma trận nhầm lẫn cho batch hiện tại\n        cm = tf.math.confusion_matrix(y_true_labels, y_pred_labels, num_classes=self.num_classes, dtype=tf.float32)\n        \n        # Từ ma trận nhầm lẫn, tính TP, FP, FN cho mỗi lớp\n        tp = tf.linalg.diag_part(cm)\n        fp = tf.reduce_sum(cm, axis=0) - tp\n        fn = tf.reduce_sum(cm, axis=1) - tp\n        \n        # Cập nhật các biến trạng thái\n        self.true_positives.assign_add(tp)\n        self.false_positives.assign_add(fp)\n        self.false_negatives.assign_add(fn)\n\n    def result(self):\n        # Tính toán Precision, Recall từ các giá trị đã tích lũy\n        precision = self.true_positives / (self.true_positives + self.false_positives + tf.keras.backend.epsilon())\n        recall = self.true_positives / (self.true_positives + self.false_negatives + tf.keras.backend.epsilon())\n        \n        # Tính F1-Score cho mỗi lớp\n        f1 = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n        \n        # Lấy trung bình cộng (macro)\n        macro_f1 = tf.reduce_mean(f1)\n        return macro_f1\n\n    def reset_state(self):\n        # Reset các biến trạng thái về 0 ở đầu mỗi epoch\n        self.true_positives.assign(tf.zeros(self.num_classes))\n        self.false_positives.assign(tf.zeros(self.num_classes))\n        self.false_negatives.assign(tf.zeros(self.num_classes))\ndef parse_tfrecord_fn(example):\n    \"\"\"Hàm đọc và xử lý một mẫu từ file TFRecord cho EfficientNet.\"\"\"\n    feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'label': tf.io.FixedLenFeature([], tf.int64),\n    }\n    example = tf.io.parse_single_example(example, feature_description)\n    image = tf.io.parse_tensor(example['image'], out_type=tf.float32)\n    image = tf.reshape(image, (256, 126))\n    \n    # --- THAY ĐỔI QUAN TRỌNG ---\n    # 1. Stack 3 kênh TRƯỚC KHI resize để tạo thành ảnh 3D\n    image_3d = tf.stack([image, image, image], axis=-1)\n    \n    # 2. Bây giờ mới resize ảnh 3D này về kích thước mong muốn\n    image_resized = tf.image.resize(image_3d, [224, 224])\n    \n    # 3. Sử dụng hàm tiền xử lý chuyên dụng của EfficientNet\n    image_preprocessed = preprocess_input(image_resized)\n    \n    label_encoded = tf.cast(example['label'], tf.int32)\n    label_onehot = tf.one_hot(label_encoded, depth=len(ALL_CLASSES))\n    \n    return image_preprocessed, label_onehot\n\ndef augment(spectrogram, label):\n    spectrogram = spec_augment(spectrogram)\n    return spectrogram, label\n\ndef focal_loss_from_logits_optimized(alpha, gamma=2.0):\n    \"\"\"\n    Tạo ra hàm Focal Loss phiên bản đầy đủ và sạch sẽ.\n    \n    Args:\n        alpha: Một list hoặc array chứa trọng số cho mỗi lớp.\n        gamma: Hệ số tập trung, mặc định là 2.0.\n    \"\"\"\n    # Chuyển alpha sang dạng tensor để tính toán\n    alpha = tf.constant(alpha, dtype=tf.float32)\n\n    def focal_loss_fixed(y_true, y_pred):\n        y_true = tf.cast(y_true, 'float32')\n        y_pred = tf.cast(y_pred, 'float32')\n        \n        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n        probs = tf.nn.softmax(y_pred)\n        pt = tf.reduce_sum(y_true * probs, axis=-1)\n        focal_term = (1.0 - pt) ** gamma\n        alpha_t = tf.reduce_sum(y_true * alpha, axis=-1)\n        loss = alpha_t * focal_term * cross_entropy\n        \n        return tf.reduce_mean(loss)\n        \n    return focal_loss_fixed\n\ndef spec_augment(spectrogram, time_masking_para=40, frequency_masking_para=30, num_time_masks=1, num_freq_masks=1):\n    spectrogram_aug = spectrogram\n    freq_bins = tf.shape(spectrogram)[1] # Sửa: Lấy chiều tần số từ shape 4D\n    time_steps = tf.shape(spectrogram)[2] # Sửa: Lấy chiều thời gian từ shape 4D\n    \n    for _ in range(num_freq_masks):\n        f = tf.random.uniform(shape=(), minval=0, maxval=frequency_masking_para, dtype=tf.int32)\n        f0 = tf.random.uniform(shape=(), minval=0, maxval=freq_bins - f, dtype=tf.int32)\n        freq_mask_1d = tf.concat([tf.ones((f0,), dtype=spectrogram.dtype), tf.zeros((f,), dtype=spectrogram.dtype), tf.ones((freq_bins - f0 - f,), dtype=spectrogram.dtype)], axis=0)\n        freq_mask_4d = tf.reshape(freq_mask_1d, (1, freq_bins, 1, 1)) # Sửa: Reshape thành 4D để broadcast\n        spectrogram_aug *= freq_mask_4d\n        \n    for _ in range(num_time_masks):\n        t = tf.random.uniform(shape=(), minval=0, maxval=time_masking_para, dtype=tf.int32)\n        t0 = tf.random.uniform(shape=(), minval=0, maxval=time_steps - t, dtype=tf.int32)\n        time_mask_1d = tf.concat([tf.ones((t0,), dtype=spectrogram.dtype), tf.zeros((t,), dtype=spectrogram.dtype), tf.ones((time_steps - t0 - t,), dtype=spectrogram.dtype)], axis=0)\n        time_mask_4d = tf.reshape(time_mask_1d, (1, 1, time_steps, 1)) # Sửa: Reshape thành 4D để broadcast\n        spectrogram_aug *= time_mask_4d\n        \n    return spectrogram_aug\n\n# HÀM CREATE_MODEL PHIÊN BẢN ĐÚNG VÀ ĐƠN GIẢN\nclass FinalModel(tf.keras.Model):\n    def __init__(self, input_shape, num_classes):\n        super(FinalModel, self).__init__()\n        \n        # --- SỬ DỤNG EfficientNetB0 LÀM MÔ HÌNH NỀN ---\n        self.base_model = EfficientNetB0(\n            weights='imagenet',      # Dùng trọng số tiền huấn luyện\n            include_top=False,       # Bỏ lớp phân loại cuối cùng\n            input_shape=input_shape\n        )\n\n        # Đóng băng các lớp như bình thường\n        # (Bạn có thể cần thử nghiệm số lớp đóng băng cho EfficientNet)\n        num_layers = len(self.base_model.layers)\n        for layer in self.base_model.layers[:int(num_layers * 0.7)]: # Ví dụ: đóng băng 70%\n             layer.trainable = False\n        \n        # Các lớp còn lại giữ nguyên\n        self.pooling = GlobalAveragePooling2D()\n        self.dropout = Dropout(0.5)\n        self.dense_output = Dense(num_classes,\n                                  activation='linear',\n                                  kernel_regularizer=l2(0.001),\n                                  dtype='float32')\n\n    def call(self, inputs, training=None):\n        x = self.base_model(inputs, training=training)\n        x = self.pooling(x)\n        x = self.dropout(x, training=training)\n        outputs = self.dense_output(x)\n        return outputs\n\ndef load_data_from_df(df):\n    X, y = [], []\n    for _, row in df.iterrows():\n        X.append(np.load(row['filepath']))\n        y.append(row['label'])\n    return np.array(X), np.array(y)\n\ndef get_grad_cam_final(model, img_array, last_conv_layer_name, pred_index=None):\n    global strategy\n    \n    with strategy.scope():\n        grad_model = Model(\n            [model.inputs[0]], \n            [model.get_layer(last_conv_layer_name).output, model.output]\n        )\n\n    with tf.GradientTape() as tape:\n        # --- THAY ĐỔI QUAN TRỌNG ---\n        # Thêm training=False để chỉ định rõ đây là chế độ inference\n        last_conv_layer_output, preds = grad_model(tf.cast(img_array, tf.float32), training=False)\n        \n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    \n    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + tf.keras.backend.epsilon())\n    \n    return heatmap.numpy()\n\ndef overlay_grad_cam(spec, heatmap, alpha=0.6):\n    heatmap_resized = tf.image.resize(heatmap[..., np.newaxis], (spec.shape[0], spec.shape[1]))\n    heatmap_resized = np.uint8(255 * heatmap_resized)\n    jet = plt.cm.get_cmap(\"jet\")\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap_resized.squeeze()]\n    spec_display = np.stack([spec]*3, axis=-1)\n    spec_display = (spec_display - spec_display.min()) / (spec_display.max() - spec_display.min())\n    superimposed_img = jet_heatmap * alpha + spec_display\n    superimposed_img = np.clip(superimposed_img, 0, 1)\n    return superimposed_img\n\nclass PDFReport(FPDF):\n    def header(self):\n        self.set_font('Arial', 'B', 12)\n        self.cell(0, 10, 'BAO CAO KET QUA HUAN LUYEN MO HINH AI', 0, 1, 'C')\n        self.ln(10)\n    def footer(self):\n        self.set_y(-15)\n        self.set_font('Arial', 'I', 8)\n        self.cell(0, 10, f'Trang {self.page_no()}', 0, 0, 'C')\n    def chapter_title(self, title):\n        self.set_font('Arial', 'B', 12)\n        self.cell(0, 10, title, 0, 1, 'L')\n        self.ln(5)\n    def chapter_body(self, content):\n        self.set_font('Arial', '', 10)\n        safe_content = content.encode('latin-1', 'replace').decode('latin-1')\n        self.multi_cell(0, 5, safe_content)\n        self.ln()\n    def add_image_section(self, title, img_path):\n        self.chapter_title(title)\n        if os.path.exists(img_path):\n            self.image(img_path, x=None, y=None, w=180)\n            self.ln(5)\n        else:\n            self.chapter_body(f\"Khong tim thay hinh anh: {img_path}\")\n\ndef authenticate_gdrive():\n    user_secrets = UserSecretsClient()\n    secret_value = user_secrets.get_secret(\"google_service_account_key\")\n    with open(\"service_account.json\", \"w\") as f:\n        f.write(secret_value)\n    scope = [\"https://www.googleapis.com/auth/drive\"]\n    gauth = GoogleAuth()\n    gauth.credentials = ServiceAccountCredentials.from_json_keyfile_name(\"service_account.json\", scope)\n    drive = GoogleDrive(gauth)\n    return drive\n\ndef upload_folder_to_drive(drive, folder_path, parent_folder_id):\n    folder_name = os.path.basename(folder_path)\n    print(f\"Đang tạo thư mục '{folder_name}' trên Google Drive...\")\n    folder_metadata = {'title': folder_name, 'mimeType': 'application/vnd.google-apps.folder', 'parents': [{'id': parent_folder_id}]}\n    folder = drive.CreateFile(folder_metadata)\n    folder.Upload()\n    \n    print(f\"Bắt đầu tải nội dung của '{folder_name}'...\")\n    for item in tqdm(os.listdir(folder_path), desc=f\"Uploading {folder_name}\"):\n        item_path = os.path.join(folder_path, item)\n        if os.path.isfile(item_path):\n            gfile = drive.CreateFile({'title': item, 'parents': [{'id': folder['id']}]})\n            gfile.SetContentFile(item_path)\n            gfile.Upload(param={'supportsTeamDrives': True})\n        elif os.path.isdir(item_path):\n            upload_folder_to_drive(drive, item_path, folder['id'])\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy()\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef serialize_example(image, label):\n    \"\"\"Creates a tf.train.Example message ready to be written to a file.\"\"\"\n    feature = {\n        'image': _bytes_feature(tf.io.serialize_tensor(image)),\n        'label': _int64_feature(label)\n    }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()\nclass LearningRateLogger(tf.keras.callbacks.Callback):\n    def on_epoch_begin(self, epoch, logs=None):\n        current_lr = tf.keras.backend.get_value(self.model.optimizer.lr)\n        print(f\"\\nEpoch {epoch+1}: Learning Rate is {current_lr:.2e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CHUẨN BỊ DỮ LIỆU VÀ TẠO TFRECORD\nsuspicious_files_to_remove = [\n    '/kaggle/input/ngt-spectrogram-id/healthy/P0030101_123370_Dkwg3F7jMGaR7kbc-seg2.npy',\n    '/kaggle/input/ngt-spectrogram-id/covid/P0032202_15897_PcbyJQWemBfghUYp-seg2.npy',\n    '/kaggle/input/ngt-spectrogram-id/covid/P0027142_5701_hupBI5CxKMNCfe8b-seg1.npy',\n    '/kaggle/input/ngt-spectrogram-id/covid/P0056214_89533_0WsmNRSKuQFGodg1-seg1.npy',\n]\n# --- BƯỚC 1: TẢI VÀ PHÂN CHIA DỮ LIỆU BAN ĐẦU ---\nprint(\"Bắt đầu chuẩn bị và phân chia dữ liệu...\")\nall_files_to_split = []\nfor class_name in ALL_CLASSES:\n    source_dir = os.path.join(KAGGLE_PROCESSED_DATA_PATH, class_name)\n    if os.path.exists(source_dir):\n        files = glob.glob(os.path.join(source_dir, '*.npy'))\n        for f in files:\n            all_files_to_split.append({'filepath': f, 'label': class_name})\n\nall_data_df = pd.DataFrame(all_files_to_split)\nall_data_df['patient_id'] = all_data_df.apply(lambda row: get_patient_id(row['filepath'], row['label']), axis=1)\n\nprint(f\"Số lượng mẫu ban đầu: {len(all_data_df)}\")\nall_data_df = all_data_df[~all_data_df['filepath'].isin(suspicious_files_to_remove)].reset_index(drop=True)\nprint(f\"Số lượng mẫu sau khi lọc bỏ file 'im lặng': {len(all_data_df)}\")\n\nprint(\"Tách tập Test cuối cùng (Hold-out set)...\")\npatient_ids = all_data_df['patient_id'].unique()\nnp.random.shuffle(patient_ids)\ntest_patient_count = int(len(patient_ids) * TEST_SPLIT_RATIO)\ntest_patients = patient_ids[:test_patient_count]\ntrain_val_patients = patient_ids[test_patient_count:]\n\ntest_df = all_data_df[all_data_df['patient_id'].isin(test_patients)].reset_index(drop=True)\ntrain_val_df = all_data_df[all_data_df['patient_id'].isin(train_val_patients)].reset_index(drop=True)\n\nprint(f\"Đã tách: {len(train_val_df)} mẫu cho Train/Validation (CV) và {len(test_df)} mẫu cho Test cuối cùng.\")\n\n# --- BƯỚC 2: KHỞI TẠO LABEL ENCODER VÀ STANDARD SCALER ---\nle = LabelEncoder().fit(ALL_CLASSES)\n# Cập nhật INPUT_SHAPE từ một file mẫu\nsample_spec = np.load(train_val_df['filepath'][0])\nprint(f\"Kích thước input được cập nhật: {INPUT_SHAPE}\")\n\n\n# --- BƯỚC 3: CHUYỂN ĐỔI DỮ LIỆU SANG ĐỊNH DẠNG TFRECORD ---\nTFRECORD_OUTPUT_PATH = \"/kaggle/working/tfrecords\"\nos.makedirs(TFRECORD_OUTPUT_PATH, exist_ok=True)\nprint(f\"Bắt đầu chuyển đổi dữ liệu sang TFRecord tại: {TFRECORD_OUTPUT_PATH}\")\n\nall_dfs = {'train_val': train_val_df, 'test': test_df}\n\nfor df_name, df in all_dfs.items():\n    print(f\"--- Đang xử lý tập {df_name} ---\")\n    tfrecord_path = os.path.join(TFRECORD_OUTPUT_PATH, f\"{df_name}.tfrec\")\n    \n    with tf.io.TFRecordWriter(tfrecord_path) as writer:\n        # Sử dụng tqdm tiêu chuẩn để tránh lỗi ImportError\n        for _, row in tqdm(df.iterrows(), total=len(df), desc=f\"Creating {df_name}.tfrec\"):\n            spectrogram = np.load(row['filepath']).astype(np.float32)\n            label_encoded = le.transform([row['label']])[0]\n            \n            example = serialize_example(spectrogram, label_encoded)\n            writer.write(example)\n            \nprint(\"\\nChuyển đổi sang TFRecord hoàn tất!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# HUẤN LUYỆN MÔ HÌNH Cross-Validation\n\n# --- BƯỚC 1: KHỞI TẠO CÁC BIẾN CẦN THIẾT ---\nprint(\"Đang khởi tạo các biến cho Cross-Validation...\")\nAUTOTUNE = tf.data.AUTOTUNE\nskf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\ncv_data_to_split = train_val_df[train_val_df['label'].isin(CLASSES_TO_TRAIN)]\nX_cv_paths = cv_data_to_split['filepath'].values\ny_cv_labels = le.transform(cv_data_to_split['label'])\ngroups_cv = cv_data_to_split['patient_id'].values\n\nfold_accuracies, fold_losses, fold_aucs, fold_f1s = [], [], [], []\n\nprint(\"Đang tính toán trọng số alpha cho Focal Loss...\")\nclass_weights_array = class_weight.compute_class_weight('balanced', classes=np.unique(y_cv_labels), y=y_cv_labels)\nalpha_weights_list = class_weights_array.tolist()\nprint(\"Trọng số Alpha được tính toán:\")\nfor i, w in enumerate(alpha_weights_list):\n    class_name = le.inverse_transform([i])[0]\n    print(f\"- Lớp '{class_name}': {w:.2f}\")\n\n# --- BƯỚC 2: BẮT ĐẦU VÒNG LẶP CROSS-VALIDATION ---\nLOCAL_TFRECORD_PATH = TFRECORD_OUTPUT_PATH\nTRAIN_VAL_TFREC = os.path.join(LOCAL_TFRECORD_PATH, 'train_val.tfrec')\nprint(f\"Sẵn sàng đọc dữ liệu TFRecord từ: {TRAIN_VAL_TFREC}\")\n\nfor fold, (train_indices, val_indices) in enumerate(skf.split(X_cv_paths, y_cv_labels, groups_cv)):\n    fold_number = fold + 1\n    print(\"-\" * 50 + f\"\\nBắt đầu Fold {fold_number}/{N_SPLITS}\\n\" + \"-\" * 50)\n    # TÍNH TOÁN CÁC BƯỚC CHO SCHEDULER\n    # 1. Tạo pipeline dữ liệu trước\n    train_indices_tf = tf.constant(train_indices, dtype=tf.int64)\n    val_indices_tf = tf.constant(val_indices, dtype=tf.int64)\n    full_ds = tf.data.TFRecordDataset(TRAIN_VAL_TFREC).enumerate()\n    train_ds = full_ds.filter(lambda i, data: tf.reduce_any(i == train_indices_tf)).map(lambda i, data: data)\n    val_ds = full_ds.filter(lambda i, data: tf.reduce_any(i == val_indices_tf)).map(lambda i, data: data)\n    train_ds = train_ds.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n    val_ds = val_ds.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n    train_ds = train_ds.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE).repeat().batch(GLOBAL_BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n    val_ds = val_ds.cache().batch(GLOBAL_BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n    \n    # 2. Bây giờ mới tính toán steps_per_epoch\n    steps_per_epoch = len(train_indices) // GLOBAL_BATCH_SIZE\n    validation_steps = len(val_indices) // GLOBAL_BATCH_SIZE\n    print(f\"Số bước mỗi epoch: {steps_per_epoch} | Số bước validation: {validation_steps}\")\n\n\n    # --- TẠO MODEL VÀ LOSS FUNCTION ---\n    with strategy.scope():\n        model = FinalModel(input_shape=INPUT_SHAPE, num_classes=len(ALL_CLASSES))\n        if USE_FOCAL_LOSS:\n            loss_function = focal_loss_from_logits_optimized(alpha=alpha_weights_list, gamma=GAMMA)\n        else:\n            loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n\n    # --- GIAI ĐOẠN 1: HUẤN LUYỆN CÁC LỚP CUỐI (HEAD TRAINING) ---\n    print(\"\\n--- Bắt đầu Giai đoạn 1: Huấn luyện các lớp cuối ---\")\n    with strategy.scope():\n        # Đóng băng toàn bộ mô hình nền\n        model.base_model.trainable = False\n        # Compile với learning rate lớn hơn (ví dụ 1e-3)\n        optimizer_head = tf.keras.optimizers.AdamW(learning_rate=1e-3, weight_decay=WEIGHT_DECAY)\n        model.compile(optimizer=optimizer_head, loss=loss_function, metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n        # Huấn luyện trong 5 epochs\n        model.fit(train_ds, validation_data=val_ds, epochs=5,\n              steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, verbose=1)\n\n    # --- GIAI ĐOẠN 2: WARMUP VÀ HUẤN LUYỆN CHÍNH VỚI RESTART ---\n    print(\"\\n--- Bắt đầu Giai đoạn 2: Fine-tuning với Warmup & Restarts ---\")\n\n    # 1. THIẾT LẬP CÁC SIÊU THAM SỐ MỚI CHO LỊCH TRÌNH\n    with strategy.scope():\n        model.base_model.trainable = True\n        f1_macro = MacroF1Score(num_classes=len(ALL_CLASSES), name='f1_macro')\n\n        # 2. GIAI ĐOẠN 2A: WARMUP\n        print(f\"\\n--- Giai đoạn 2A: Bắt đầu Warmup trong {WARMUP_EPOCHS} epochs ---\")\n        warmup_lr = LEARNING_RATE / 10 # Bắt đầu với LR rất thấp\n        optimizer_warmup = tf.keras.optimizers.AdamW(learning_rate=warmup_lr, weight_decay=WEIGHT_DECAY)\n        model.compile(optimizer=optimizer_warmup, loss=loss_function, metrics=['accuracy', f1_macro])\n\n        model.fit(\n            train_ds, validation_data=val_ds, epochs=WARMUP_EPOCHS,\n            steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, verbose=1\n        )\n\n        # 3. GIAI ĐOẠN 2B: HUẤN LUYỆN CHÍNH VỚI COSINE DECAY RESTARTS\n        # KHỞI TẠO COSINE DECAY SCHEDULER\n        print(f\"\\n--- Giai đoạn 2B: Bắt đầu huấn luyện chính với CosineDecayRestarts ---\")\n        first_decay_steps = RESTART_CYCLE_1_EPOCHS * steps_per_epoch\n        lr_scheduler = tf.keras.optimizers.schedules.CosineDecayRestarts(\n            initial_learning_rate=LEARNING_RATE,\n            first_decay_steps=first_decay_steps,\n            t_mul=2.0, m_mul=0.9\n        )\n        optimizer_finetune = tf.keras.optimizers.AdamW(learning_rate=lr_scheduler, weight_decay=WEIGHT_DECAY)\n        model.compile(optimizer=optimizer_finetune, loss=loss_function, metrics=['accuracy', tf.keras.metrics.AUC(name='auc'), f1_macro])\n    \n    callbacks = [\n        EarlyStopping(\n            monitor='val_f1_macro', mode='max', patience=PATIENCE_EPOCHS,\n            restore_best_weights=True, min_delta=MIN_DELTA, verbose=1\n        )\n        LearningRateLogger()\n    ]\n\n    history = model.fit(\n        train_ds, validation_data=val_ds, epochs=TOTAL_EPOCHS,\n        initial_epoch=WARMUP_EPOCHS,\n        steps_per_epoch=steps_per_epoch, validation_steps=validation_steps,\n        callbacks=callbacks, verbose=1\n    )\n    # Tạo đường dẫn và tên file để lưu model\n    model_save_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_fold_{fold_number}.keras')\n    # Lưu lại toàn bộ mô hình (kiến trúc + trọng số)\n    model.save(model_save_path)\n    # In ra thông báo để xác nhận\n    print(f\"Đã lưu mô hình cho Fold {fold_number} tại: {model_save_path}\")\n\n    # --- VẼ BIỂU ĐỒ VÀ ĐÁNH GIÁ ---\n    print(\"Đang tạo và lưu biểu đồ huấn luyện...\")\n    plt.figure(figsize=(18, 7))\n    plt.suptitle(f'Training Metrics for Fold {fold_number}', fontsize=16)\n    \n    # --- Biểu đồ cho các chỉ số (Accuracy, AUC, F1-Macro) ---\n    plt.subplot(1, 2, 1)\n    # Vẽ các chỉ số của tập Train\n    plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue', linestyle='-')\n    plt.plot(history.history['auc'], label='Training AUC', color='green', linestyle='-')\n    plt.plot(history.history['f1_macro'], label='Training F1-Macro', color='red', linestyle='-')\n    \n    # Vẽ các chỉ số của tập Validation\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='blue', linestyle='--')\n    plt.plot(history.history['val_auc'], label='Validation AUC', color='green', linestyle='--')\n    plt.plot(history.history['val_f1_macro'], label='Validation F1-Macro', color='red', linestyle='--')\n    \n    # Cập nhật lại tiêu đề và nhãn\n    plt.title('Biểu đồ các chỉ số (Accuracy, AUC, F1-Macro)')\n    plt.xlabel('Epoch')\n    plt.ylabel('Giá trị')\n    plt.legend(loc='lower right')\n    plt.grid(True)\n    \n    # --- Biểu đồ cho Loss ---\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Training Loss', color='orange')\n    plt.plot(history.history['val_loss'], label='Validation Loss', color='purple')\n    plt.title('Biểu đồ Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n    plt.grid(True)\n    \n    # Lưu và đóng hình ảnh\n    plot_filename = f'fold_{fold_number}_metrics.png'\n    plot_filepath = os.path.join(KAGGLE_OUTPUT_PATH, plot_filename)\n    plt.savefig(plot_filepath)\n    plt.close()\n    \n    print(f\"Đã lưu biểu đồ cho Fold {fold_number} tại: {plot_filepath}\")\n    \n    # THÊM 4: Sửa lại model.evaluate để nhận đủ 4 giá trị\n    loss, accuracy, auc, f1 = model.evaluate(val_ds, verbose=0)\n    print(f\"Fold {fold_number} - Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}, Validation AUC: {auc:.4f}, Validation F1-Macro: {f1:.4f}\")\n    \n    fold_aucs.append(auc)\n    fold_losses.append(loss)\n    fold_accuracies.append(accuracy)\n    fold_f1s.append(f1) # Thêm lưu trữ F1\n\n    # THÊM 5: Sửa lại câu lệnh print cuối cùng\n    print(\"=\" * 50 + \"\\nKết quả Cross-Validation:\\n\" \n      + f\"Validation Accuracy trung bình: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\\n\"\n      + f\"Validation Loss trung bình: {np.mean(fold_losses):.4f} +/- {np.std(fold_losses):.4f}\\n\"\n      + f\"Validation AUC trung bình: {np.mean(fold_aucs):.4f} +/- {np.std(fold_aucs):.4f}\\n\"\n      + f\"Validation F1-Macro trung bình: {np.mean(fold_f1s):.4f} +/- {np.std(fold_f1s):.4f}\\n\" # Thêm dòng này\n      + \"=\" * 50)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ĐÁNH GIÁ MÔ HÌNH VÀ VẼ CÁC SƠ ĐỒ (PHIÊN BẢN HOÀN CHỈNH)\nprint(\"\\nĐang đánh giá mô hình cuối cùng trên tập Test (Hold-out)...\")\n\n# --- BƯỚC 1: TẠO KIẾN TRÚC, TẢI TRỌNG SỐ VÀ BIÊN DỊCH LẠI MODEL ---\n\nprint(\"Đang tạo lại kiến trúc model và tải trọng số đã lưu...\")\nwith strategy.scope():\n    # Tạo một kiến trúc model mới y hệt lúc huấn luyện\n    final_model = FinalModel(input_shape=INPUT_SHAPE, num_classes=len(ALL_CLASSES))\n    # THÊM BƯỚC BUILD: Xây dựng model với input shape đã biết\n    # (None, *INPUT_SHAPE) để bao gồm cả chiều batch (batch dimension)\n    final_model.build(input_shape=(None, *INPUT_SHAPE))\n\n    # Bây giờ mới nạp trọng số\n    final_model.load_weights(model_checkpoint_path)\n    \n    # Tải các trọng số đã được huấn luyện vào kiến trúc mới này\n    final_model.load_weights(model_checkpoint_path)\n\n    # --- THÊM VÀO ĐÂY: BIÊN DỊCH LẠI MODEL ---\n    # Model cần được compile với đúng các thiết lập như khi huấn luyện\n    # để có thể tính toán loss và metrics.\n    print(\"Đang biên dịch lại model...\")\n    if USE_FOCAL_LOSS:\n        loss_function = focal_loss_from_logits_optimized(alpha=final_alpha_weights_list, gamma=GAMMA)\n    else:\n        loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n        \n    final_optimizer = tf.keras.optimizers.AdamW(learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n    \n    final_model.compile(optimizer=final_optimizer, \n                        loss=loss_function, \n                        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n\nprint(\"Tải và biên dịch model cuối cùng hoàn tất.\")\n\n\n# --- BƯỚC 2: TẠO PIPELINE DỮ LIỆU CHO TẬP TEST ---\nTEST_TFREC = os.path.join(LOCAL_TFRECORD_PATH, 'test.tfrec')\nprint(f\"Sử dụng dữ liệu test từ: {TEST_TFREC}\")\n\ntest_ds = tf.data.TFRecordDataset(TEST_TFREC)\ntest_ds = test_ds.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.batch(GLOBAL_BATCH_SIZE, drop_remainder=True)\ntest_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n\n\n# --- BƯỚC 3: ĐÁNH GIÁ VÀ DỰ ĐOÁN TRÊN PIPELINE ---\nprint(\"Đang đánh giá trên tập test...\")\nloss, accuracy, auc = final_model.evaluate(test_ds, verbose=1)\nprint(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}, Test AUC: {auc:.4f}\")\n\nprint(\"Đang dự đoán trên tập test...\")\ny_pred_logits = final_model.predict(test_ds, verbose=1) # Đổi tên thành logits để rõ ràng hơn\ny_pred_encoded = np.argmax(y_pred_logits, axis=1)\n\n# Lấy nhãn thật từ dataframe\nfinal_test_df = test_df[test_df['label'].isin(CLASSES_TO_TRAIN)]\ny_test_labels = final_test_df['label'].values\ny_test_encoded = le.transform(y_test_labels)\ny_test_encoded = y_test_encoded[:len(y_pred_encoded)]\n\ntrained_class_indices = np.unique(y_test_encoded)\ntarget_names_trained = le.inverse_transform(trained_class_indices)\n\n\n# --- BƯỚC 4: TÍNH TOÁN VÀ TRÍCH XUẤT CÁC CHỈ SỐ CHI TIẾT ---\n# Sử dụng output_dict=True để lấy kết quả dưới dạng dictionary\nreport_dict = classification_report(y_test_encoded, y_pred_encoded, target_names=target_names_trained, labels=trained_class_indices, output_dict=True)\nreport_text = classification_report(y_test_encoded, y_pred_encoded, target_names=target_names_trained, labels=trained_class_indices)\n\nprint(\"\\nClassification Report:\\n\", report_text)\n\n# Ví dụ cách trích xuất các chỉ số bạn cần cho báo cáo:\nmacro_f1 = report_dict['macro avg']['f1-score']\nweighted_f1 = report_dict['weighted avg']['f1-score']\nasthma_recall = report_dict['asthma']['recall']\n\nprint(f\"\\\\nCác chỉ số riêng lẻ:\")\nprint(f\"- Macro F1-Score: {macro_f1:.4f}\")\nprint(f\"- Weighted F1-Score: {weighted_f1:.4f}\")\nprint(f\"- Recall của lớp 'asthma': {asthma_recall:.4f}\")\n\n\n# --- BƯỚC 5: VẼ CÁC BIỂU ĐỒ ---\nreport_figs_path = os.path.join(KAGGLE_OUTPUT_PATH, \"report_figures\")\nos.makedirs(report_figs_path, exist_ok=True)\n\n# Biểu đồ training history (giữ nguyên)\nplt.figure(figsize=(8, 6))\nplt.plot(final_history.history['accuracy'], label='Training Accuracy')\nplt.plot(final_history.history['auc'], label='Training AUC') # Thêm AUC vào biểu đồ\nplt.title('Biểu đồ Accuracy & AUC của mô hình cuối cùng')\nplt.xlabel('Epoch')\nplt.ylabel('Value')\nplt.legend(loc='lower right')\naccuracy_plot_path = os.path.join(report_figs_path, f'final_accuracy_plot_{run_timestamp}.png')\nplt.savefig(accuracy_plot_path)\nplt.close()\n\nplt.figure(figsize=(8, 6))\nplt.plot(final_history.history['loss'], label='Training Loss')\nplt.title('Biểu đồ Loss của mô hình cuối cùng')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\nloss_plot_path = os.path.join(report_figs_path, f'final_loss_plot_{run_timestamp}.png')\nplt.savefig(loss_plot_path)\nplt.close()\n\n# Ma trận nhầm lẫn (giữ nguyên)\ncm = confusion_matrix(y_test_encoded, y_pred_encoded, labels=trained_class_indices)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names_trained, yticklabels=target_names_trained)\nplt.title('Ma trận nhầm lẫn trên tập Test cuối cùng')\nplt.ylabel('Nhãn thật')\nplt.xlabel('Nhãn dự đoán')\ncm_plot_path = os.path.join(report_figs_path, f'confusion_matrix_{run_timestamp}.png')\nplt.savefig(cm_plot_path)\nplt.close()\n\n\n# --- BƯỚC 6: TÍNH TOÁN VÀ VẼ ĐƯỜNG CONG ROC CHO TỪNG LỚP ---\n# Chuyển logits thành xác suất\ny_pred_probs = tf.nn.softmax(y_pred_logits).numpy()\n\n# Chuyển nhãn thật sang dạng one-hot để tính ROC cho từng lớp\ny_test_binarized = label_binarize(y_test_encoded, classes=trained_class_indices)\nn_classes = y_test_binarized.shape[1]\n\n# Tính toán ROC và AUC cho từng lớp\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_pred_probs[:, i])\n    roc_auc[i] = sklearn_auc(fpr[i], tpr[i])\n\n# Vẽ đường cong ROC\nplt.figure(figsize=(10, 8))\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'deeppink'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label='Đường cong ROC của lớp {0} (AUC = {1:0.2f})'\n             ''.format(target_names_trained[i], roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Tỷ lệ Dương tính Giả (False Positive Rate)')\nplt.ylabel('Tỷ lệ Dương tính Thật (True Positive Rate)')\nplt.title('Đường cong ROC cho từng lớp')\nplt.legend(loc=\"lower right\")\nroc_plot_path = os.path.join(report_figs_path, f'roc_curves_{run_timestamp}.png')\nplt.savefig(roc_plot_path)\nplt.show()\nplt.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# VẼ GRAD-CAM (PHIÊN BẢN HOÀN CHỈNH)\n\nprint(\"Đang tạo lại kiến trúc model và tải trọng số đã lưu...\")\nwith strategy.scope():\n    # Tạo một kiến trúc model mới y hệt lúc huấn luyện\n    final_model = create_model(INPUT_SHAPE, len(ALL_CLASSES))\n    \n    # Tải các trọng số đã được huấn luyện vào kiến trúc mới này\n    final_model.load_weights(model_checkpoint_path)\n\nprint(\"Tải trọng số cho model cuối cùng hoàn tất.\")\n\n# --- BƯỚC 1: LẤY DỮ LIỆU TEST TỪ PIPELINE `test_ds` ---\nprint(\"Đang trích xuất dữ liệu từ test_ds để vẽ Grad-CAM...\")\nX_test_list = []\ny_test_onehot_list = []\n\n# Sử dụng tqdm để theo dõi tiến trình\nfor images, labels in tqdm(test_ds, desc=\"Extracting data from test_ds\"):\n    X_test_list.append(images.numpy())\n    y_test_onehot_list.append(labels.numpy())\n\n# Nối các batch lại thành các mảng NumPy lớn\nX_test = np.concatenate(X_test_list, axis=0)\ny_test_onehot = np.concatenate(y_test_onehot_list, axis=0)\ny_test_encoded_from_ds = np.argmax(y_test_onehot, axis=1)\n\nprint(f\"Đã trích xuất thành công {len(X_test)} mẫu.\")\n\n\n# --- BƯỚC 2: TÌM LỚP CONVOLUTION CUỐI CÙNG (giữ nguyên) ---\nlast_conv_layer_name = None\nfor layer in reversed(final_model.layers):\n    if isinstance(layer, tf.keras.layers.GlobalAveragePooling2D):\n        pooling_index = final_model.layers.index(layer)\n        last_conv_layer_name = final_model.layers[pooling_index - 1].name\n        break\nif last_conv_layer_name is None:\n    raise ValueError(\"Không thể tự động tìm thấy lớp phù hợp cho Grad-CAM.\")\nprint(f\"Đã tự động xác định lớp Grad-CAM: {last_conv_layer_name}\")\n\n\n# --- BƯỚC 3: TẠO HÌNH ẢNH GRAD-CAM CHO CÁC MẪU TIÊU BIỂU ---\ngradcam_path = os.path.join(report_figs_path, \"grad_cam\")\nos.makedirs(gradcam_path, exist_ok=True)\nprint(\"Tạo hình ảnh Grad-CAM cho các mẫu tiêu biểu...\")\n\nresults_list = []\nfor i in range(len(y_pred_encoded)):\n    true_label_encoded = y_test_encoded_from_ds[i]\n    pred_label_encoded = y_pred_encoded[i]\n    confidence = y_pred_probs[i][pred_label_encoded]\n    is_correct = (true_label_encoded == pred_label_encoded)\n    results_list.append({'index': i, 'true_label': true_label_encoded, 'pred_label': pred_label_encoded, 'confidence': confidence, 'is_correct': is_correct})\nresults_df = pd.DataFrame(results_list)\n\nfor class_index, class_name in zip(trained_class_indices, target_names_trained):\n    correct_samples = results_df[(results_df['is_correct'] == True) & (results_df['true_label'] == class_index)].nlargest(3, 'confidence')\n    incorrect_samples = results_df[(results_df['is_correct'] == False) & (results_df['true_label'] == class_index)].nlargest(3, 'confidence')\n    \n    for _, row in correct_samples.iterrows():\n        idx = int(row['index'])\n        img_array, spec = X_test[idx][np.newaxis, ...], X_test[idx, :, :, 0]\n        # Đổi tên hàm thành get_grad_cam_final\n        heatmap = get_grad_cam_final(final_model, img_array, last_conv_layer_name, pred_index=class_index)\n        overlay = overlay_grad_cam(spec, heatmap)\n        plt.imshow(overlay)\n        plt.title(f\"Đúng: {class_name}, Tin cậy: {row['confidence']:.2f}\")\n        plt.axis('off')\n        plt.savefig(os.path.join(gradcam_path, f\"correct_{class_name}_{idx}_{run_timestamp}.png\"))\n        plt.close()\n        \n    for _, row in incorrect_samples.iterrows():\n        idx = int(row['index'])\n        pred_class_name = le.inverse_transform([int(row['pred_label'])])[0]\n        img_array, spec = X_test[idx][np.newaxis, ...], X_test[idx, :, :, 0]\n        # Đổi tên hàm thành get_grad_cam_final\n        heatmap = get_grad_cam_final(final_model, img_array, last_conv_layer_name, pred_index=class_index)\n        overlay = overlay_grad_cam(spec, heatmap)\n        plt.imshow(overlay)\n        plt.title(f\"Thật: {class_name}, Sai -> {pred_class_name}, Tin cậy: {row['confidence']:.2f}\")\n        plt.axis('off')\n        plt.savefig(os.path.join(gradcam_path, f\"incorrect_{class_name}_as_{pred_class_name}_{idx}_{run_timestamp}.png\"))\n        plt.close()\n\n# --- BƯỚC 4: TÍNH TOÁN VÀ VẼ GRAD-CAM TRUNG BÌNH ---\nprint(\"Đang tính toán Grad-CAM trung bình cho tất cả các lớp...\")\n\n# Tạo các dictionary để lưu trữ heatmaps\ncorrect_heatmaps = {class_name: [] for class_name in target_names_trained}\nincorrect_heatmaps = {class_name: [] for class_name in target_names_trained}\n\n# Lặp qua tất cả các kết quả để tính heatmap\nfor _, row in tqdm(results_df.iterrows(), total=len(results_df), desc=\"Calculating all heatmaps\"):\n    idx = int(row['index'])\n    true_label_index = int(row['true_label'])\n    true_class_name = le.inverse_transform([true_label_index])[0]\n    \n    img_array = X_test[idx][np.newaxis, ...]\n    # Luôn tính heatmap theo nhãn thật để xem model tập trung vào đâu\n    heatmap = get_grad_cam_final(final_model, img_array, last_conv_layer_name, pred_index=true_label_index)\n    \n    if row['is_correct']:\n        correct_heatmaps[true_class_name].append(heatmap)\n    else:\n        incorrect_heatmaps[true_class_name].append(heatmap)\n\n# Vẽ Grad-CAM trung bình\nfor class_name in target_names_trained:\n    # Xử lý các ca đoán đúng\n    if correct_heatmaps[class_name]:\n        avg_heatmap_correct = np.mean(correct_heatmaps[class_name], axis=0)\n        overlay = overlay_grad_cam(np.zeros(INPUT_SHAPE[:2]), avg_heatmap_correct)\n        plt.imshow(overlay)\n        plt.title(f\"Grad-CAM TB - Đúng cho lớp {class_name}\")\n        plt.axis('off')\n        plt.savefig(os.path.join(gradcam_path, f\"avg_correct_{class_name}_{run_timestamp}.png\"))\n        plt.close()\n        \n    # Xử lý các ca đoán sai\n    if incorrect_heatmaps[class_name]:\n        avg_heatmap_incorrect = np.mean(incorrect_heatmaps[class_name], axis=0)\n        overlay = overlay_grad_cam(np.zeros(INPUT_SHAPE[:2]), avg_heatmap_incorrect)\n        plt.imshow(overlay)\n        plt.title(f\"Grad-CAM TB - Sai cho lớp {class_name}\")\n        plt.axis('off')\n        plt.savefig(os.path.join(gradcam_path, f\"avg_incorrect_{class_name}_{run_timestamp}.png\"))\n        plt.close()\n\nprint(\"Hoàn tất việc tạo Grad-CAM.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TẠO BÁO CÁO PDF\nprint(\"Tạo báo cáo PDF...\")\npdf = PDFReport()\npdf.add_page()\npdf.chapter_title(\"1. Tom tat cau hinh va Ket qua\")\nconfig_summary = f\"\"\"\n- Model ID: {MODEL_ID}\n- Thoi gian chay: {datetime.datetime.now(pytz.timezone('Asia/Ho_Chi_Minh')).strftime(\"%Y-%m-%d %H:%M:%S\")}\n- Cac lop huan luyen: {', '.join(CLASSES_TO_TRAIN)}\n- K-Fold Cross-Validation: {N_SPLITS} folds\n\n--- KET QUA CROSS-VALIDATION ---\n- Validation Accuracy trung binh: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\n- Validation Loss trung binh: {np.mean(fold_losses):.4f} +/- {np.std(fold_losses):.4f}\n\n--- KET QUA TREN TAP TEST CUOI CUNG ---\n- Test Loss: {loss:.4f}\n- Test Accuracy: {accuracy:.4f}\n\n--- CAU HINH CHI TIET ---\n- SEED: {SEED}\n- Epochs: {EPOCHS} (Patience: {EARLY_STOPPING_PATIENCE})\n- Batch Size: {BATCH_SIZE}\n- Learning Rate: {LEARNING_RATE}\n- Ham Loss: {'Focal Loss' if USE_FOCAL_LOSS else 'Categorical Crossentropy'}\n- Tang cuong du lieu: {'Co (SpecAugment)' if USE_DATA_AUGMENTATION else 'Khong'}\n- Kich thuoc Input: {INPUT_SHAPE}\n\"\"\"\npdf.chapter_body(config_summary)\npdf.add_image_section(\"2. Bieu do Huan luyen cua Mo hinh Cuoi cung\", accuracy_plot_path)\npdf.add_image_section(\"\", loss_plot_path)\npdf.chapter_title(\"3. Danh gia chi tiet tren tap Test\")\npdf.chapter_body(\"Bao cao phan loai chi tiet:\")\npdf.set_font('Courier', '', 8)\npdf.chapter_body(report)\npdf.add_image_section(\"Ma tran nham lan:\", cm_plot_path)\n\npdf.add_page()\npdf.chapter_title(\"4. Phan tich Grad-CAM\")\nfor class_name in target_names_trained:\n    pdf.chapter_body(f\"Lop: {class_name}\")\n    correct_imgs = sorted(glob.glob(os.path.join(gradcam_path, f\"correct_{class_name}_*_{run_timestamp}.png\")))\n    incorrect_imgs = sorted(glob.glob(os.path.join(gradcam_path, f\"incorrect_{class_name}_*_{run_timestamp}.png\")))\n    \n    x_pos, y_pos = pdf.get_x(), pdf.get_y()\n    for i, img_path in enumerate(correct_imgs[:3]):\n        if os.path.exists(img_path): pdf.image(img_path, x=x_pos + i * 60, y=y_pos, w=55)\n    if correct_imgs: y_pos += 45\n    for i, img_path in enumerate(incorrect_imgs[:3]):\n        if os.path.exists(img_path): pdf.image(img_path, x=x_pos + i * 60, y=y_pos, w=55)\n    if incorrect_imgs: y_pos += 45\n    pdf.set_y(y_pos)\n    \n    avg_correct_path = os.path.join(gradcam_path, f\"avg_correct_{class_name}_{run_timestamp}.png\")\n    avg_incorrect_path = os.path.join(gradcam_path, f\"avg_incorrect_{class_name}_{run_timestamp}.png\")\n    if os.path.exists(avg_correct_path):\n        pdf.image(avg_correct_path, w=80)\n    if os.path.exists(avg_incorrect_path):\n        pdf.image(avg_incorrect_path, w=80)\n    pdf.ln(10)\n\nreport_filename = f\"report_{MODEL_ID}_{run_timestamp}.pdf\"\nreport_filepath = os.path.join(KAGGLE_OUTPUT_PATH, report_filename)\npdf.output(report_filepath)\nprint(f\"Đã tạo báo cáo PDF tại: {report_filepath}\")\n\nprint(\"\\nBắt đầu quá trình tải kết quả lên Google Drive...\")\ndrive = authenticate_gdrive()\nupload_folder_to_drive(drive, KAGGLE_OUTPUT_PATH, DRIVE_RESULTS_FOLDER_ID)\nprint(\"Hoàn tất! Toàn bộ kết quả đã được lưu về Google Drive.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}