{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12870874,"sourceType":"datasetVersion","datasetId":8141736}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 0.1. Cài đặt các thư viện cần thiết\n!pip install -q fpdf2 noisereduce librosa tensorflow scikit-learn matplotlib seaborn pytz PyDrive2  ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CÀI ĐẶT & CẤU HÌNH \n# 0.2. Import thư viện\nimport os\nimport glob \nimport random\nimport datetime\nimport pytz\nimport shutil\nimport joblib\nimport zipfile\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\nfrom fpdf import FPDF\nfrom tqdm import tqdm\nimport librosa\nimport noisereduce as nr\nimport tensorflow as tf\nfrom tensorflow.keras import mixed_precision\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D, AveragePooling2D\nfrom tensorflow.keras.applications import EfficientNetV2B2\nfrom tensorflow.keras.applications.efficientnet_v2 import preprocess_input\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.utils import class_weight\nfrom pydrive2.auth import GoogleAuth\nfrom pydrive2.drive import GoogleDrive\nfrom kaggle_secrets import UserSecretsClient\nfrom oauth2client.service_account import ServiceAccountCredentials\nfrom tensorflow.keras.regularizers import l2\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.metrics import roc_curve, auc as sklearn_auc\nfrom sklearn.preprocessing import label_binarize\nfrom itertools import cycle\nfrom keras.saving import register_keras_serializable\n\nprint(f\"TensorFlow Version: {tf.__version__}\")\n\ntry:\n    # --- 1. ƯU TIÊN KẾT NỐI VỚI TPU ---\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    strategy = tf.distribute.TPUStrategy(tpu)\n    \n    # Kiểu dữ liệu tối ưu nhất cho TPU là 'mixed_bfloat16'\n    policy = 'mixed_bfloat16'\n    mixed_precision.set_global_policy(policy)\n    \n    print(\" KẾT NỐI TPU THÀNH CÔNG!\")\n    print(f\"   - Số lượng nhân (replicas): {strategy.num_replicas_in_sync}\")\n    print(f\"   - Kiểu dữ liệu (DType Policy): {policy}\")\n\nexcept Exception:\n    print(\" Không tìm thấy TPU. Đang kiểm tra GPU...\")\n    \n    # --- 2. NẾU KHÔNG CÓ TPU, TÌM VÀ KẾT NỐI VỚI GPU ---\n    gpus = tf.config.list_physical_devices('GPU')\n    if gpus:\n        # MirroredStrategy sẽ tự động sử dụng TẤT CẢ các GPU tìm thấy\n        strategy = tf.distribute.MirroredStrategy()\n        \n        # Kiểu dữ liệu tối ưu nhất cho GPU T4 là 'mixed_float16'\n        policy = 'mixed_float16'\n        mixed_precision.set_global_policy(policy)\n        \n        print(\" KẾT NỐI GPU THÀNH CÔNG!\")\n        print(f\"   - Số lượng GPU được sử dụng: {strategy.num_replicas_in_sync}\")\n        print(f\"   - Kiểu dữ liệu (DType Policy): {policy}\")\n        \n    else:\n        # --- 3. NẾU KHÔNG CÓ CẢ GPU, SỬ DỤNG CPU ---\n        print(\" Không tìm thấy GPU. Sử dụng CPU.\")\n        strategy = tf.distribute.get_strategy()\n        print(\" Sử dụng chiến lược mặc định cho CPU.\")\n        print(f\"   - Số lượng nhân (replicas): {strategy.num_replicas_in_sync}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# THIẾT LẬP CẤU HÌNH \n# --- Các cấu hình cơ bản ---\nSEED = 42\ndef set_seed(seed_value):\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    #os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    tf.random.set_seed(seed_value)\nset_seed(SEED)\n\nKAGGLE_PROCESSED_DATA_PATH = \"/kaggle/input/ngt-spectrogram-id/\"\nKAGGLE_OUTPUT_PATH = \"/kaggle/working/output_results\"\nCHECKPOINT_PATH = \"/kaggle/working/checkpoints\"\nos.makedirs(CHECKPOINT_PATH, exist_ok=True)\nos.makedirs(KAGGLE_OUTPUT_PATH, exist_ok=True)\n\nCLASSES_TO_TRAIN = ['covid', 'asthma', 'healthy', 'tuberculosis']\nALL_CLASSES = ['healthy', 'asthma', 'covid', 'tuberculosis']\nN_SPLITS = 5\nTEST_SPLIT_RATIO = 0.15\nUSE_DATA_AUGMENTATION = True # Bật/tắt augmentation ở đây\nUSE_FOCAL_LOSS = True\nUSE_COSINE_DECAY_RESTARTS = True \n\nMODEL_ID = f'EfficienetV2B2_CV_TPU'\nMIN_DELTA = 1e-4\nSHUFFLE_BUFFER_SIZE = 2048 \nGAMMA = 3.0 # Giữ nguyên giá trị tiêu chuẩn\n\n# --- CÁC THAY ĐỔI CHÍNH ---\nLEARNING_RATE = 1e-5              \nWEIGHT_DECAY = 5e-4               \n\n# Cấu hình cho Cross-Validation\nTOTAL_EPOCHS = 500               \nWARMUP_EPOCHS = 3                 \nRESTART_CYCLE_1_EPOCHS = 50       \nPATIENCE_EPOCHS = RESTART_CYCLE_1_EPOCHS + 25 # Thay đổi: Patience = 50\n\n# --- ĐỊNH NGHĨA BATCH SIZE ---\n# BATCH_SIZE này là batch size cho mỗi nhân TPU (per-replica)\nBATCH_SIZE = 64\n# Tính toán GLOBAL_BATCH_SIZE để dùng trong pipeline\n# Biến 'strategy' được lấy từ ô code đầu tiên\nGLOBAL_BATCH_SIZE = BATCH_SIZE * strategy.num_replicas_in_sync\nprint(f\"Batch size mỗi nhân: {BATCH_SIZE}\")\nprint(f\"Global batch size (tổng cộng): {GLOBAL_BATCH_SIZE}\")\n\n# INPUT_SHAPE sẽ được cập nhật lại ở ô chuẩn bị dữ liệu\nINPUT_SHAPE = (256, 256, 3)\nprint(f\"Input shape: {INPUT_SHAPE}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# KHỞI TẠO CÁC HÀM CẦN THIẾT \n\ndef get_patient_id(filepath, class_name):\n    filename = os.path.basename(filepath)\n    if class_name.lower() in ['asthma', 'covid', 'healthy']:\n        return filename.split('_')[0]\n    elif class_name.lower() == 'tuberculosis':\n        return '_'.join(filename.split('_')[:-1]).replace('.npy', '')\n    else:\n        return filename.split('_')[0]\n\n@register_keras_serializable()\nclass MacroF1Score(tf.keras.metrics.Metric):\n    \"\"\"\n    Lớp metric để tính toán Macro F1-Score một cách chính xác trên toàn bộ epoch.\n    \"\"\"\n    def __init__(self, num_classes, name='f1_macro', **kwargs):\n        super(MacroF1Score, self).__init__(name=name, **kwargs)\n        self.num_classes = num_classes\n        self.true_positives = self.add_weight(name='tp', shape=(num_classes,), initializer='zeros')\n        self.false_positives = self.add_weight(name='fp', shape=(num_classes,), initializer='zeros')\n        self.false_negatives = self.add_weight(name='fn', shape=(num_classes,), initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_pred_labels = tf.argmax(tf.nn.softmax(y_pred), axis=1)\n        y_true_labels = tf.argmax(y_true, axis=1)\n        cm = tf.math.confusion_matrix(y_true_labels, y_pred_labels, num_classes=self.num_classes, dtype=tf.float32)\n        tp = tf.linalg.diag_part(cm)\n        fp = tf.reduce_sum(cm, axis=0) - tp\n        fn = tf.reduce_sum(cm, axis=1) - tp\n        self.true_positives.assign_add(tp)\n        self.false_positives.assign_add(fp)\n        self.false_negatives.assign_add(fn)\n\n    def result(self):\n        precision = self.true_positives / (self.true_positives + self.false_positives + tf.keras.backend.epsilon())\n        recall = self.true_positives / (self.true_positives + self.false_negatives + tf.keras.backend.epsilon())\n        f1 = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n        macro_f1 = tf.reduce_mean(f1)\n        return macro_f1\n\n    def reset_state(self):\n        self.true_positives.assign(tf.zeros(self.num_classes))\n        self.false_positives.assign(tf.zeros(self.num_classes))\n        self.false_negatives.assign(tf.zeros(self.num_classes))\n\n    # Thêm phương thức get_config\n    def get_config(self):\n        config = super(MacroF1Score, self).get_config()\n        config.update({'num_classes': self.num_classes})\n        return config\n\n    def reset_state(self):\n        # Reset các biến trạng thái về 0 ở đầu mỗi epoch\n        self.true_positives.assign(tf.zeros(self.num_classes))\n        self.false_positives.assign(tf.zeros(self.num_classes))\n        self.false_negatives.assign(tf.zeros(self.num_classes))\n        \ndef parse_tfrecord_fn(example):\n    feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'label': tf.io.FixedLenFeature([], tf.int64),\n    }\n    example = tf.io.parse_single_example(example, feature_description)\n    \n    # 1. Parse tensor gốc (kích thước nhỏ)\n    image = tf.io.parse_tensor(example['image'], out_type=tf.float32)\n    \n    # --- THÊM DÒNG SỬA LỖI TẠI ĐÂY ---\n    # Thông báo cho TensorFlow biết hình dạng gốc của spectrogram là (256, 126)\n    image.set_shape([256, 126])\n    # ------------------------------------\n    \n    # 2. Thực hiện toàn bộ quá trình xử lý trên đồ thị TensorFlow\n    image_3d = tf.stack([image, image, image], axis=-1)\n    image_resized = tf.image.resize(image_3d, [INPUT_SHAPE[0], INPUT_SHAPE[1]])\n    min_val = tf.reduce_min(image_resized)\n    max_val = tf.reduce_max(image_resized)\n    image_scaled_01 = (image_resized - min_val) / (max_val - min_val + 1e-7)\n    image_scaled_255 = image_scaled_01 * 255.0\n    \n    # 3. Gọi hàm preprocess_input của model\n    image_preprocessed = preprocess_input(image_scaled_255)\n    \n    # 4. Chuyển nhãn sang one-hot\n    label = tf.one_hot(tf.cast(example['label'], tf.int32), depth=len(ALL_CLASSES))\n    \n    return image_preprocessed, label\n\ndef augment(spectrogram, label):\n    spectrogram = spec_augment(spectrogram)\n    return spectrogram, label\n\ndef focal_loss_from_logits_optimized(alpha, gamma=2.0):\n    \"\"\"\n    Tạo ra hàm Focal Loss phiên bản đầy đủ và sạch sẽ.\n    \n    Args:\n        alpha: Một list hoặc array chứa trọng số cho mỗi lớp.\n        gamma: Hệ số tập trung, mặc định là 2.0.\n    \"\"\"\n    # Chuyển alpha sang dạng tensor để tính toán\n    alpha = tf.constant(alpha, dtype=tf.float32)\n\n    def focal_loss_fixed(y_true, y_pred):\n        y_true = tf.cast(y_true, 'float32')\n        y_pred = tf.cast(y_pred, 'float32')\n        \n        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n        probs = tf.nn.softmax(y_pred)\n        pt = tf.reduce_sum(y_true * probs, axis=-1)\n        focal_term = (1.0 - pt) ** gamma\n        alpha_t = tf.reduce_sum(y_true * alpha, axis=-1)\n        loss = alpha_t * focal_term * cross_entropy\n        \n        return tf.reduce_mean(loss)\n        \n    return focal_loss_fixed\n\ndef spec_augment(spectrogram, time_masking_para=40, frequency_masking_para=30, num_time_masks=1, num_freq_masks=1):\n    spectrogram_aug = spectrogram\n    freq_bins = tf.shape(spectrogram)[1] # Sửa: Lấy chiều tần số từ shape 4D\n    time_steps = tf.shape(spectrogram)[2] # Sửa: Lấy chiều thời gian từ shape 4D\n    \n    for _ in range(num_freq_masks):\n        f = tf.random.uniform(shape=(), minval=0, maxval=frequency_masking_para, dtype=tf.int32)\n        f0 = tf.random.uniform(shape=(), minval=0, maxval=freq_bins - f, dtype=tf.int32)\n        freq_mask_1d = tf.concat([tf.ones((f0,), dtype=spectrogram.dtype), tf.zeros((f,), dtype=spectrogram.dtype), tf.ones((freq_bins - f0 - f,), dtype=spectrogram.dtype)], axis=0)\n        freq_mask_4d = tf.reshape(freq_mask_1d, (1, freq_bins, 1, 1)) # Sửa: Reshape thành 4D để broadcast\n        spectrogram_aug *= freq_mask_4d\n        \n    for _ in range(num_time_masks):\n        t = tf.random.uniform(shape=(), minval=0, maxval=time_masking_para, dtype=tf.int32)\n        t0 = tf.random.uniform(shape=(), minval=0, maxval=time_steps - t, dtype=tf.int32)\n        time_mask_1d = tf.concat([tf.ones((t0,), dtype=spectrogram.dtype), tf.zeros((t,), dtype=spectrogram.dtype), tf.ones((time_steps - t0 - t,), dtype=spectrogram.dtype)], axis=0)\n        time_mask_4d = tf.reshape(time_mask_1d, (1, 1, time_steps, 1)) # Sửa: Reshape thành 4D để broadcast\n        spectrogram_aug *= time_mask_4d\n        \n    return spectrogram_aug\n\n@register_keras_serializable()\nclass FinalModel(tf.keras.Model):\n    def __init__(self, input_shape, num_classes, **kwargs):\n        super(FinalModel, self).__init__(**kwargs)\n        self.input_shape_config = input_shape\n        self.num_classes_config = num_classes\n        \n        # 1. Mô hình nền \n        self.base_model = EfficientNetV2B2(\n            weights='imagenet',\n            include_top=False,\n            input_shape=self.input_shape_config\n        )\n        \n        # 2. Các lớp \"Head\" phân loại phức tạp hơn\n        self.pooling = GlobalAveragePooling2D(name=\"pooling_layer\")\n        self.dense1 = Dense(512, activation='relu', kernel_regularizer=l2(0.001), name=\"dense_layer_1\")\n        self.dropout1 = Dropout(0.5, name=\"dropout_layer_1\")\n        self.dense2 = Dense(256, activation='relu', kernel_regularizer=l2(0.001), name=\"dense_layer_2\")\n        self.dropout2 = Dropout(0.3, name=\"dropout_layer_2\")\n        self.dense_output = Dense(num_classes, activation='linear', dtype='float32', name=\"output_layer\")\n\n    def call(self, inputs, training=None):\n        # Dữ liệu đi qua mô hình nền\n        x = self.base_model(inputs, training=training)\n        \n        # Dữ liệu đi qua các lớp \"Head\" mới\n        x = self.pooling(x)\n        x = self.dense1(x)\n        x = self.dropout1(x, training=training)\n        x = self.dense2(x)\n        x = self.dropout2(x, training=training)\n        outputs = self.dense_output(x)\n        return outputs\n\n    # Phương thức get_config (giữ nguyên)\n    def get_config(self):\n        config = super(FinalModel, self).get_config()\n        config.update({\n            'input_shape': self.input_shape_config,\n            'num_classes': self.num_classes_config\n        })\n        return config\n\ndef load_data_from_df(df):\n    X, y = [], []\n    for _, row in df.iterrows():\n        X.append(np.load(row['filepath']))\n        y.append(row['label'])\n    return np.array(X), np.array(y)\n\ndef get_grad_cam_final(model, img_array, last_conv_layer_name, pred_index=None):\n    \"\"\"\n    Tạo Grad-CAM cho một subclassed model.\n    Lưu ý: Model phải được build (chạy qua dữ liệu một lần) trước khi gọi hàm này.\n    \"\"\"\n    # Tạo một model trung gian với input là input của model chính,\n    # và output là lớp conv cuối và output cuối cùng của model chính.\n    grad_model = Model(\n        inputs=model.inputs,\n        outputs=[model.base_model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    # Tính toán gradient\n    with tf.GradientTape() as tape:\n        # Đưa ảnh vào grad_model để lấy 2 output đã định nghĩa ở trên\n        last_conv_layer_output, preds = grad_model(img_array)\n        \n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # Lấy gradient của lớp được dự đoán đối với feature map của lớp conv cuối\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # Tính trung bình gradient và tạo heatmap\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    \n    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + tf.keras.backend.epsilon())\n    \n    return heatmap.numpy()\n\ndef overlay_grad_cam(spec, heatmap, alpha=0.6):\n    heatmap_resized = tf.image.resize(heatmap[..., np.newaxis], (spec.shape[0], spec.shape[1]))\n    heatmap_resized = np.uint8(255 * heatmap_resized)\n    jet = plt.cm.get_cmap(\"jet\")\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap_resized.squeeze()]\n    spec_display = np.stack([spec]*3, axis=-1)\n    spec_display = (spec_display - spec_display.min()) / (spec_display.max() - spec_display.min())\n    superimposed_img = jet_heatmap * alpha + spec_display\n    superimposed_img = np.clip(superimposed_img, 0, 1)\n    return superimposed_img\n\nclass PDFReport(FPDF):\n    def header(self):\n        self.set_font('Arial', 'B', 12)\n        self.cell(0, 10, 'BAO CAO KET QUA HUAN LUYEN MO HINH AI', 0, 1, 'C')\n        self.ln(10)\n    def footer(self):\n        self.set_y(-15)\n        self.set_font('Arial', 'I', 8)\n        self.cell(0, 10, f'Trang {self.page_no()}', 0, 0, 'C')\n    def chapter_title(self, title):\n        self.set_font('Arial', 'B', 12)\n        self.cell(0, 10, title, 0, 1, 'L')\n        self.ln(5)\n    def chapter_body(self, content):\n        self.set_font('Arial', '', 10)\n        safe_content = content.encode('latin-1', 'replace').decode('latin-1')\n        self.multi_cell(0, 5, safe_content)\n        self.ln()\n    def add_image_section(self, title, img_path):\n        self.chapter_title(title)\n        if os.path.exists(img_path):\n            self.image(img_path, x=None, y=None, w=180)\n            self.ln(5)\n        else:\n            self.chapter_body(f\"Khong tim thay hinh anh: {img_path}\")\n\ndef authenticate_gdrive():\n    user_secrets = UserSecretsClient()\n    secret_value = user_secrets.get_secret(\"google_service_account_key\")\n    with open(\"service_account.json\", \"w\") as f:\n        f.write(secret_value)\n    scope = [\"https://www.googleapis.com/auth/drive\"]\n    gauth = GoogleAuth()\n    gauth.credentials = ServiceAccountCredentials.from_json_keyfile_name(\"service_account.json\", scope)\n    drive = GoogleDrive(gauth)\n    return drive\n\ndef upload_folder_to_drive(drive, folder_path, parent_folder_id):\n    folder_name = os.path.basename(folder_path)\n    print(f\"Đang tạo thư mục '{folder_name}' trên Google Drive...\")\n    folder_metadata = {'title': folder_name, 'mimeType': 'application/vnd.google-apps.folder', 'parents': [{'id': parent_folder_id}]}\n    folder = drive.CreateFile(folder_metadata)\n    folder.Upload()\n    \n    print(f\"Bắt đầu tải nội dung của '{folder_name}'...\")\n    for item in tqdm(os.listdir(folder_path), desc=f\"Uploading {folder_name}\"):\n        item_path = os.path.join(folder_path, item)\n        if os.path.isfile(item_path):\n            gfile = drive.CreateFile({'title': item, 'parents': [{'id': folder['id']}]})\n            gfile.SetContentFile(item_path)\n            gfile.Upload(param={'supportsTeamDrives': True})\n        elif os.path.isdir(item_path):\n            upload_folder_to_drive(drive, item_path, folder['id'])\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy()\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef serialize_example(image, label):\n    \"\"\"Creates a tf.train.Example message ready to be written to a file.\"\"\"\n    feature = {\n        'image': _bytes_feature(tf.io.serialize_tensor(image)),\n        'label': _int64_feature(label)\n    }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()\nclass LearningRateLogger(tf.keras.callbacks.Callback):\n    def on_epoch_begin(self, epoch, logs=None):\n        current_lr = tf.keras.backend.get_value(self.model.optimizer.learning_rate)\n        print(f\"\\nEpoch {epoch+1}: Learning Rate is {current_lr:.2e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CHUẨN BỊ DỮ LIỆU VÀ TẠO TFRECORD \n\nsuspicious_files_to_remove = [\n    '/kaggle/input/ngt-spectrogram-id/healthy/P0030101_123370_Dkwg3F7jMGaR7kbc-seg2.npy',\n    '/kaggle/input/ngt-spectrogram-id/covid/P0032202_15897_PcbyJQWemBfghUYp-seg2.npy',\n    '/kaggle/input/ngt-spectrogram-id/covid/P0027142_5701_hupBI5CxKMNCfe8b-seg1.npy',\n    '/kaggle/input/ngt-spectrogram-id/covid/P0056214_89533_0WsmNRSKuQFGodg1-seg1.npy',\n]\n# --- BƯỚC 1: TẢI VÀ PHÂN CHIA DỮ LIỆU BAN ĐẦU ---\nprint(\"Bắt đầu chuẩn bị và phân chia dữ liệu...\")\nall_files_to_split = []\nfor class_name in ALL_CLASSES:\n    source_dir = os.path.join(KAGGLE_PROCESSED_DATA_PATH, class_name)\n    if os.path.exists(source_dir):\n        files = glob.glob(os.path.join(source_dir, '*.npy'))\n        for f in files:\n            all_files_to_split.append({'filepath': f, 'label': class_name})\n\nall_data_df = pd.DataFrame(all_files_to_split)\nall_data_df['patient_id'] = all_data_df.apply(lambda row: get_patient_id(row['filepath'], row['label']), axis=1)\n\nprint(f\"Số lượng mẫu ban đầu: {len(all_data_df)}\")\nall_data_df = all_data_df[~all_data_df['filepath'].isin(suspicious_files_to_remove)].reset_index(drop=True)\nprint(f\"Số lượng mẫu sau khi lọc bỏ file 'im lặng': {len(all_data_df)}\")\n\nprint(\"Tách tập Test cuối cùng (Hold-out set)...\")\npatient_ids = all_data_df['patient_id'].unique()\nnp.random.shuffle(patient_ids)\ntest_patient_count = int(len(patient_ids) * TEST_SPLIT_RATIO)\ntest_patients = patient_ids[:test_patient_count]\ntrain_val_patients = patient_ids[test_patient_count:]\n\ntest_df = all_data_df[all_data_df['patient_id'].isin(test_patients)].reset_index(drop=True)\ntrain_val_df = all_data_df[all_data_df['patient_id'].isin(train_val_patients)].reset_index(drop=True)\n\nprint(f\"Đã tách: {len(train_val_df)} mẫu cho Train/Validation (CV) và {len(test_df)} mẫu cho Test cuối cùng.\")\n\n# --- BƯỚC 2: KHỞI TẠO LABEL ENCODER ---\nle = LabelEncoder().fit(ALL_CLASSES)\n\n# --- BƯỚC 3: CHỈ TẠO FILE TFRECORD CHO TẬP TEST ---\nTFRECORD_OUTPUT_PATH = \"/kaggle/working/tfrecords\"\nos.makedirs(TFRECORD_OUTPUT_PATH, exist_ok=True)\nprint(f\"Bắt đầu chuyển đổi dữ liệu sang TFRecord tại: {TFRECORD_OUTPUT_PATH}\")\n\nprint(\"--- Đang xử lý và tạo file cho tập test ---\")\ntest_tfrecord_path = os.path.join(TFRECORD_OUTPUT_PATH, \"test.tfrec\")\nwith tf.io.TFRecordWriter(test_tfrecord_path) as writer:\n    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Creating test.tfrec\"):\n        spectrogram = np.load(row['filepath']).astype(np.float32)\n        \n        image_tensor = tf.convert_to_tensor(spectrogram)\n        image_3d = tf.stack([image_tensor]*3, axis=-1)\n        image_resized = tf.image.resize(image_3d, [INPUT_SHAPE[0], INPUT_SHAPE[1]])\n        min_val = tf.reduce_min(image_resized)\n        max_val = tf.reduce_max(image_resized)\n        image_scaled_01 = (image_resized - min_val) / (max_val - min_val + 1e-7)\n        image_to_serialize = image_scaled_01 * 255.0\n\n        label_encoded = le.transform([row['label']])[0]\n        example = serialize_example(image_to_serialize, label_encoded)\n        writer.write(example)\n\nprint(\"\\\\nChuẩn bị dữ liệu ban đầu hoàn tất!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# HUẤN LUYỆN MÔ HÌNH Cross-Validation\n\n# --- BƯỚC 1: KHỞI TẠO CÁC BIẾN CẦN THIẾT ---\nprint(\"Đang khởi tạo các biến cho Cross-Validation...\")\nAUTOTUNE = tf.data.AUTOTUNE\nskf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n# Sử dụng train_val_df đã được tạo ở ô trước\ny_labels_for_split = le.transform(train_val_df['label'])\ngroups_for_split = train_val_df['patient_id'].values\n\nfold_accuracies, fold_losses, fold_aucs, fold_f1s = [], [], [], []\n\nprint(\"Đang tính toán trọng số alpha cho Focal Loss...\")\nclass_weights_array = class_weight.compute_class_weight('balanced', classes=np.unique(y_labels_for_split), y=y_labels_for_split)\nalpha_weights_list = class_weights_array.tolist()\nprint(\"Trọng số Alpha được tính toán:\")\nfor i, w in enumerate(alpha_weights_list):\n    class_name = le.inverse_transform([i])[0]\n    print(f\"- Lớp '{class_name}': {w:.2f}\")\n\n# --- BƯỚC 2: BẮT ĐẦU VÒNG LẶP CROSS-VALIDATION ---\nfor fold, (train_indices, val_indices) in enumerate(skf.split(train_val_df, y_labels_for_split, groups_for_split)):\n    fold_number = fold + 1\n    print(\"-\" * 50 + f\"\\\\nBắt đầu Fold {fold_number}/{N_SPLITS}\\\\n\" + \"-\" * 50)\n\n    checkpoint_filepath = os.path.join(CHECKPOINT_PATH, f'fold_{fold_number}_checkpoint.keras')\n    # Tạo model hoặc tải lại từ checkpoint\n    with strategy.scope():\n        if os.path.exists(checkpoint_filepath):\n            print(f\"--- Tìm thấy checkpoint, đang tải lại model từ: {checkpoint_filepath} ---\")\n            model = tf.keras.models.load_model(checkpoint_filepath, custom_objects={...}) # Điền custom objects\n        else:\n            print(\"--- Không tìm thấy checkpoint, tạo model mới ---\")\n            model = FinalModel(input_shape=INPUT_SHAPE, num_classes=len(ALL_CLASSES))\n            \n    # === TẠO FILE TFRECORD \"JUST-IN-TIME\" VỚI DỮ LIỆU THÔ ===\n    print(f\"--- Đang tạo file TFRecord (dữ liệu thô) cho Fold {fold_number} ---\")\n    train_fold_df = train_val_df.iloc[train_indices]\n    val_fold_df = train_val_df.iloc[val_indices]\n    \n    train_tfrec_path = os.path.join(TFRECORD_OUTPUT_PATH, f\"train_fold_{fold_number}.tfrec\")\n    val_tfrec_path = os.path.join(TFRECORD_OUTPUT_PATH, f\"val_fold_{fold_number}.tfrec\")\n\n    # Hàm trợ giúp để ghi dữ liệu THÔ, chưa qua xử lý\n    def write_raw_tfrecord(df, path, desc):\n        with tf.io.TFRecordWriter(path) as writer:\n            for _, row in tqdm(df.iterrows(), total=len(df), desc=desc):\n                # Chỉ load và serialize spectrogram gốc, không xử lý gì thêm\n                spectrogram = np.load(row['filepath']).astype(np.float32)\n                label_encoded = le.transform([row['label']])[0]\n                example = serialize_example(spectrogram, label_encoded)\n                writer.write(example)\n    \n    write_raw_tfrecord(train_fold_df, train_tfrec_path, f\"Writing Raw Train Fold {fold_number}\")\n    write_raw_tfrecord(val_fold_df, val_tfrec_path, f\"Writing Raw Val Fold {fold_number}\")\n    print(f\"--- Đã tạo xong file TFRecord (dữ liệu thô) cho Fold {fold_number} ---\")\n    \n    # Đọc trực tiếp file vừa tạo\n    train_ds = tf.data.TFRecordDataset(train_tfrec_path)\n    val_ds = tf.data.TFRecordDataset(val_tfrec_path)\n    train_ds = train_ds.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n    val_ds = val_ds.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n    train_ds = train_ds.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE).repeat().batch(GLOBAL_BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n    val_ds = val_ds.cache().batch(GLOBAL_BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n    \n    steps_per_epoch = len(train_indices) // GLOBAL_BATCH_SIZE\n    validation_steps = len(val_indices) // GLOBAL_BATCH_SIZE\n    print(f\"Số bước mỗi epoch: {steps_per_epoch} | Số bước validation: {validation_steps}\")\n\n\n    # --- TẠO MODEL VÀ LOSS FUNCTION ---\n    with strategy.scope():\n        model = FinalModel(input_shape=INPUT_SHAPE, num_classes=len(ALL_CLASSES))\n        if USE_FOCAL_LOSS:\n            loss_function = focal_loss_from_logits_optimized(alpha=alpha_weights_list, gamma=GAMMA)\n        else:\n            loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n\n    # --- GIAI ĐOẠN 1: HUẤN LUYỆN CÁC LỚP CUỐI (PHIÊN BẢN TỐI ƯU) ---\n    print(\"\\\\n--- Bắt đầu Giai đoạn 1: Huấn luyện các lớp cuối ---\")\n    \n    # Tạo callback EarlyStopping chỉ dành riêng cho giai đoạn này\n    head_early_stopping = EarlyStopping(\n        monitor='val_loss', \n        patience=5,  # Dừng lại nếu val_loss không cải thiện sau 5 epochs\n        restore_best_weights=True,\n        verbose=1\n    )\n\n    with strategy.scope():\n        # Đóng băng toàn bộ mô hình nền\n        model.base_model.trainable = False\n        \n        # Compile với learning rate lớn hơn cho head\n        optimizer_head = tf.keras.optimizers.AdamW(learning_rate=1e-3, weight_decay=WEIGHT_DECAY)\n        model.compile(optimizer=optimizer_head, \n                      loss=loss_function, \n                      metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n        \n        print(\"Bắt đầu huấn luyện head với Early Stopping...\")\n        # Huấn luyện cho tối đa 20 epochs, nhưng sẽ dừng sớm nếu cần\n        model.fit(train_ds, \n                  validation_data=val_ds, \n                  epochs=20,  # Tăng số epochs tối đa\n                  steps_per_epoch=steps_per_epoch, \n                  validation_steps=validation_steps, \n                  callbacks=[head_early_stopping], # Thêm callback vào đây\n                  verbose=1)\n\n        # 2. GIAI ĐOẠN 2A: WARMUP\n        print(f\"\\n--- Giai đoạn 2A: Bắt đầu Warmup trong {WARMUP_EPOCHS} epochs ---\")\n        warmup_lr = LEARNING_RATE / 10 # Bắt đầu với LR rất thấp\n        f1_macro = MacroF1Score(num_classes=len(ALL_CLASSES), name='f1_macro')\n        optimizer_warmup = tf.keras.optimizers.AdamW(learning_rate=warmup_lr, weight_decay=WEIGHT_DECAY)\n        model.compile(optimizer=optimizer_warmup, loss=loss_function, metrics=['accuracy', f1_macro])\n\n        model.fit(\n            train_ds, validation_data=val_ds, epochs=WARMUP_EPOCHS,\n            steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, verbose=1\n        )\n\n        # 3. GIAI ĐOẠN 2B: HUẤN LUYỆN CHÍNH VỚI COSINE DECAY RESTARTS\n        print(f\"\\n--- Giai đoạn 2B: Bắt đầu huấn luyện chính ---\")\n\n        # Sử dụng công tắc để chọn optimizer và callbacks\n        if USE_COSINE_DECAY_RESTARTS:\n            print(\"Sử dụng scheduler: CosineDecayRestarts\")\n            first_decay_steps = RESTART_CYCLE_1_EPOCHS * steps_per_epoch\n            lr_scheduler = tf.keras.optimizers.schedules.CosineDecayRestarts(\n                initial_learning_rate=LEARNING_RATE,\n                first_decay_steps=first_decay_steps,\n                t_mul=2.0, \n                m_mul=0.9,  \n                alpha=0.1\n            )\n            optimizer_finetune = tf.keras.optimizers.AdamW(learning_rate=lr_scheduler, weight_decay=WEIGHT_DECAY)\n            \n            # Callbacks cho CosineDecayRestarts\n            callbacks = [\n                EarlyStopping(\n                    monitor='val_f1_macro', mode='max', patience=PATIENCE_EPOCHS,\n                    restore_best_weights=True, min_delta=MIN_DELTA, verbose=1\n                ),\n                LearningRateLogger()\n            ]\n        else:\n            print(\"Sử dụng scheduler: ReduceLROnPlateau\")\n            # Optimizer với learning rate ban đầu cố định\n            optimizer_finetune = tf.keras.optimizers.AdamW(learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n            \n            # Callbacks cho ReduceLROnPlateau\n            callbacks = [\n                EarlyStopping(\n                    monitor='val_f1_macro', mode='max', patience=30, # Có thể cần patience dài hơn\n                    restore_best_weights=True, min_delta=MIN_DELTA, verbose=1\n                ),\n                tf.keras.callbacks.ReduceLROnPlateau(\n                    monitor='val_f1_macro', mode='max', factor=0.2,\n                    patience=10, # Giảm LR nếu F1 không cải thiện trong 10 epochs\n                    min_lr=1e-7,\n                    verbose=1\n                ),\n                LearningRateLogger()\n            ]\n\n        # Biên dịch lại mô hình với optimizer và metrics cuối cùng\n        with strategy.scope():\n            model.compile(optimizer=optimizer_finetune, loss=loss_function, metrics=['accuracy', tf.keras.metrics.AUC(name='auc'), f1_macro])\n        \n        # Huấn luyện mô hình\n        history = model.fit(\n            train_ds, validation_data=val_ds, epochs=TOTAL_EPOCHS,\n            initial_epoch=WARMUP_EPOCHS,\n            steps_per_epoch=steps_per_epoch, validation_steps=validation_steps,\n            callbacks=callbacks, verbose=1\n        )\n\n    # Tạo đường dẫn và tên file để lưu trọng số\n    weights_save_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_fold_{fold_number}.weights.h5')\n    # Chỉ lưu lại trọng số của mô hình\n    model.save_weights(weights_save_path)\n    # In ra thông báo để xác nhận\n    print(f\"Đã lưu trọng số cho Fold {fold_number} tại: {weights_save_path}\")\n\n    # --- VẼ BIỂU ĐỒ VÀ ĐÁNH GIÁ ---\n    print(\"Đang tạo và lưu biểu đồ huấn luyện...\")\n    plt.figure(figsize=(18, 7))\n    plt.suptitle(f'Training Metrics for Fold {fold_number}', fontsize=16)\n    \n    # --- Biểu đồ cho các chỉ số (Accuracy, AUC, F1-Macro) ---\n    plt.subplot(1, 2, 1)\n    # Vẽ các chỉ số của tập Train\n    plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue', linestyle='-')\n    plt.plot(history.history['auc'], label='Training AUC', color='green', linestyle='-')\n    plt.plot(history.history['f1_macro'], label='Training F1-Macro', color='red', linestyle='-')\n    \n    # Vẽ các chỉ số của tập Validation\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='blue', linestyle='--')\n    plt.plot(history.history['val_auc'], label='Validation AUC', color='green', linestyle='--')\n    plt.plot(history.history['val_f1_macro'], label='Validation F1-Macro', color='red', linestyle='--')\n    \n    # Cập nhật lại tiêu đề và nhãn\n    plt.title('Biểu đồ các chỉ số (Accuracy, AUC, F1-Macro)')\n    plt.xlabel('Epoch')\n    plt.ylabel('Giá trị')\n    plt.legend(loc='lower right')\n    plt.grid(True)\n    \n    # --- Biểu đồ cho Loss ---\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Training Loss', color='orange')\n    plt.plot(history.history['val_loss'], label='Validation Loss', color='purple')\n    plt.title('Biểu đồ Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n    plt.grid(True)\n    \n    # Lưu và đóng hình ảnh\n    plot_filename = f'fold_{fold_number}_metrics.png'\n    plot_filepath = os.path.join(KAGGLE_OUTPUT_PATH, plot_filename)\n    plt.savefig(plot_filepath)\n    plt.close()\n    \n    print(f\"Đã lưu biểu đồ cho Fold {fold_number} tại: {plot_filepath}\")\n    \n    # THÊM 4: Sửa lại model.evaluate để nhận đủ 4 giá trị\n    loss, accuracy, auc, f1 = model.evaluate(val_ds, verbose=0)\n    print(f\"Fold {fold_number} - Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}, Validation AUC: {auc:.4f}, Validation F1-Macro: {f1:.4f}\")\n    \n    fold_aucs.append(auc)\n    fold_losses.append(loss)\n    fold_accuracies.append(accuracy)\n    fold_f1s.append(f1) # Thêm lưu trữ F1\n\n    # THÊM 5: Sửa lại câu lệnh print cuối cùng\n    print(\"=\" * 50 + \"\\nKết quả Cross-Validation:\\n\" \n      + f\"Validation Accuracy trung bình: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\\n\"\n      + f\"Validation Loss trung bình: {np.mean(fold_losses):.4f} +/- {np.std(fold_losses):.4f}\\n\"\n      + f\"Validation AUC trung bình: {np.mean(fold_aucs):.4f} +/- {np.std(fold_aucs):.4f}\\n\"\n      + f\"Validation F1-Macro trung bình: {np.mean(fold_f1s):.4f} +/- {np.std(fold_f1s):.4f}\\n\" # Thêm dòng này\n      + \"=\" * 50)\n    print(f\"\\\\n--- Dọn dẹp file cho Fold {fold_number} ---\")\n    try:\n        os.remove(train_tfrec_path)\n        os.remove(val_tfrec_path)\n        print(f\"Đã xóa thành công file tạm của Fold {fold_number}\")\n    except OSError as e:\n        print(f\"Lỗi khi xóa file: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Bắt đầu quy trình đánh giá tổng hợp 5-Fold trên tập test ---\n\nprint(\"--- Chuẩn bị dữ liệu Test cho việc đánh giá ---\")\n\n# 1. Tạo Test Dataset từ file TFRecord đã được xử lý trước\nTEST_TFREC_PATH = os.path.join(TFRECORD_OUTPUT_PATH, \"test.tfrec\")\nif not os.path.exists(TEST_TFREC_PATH):\n    print(f\"Lỗi: Không tìm thấy file test.tfrec tại {TEST_TFREC_PATH}. Vui lòng chạy lại ô chuẩn bị dữ liệu.\")\nelse:\n    # Tạo dataset đã được batch để đưa vào model.evaluate\n    test_ds_batched = tf.data.TFRecordDataset(TEST_TFREC_PATH)\n    test_ds_batched = test_ds_batched.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n    test_ds_batched = test_ds_batched.batch(GLOBAL_BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\n    # --- Bắt đầu quá trình đánh giá ---\n    evaluation_results = []\n    output_filename = \"teacher_models_evaluation_summary.csv\"\n    output_filepath = os.path.join(KAGGLE_OUTPUT_PATH, output_filename)\n    n_classes = len(ALL_CLASSES)\n\n    # Vòng lặp qua 5 Fold để tải và đánh giá từng mô hình\n    for fold_number in range(1, N_SPLITS + 1):\n        print(f\"\\\\n---> Đang đánh giá Fold {fold_number}/{N_SPLITS}...\")\n        \n        model_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_fold_{fold_number}.keras')\n        \n        if not os.path.exists(model_path):\n            print(f\"!!! Cảnh báo: Không tìm thấy file model cho Fold {fold_number} tại '{model_path}'. Bỏ qua fold này.\")\n            continue\n\n        try:\n            with strategy.scope():\n                # Tải lại mô hình đã huấn luyện\n                model = tf.keras.models.load_model(\n                    model_path,\n                    custom_objects={\n                        'focal_loss_fixed': focal_loss_from_logits_optimized(alpha=alpha_weights_list),\n                        'MacroF1Score': MacroF1Score\n                    }\n                )\n                \n                # Biên dịch lại mô hình để đảm bảo các metrics được tính đúng\n                model.compile(\n                    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n                    optimizer='adam', # Optimizer ở đây không quan trọng vì không huấn luyện lại\n                    metrics=[\n                        'accuracy', \n                        tf.keras.metrics.AUC(name='auc'), \n                        MacroF1Score(num_classes=n_classes, name='f1_macro')\n                    ]\n                )\n\n            # Đánh giá mô hình trên tập Test đã được batch\n            print(f\"Bắt đầu tính toán các chỉ số cho Fold {fold_number}...\")\n            results = model.evaluate(test_ds_batched, return_dict=True, verbose=0)\n            \n            # Lưu kết quả của fold hiện tại\n            fold_summary = {\n                'Fold': fold_number,\n                'Loss': results.get('loss', 0),\n                'Accuracy': results.get('accuracy', 0),\n                'AUC': results.get('auc', 0),\n                'F1-Macro': results.get('f1_macro', 0)\n            }\n            evaluation_results.append(fold_summary)\n            print(f\"Kết quả Fold {fold_number}: {fold_summary}\")\n\n        except Exception as e:\n            print(f\"!!! Lỗi khi xử lý Fold {fold_number}: {e}\")\n\n    # --- Tổng hợp và Lưu kết quả ra file CSV ---\n    if evaluation_results:\n        results_df = pd.DataFrame(evaluation_results)\n        \n        # Tính toán giá trị trung bình và độ lệch chuẩn\n        summary_stats = results_df.drop('Fold', axis=1).agg(['mean', 'std'])\n        print(\"\\\\n\\\\n--- Thống kê tổng hợp (5 Folds) trên tập Test ---\")\n        print(summary_stats)\n        \n        # Tạo dòng tổng kết để thêm vào file CSV\n        summary_stats_df = summary_stats.reset_index().rename(columns={'index': 'Fold'})\n        \n        # Ghép kết quả chi tiết và kết quả tổng hợp\n        final_df_to_save = pd.concat([results_df, summary_stats_df], ignore_index=True)\n        \n        final_df_to_save.to_csv(output_filepath, index=False, float_format='%.4f')\n        print(f\"\\\\n--- HOÀN TẤT ---\")\n        print(f\"Bảng kết quả tổng hợp đã được lưu tại: {output_filepath}\")\n        \n        print(\"\\\\nNội dung file CSV:\")\n        print(final_df_to_save.to_string(index=False))\n    else:\n        print(\"\\\\nKhông có fold nào được đánh giá thành công. Không có file CSV nào được tạo.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Bắt đầu quy trình vẽ đường cong ROC trung bình 5-Fold ---\n\nprint(\"--- Chuẩn bị dữ liệu Test cho việc vẽ ROC ---\")\n\n# 1. Tạo Test Dataset và trích xuất nhãn thật\nTEST_TFREC_PATH = os.path.join(TFRECORD_OUTPUT_PATH, \"test.tfrec\")\nif not os.path.exists(TEST_TFREC_PATH):\n    print(f\"Lỗi: Không tìm thấy file test.tfrec tại {TEST_TFREC_PATH}. Vui lòng chạy lại ô chuẩn bị dữ liệu.\")\nelse:\n    # Tạo dataset gốc để lấy nhãn\n    test_ds_unbatched = tf.data.TFRecordDataset(TEST_TFREC_PATH)\n    test_ds_unbatched = test_ds_unbatched.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n    \n    # Tạo dataset đã được batch để lấy dự đoán\n    test_ds_batched = test_ds_unbatched.batch(GLOBAL_BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\n    print(\"Đang trích xuất nhãn từ tập test...\")\n    y_test_onehot = np.concatenate([y.numpy() for x, y in test_ds_unbatched], axis=0)\n    print(f\"Đã trích xuất xong {len(y_test_onehot)} nhãn.\")\n\n    # --- Bắt đầu quá trình lấy dự đoán và vẽ biểu đồ ---\n    y_test_binarized = y_test_onehot\n    n_classes = y_test_binarized.shape[1]\n    class_names = le.classes_\n    \n    all_y_preds_probs = []\n    print(\"\\\\nĐang tải 5 model và lấy dự đoán từ 5 folds...\")\n    for fold_number in tqdm(range(1, N_SPLITS + 1), desc=\"Processing Folds for ROC\"):\n        model_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_fold_{fold_number}.keras')\n        if not os.path.exists(model_path):\n            continue\n        \n        with strategy.scope():\n            model = tf.keras.models.load_model(\n                model_path,\n                custom_objects={\n                    'focal_loss_fixed': focal_loss_from_logits_optimized(alpha=alpha_weights_list),\n                    'MacroF1Score': MacroF1Score\n                }\n            )\n        \n        all_logits = []\n        for images_batch, _ in test_ds_batched:\n            batch_logits = model(images_batch, training=False)\n            all_logits.append(batch_logits.numpy())\n        \n        y_pred_logits = np.concatenate(all_logits, axis=0)\n        y_pred_probs = tf.nn.softmax(y_pred_logits).numpy()\n        all_y_preds_probs.append(y_pred_probs)\n\n    # --- Tính toán ROC và nội suy ---\n    print(\"\\\\nĐang tính toán ROC và nội suy...\")\n    tprs_per_class = [[] for _ in range(n_classes)]\n    aucs_per_class = [[] for _ in range(n_classes)]\n    mean_fpr = np.linspace(0, 1, 100)\n\n    for y_pred_probs in all_y_preds_probs:\n        for i in range(n_classes):\n            fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_pred_probs[:, i])\n            interp_tpr = np.interp(mean_fpr, fpr, tpr)\n            interp_tpr[0] = 0.0\n            tprs_per_class[i].append(interp_tpr)\n            aucs_per_class[i].append(sklearn_auc(fpr, tpr))\n\n    # --- Vẽ biểu đồ ---\n    print(\"Đang vẽ biểu đồ...\")\n    plt.figure(figsize=(12, 10))\n    colors = plt.cm.get_cmap('tab10', n_classes)\n\n    for i in range(n_classes):\n        mean_tpr = np.mean(tprs_per_class[i], axis=0)\n        mean_tpr[-1] = 1.0\n        std_tpr = np.std(tprs_per_class[i], axis=0)\n        mean_auc = np.mean(aucs_per_class[i])\n        std_auc = np.std(aucs_per_class[i])\n\n        plt.plot(mean_fpr, mean_tpr, color=colors(i),\n                 label=f'Lớp: {class_names[i]} (AUC = {mean_auc:.2f} $\\\\pm$ {std_auc:.2f})',\n                 lw=2)\n        \n        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n        plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color=colors(i), alpha=.2)\n\n    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate', fontsize=14)\n    plt.ylabel('True Positive Rate', fontsize=14)\n    plt.title('Đường cong ROC trung bình (5-Fold Cross-Validation)', fontsize=16)\n    plt.legend(loc=\"lower right\", fontsize=12)\n    plt.grid(True)\n    \n    output_filename = \"roc_curve_5_folds_average.png\"\n    output_filepath = os.path.join(KAGGLE_OUTPUT_PATH, output_filename)\n    plt.savefig(output_filepath, dpi=300)\n    print(f\"\\\\nHoàn tất! Biểu đồ đã được lưu tại: {output_filepath}\")\n    \n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Bắt đầu quy trình phân tích Grad-CAM chi tiết cho 5 Folds ---\n\nprint(\"--- Chuẩn bị dữ liệu Test cho việc phân tích Grad-CAM ---\")\n\n# 1. Tạo Test Dataset từ file TFRecord đã được xử lý trước\n# Lưu ý: Các biến TFRECORD_OUTPUT_PATH, parse_tfrecord_fn, GLOBAL_BATCH_SIZE, AUTOTUNE\n# đã được định nghĩa ở các ô code phía trên.\nTEST_TFREC_PATH = os.path.join(TFRECORD_OUTPUT_PATH, \"test.tfrec\")\nif not os.path.exists(TEST_TFREC_PATH):\n    print(f\"Lỗi: Không tìm thấy file test.tfrec tại {TEST_TFREC_PATH}. Vui lòng chạy lại ô chuẩn bị dữ liệu.\")\nelse:\n    test_ds_batched = tf.data.TFRecordDataset(TEST_TFREC_PATH)\n    test_ds_batched = test_ds_batched.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n    test_ds_batched = test_ds_batched.batch(GLOBAL_BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\n    # --- Định nghĩa các hàm cần thiết cho Grad-CAM ---\n    target_names = le.classes_\n    grad_cam_main_path = os.path.join(KAGGLE_OUTPUT_PATH, \"grad_cam_detailed_analysis\")\n    os.makedirs(grad_cam_main_path, exist_ok=True)\n\n    def find_last_conv_layer(model):\n        for layer in reversed(model.layers):\n            if isinstance(layer, tf.keras.layers.Conv2D):\n                return layer\n            if isinstance(layer, tf.keras.Model):\n                return find_last_conv_layer(layer)\n        return None\n\n    @tf.function\n    def get_grad_cam_batched(model, img_batch):\n        if hasattr(model, 'base_model'):\n            inp = model.base_model.input\n            last_conv_layer = model.base_model.get_layer(\"top_conv\")\n            x = model.pooling(model.base_model.output)\n            x = model.dense1(x)\n            if hasattr(model, 'dense2'): # Thích ứng với head phức tạp hơn\n                x = model.dense2(x)\n            final_output = model.dense_output(x)\n            grad_model = Model(inp, [last_conv_layer.output, final_output])\n        else:\n            last_conv_layer = find_last_conv_layer(model)\n            grad_model = Model([model.inputs], [last_conv_layer.output, model.output])\n        \n        with tf.GradientTape() as tape:\n            last_conv_layer_output_value, preds = grad_model(img_batch)\n            pred_indices = tf.argmax(preds, axis=1)\n            class_channels = tf.gather(preds, pred_indices, axis=1, batch_dims=1)\n\n        grads = tape.gradient(class_channels, last_conv_layer_output_value)\n        pooled_grads = tf.reduce_mean(grads, axis=(1, 2))\n        heatmap_batch = tf.einsum('bhwc,bc->bhw', last_conv_layer_output_value, pooled_grads)\n        heatmap_batch = tf.maximum(heatmap_batch, 0)\n        max_vals = tf.reduce_max(heatmap_batch, axis=(1, 2), keepdims=True)\n        heatmap_batch = heatmap_batch / (max_vals + tf.keras.backend.epsilon())\n        return heatmap_batch, preds\n\n    def run_grad_cam_analysis_final(model, model_name, output_base_path, test_dataset):\n        print(f\"\\\\n--- Bắt đầu phân tích cho mô hình: {model_name} ---\")\n        results_by_class = { name: {'correct_heatmaps': [], 'correct_confidences': [], 'correct_images': [],\n                                    'incorrect_heatmaps': [], 'incorrect_confidences': [], 'incorrect_images': []}\n                            for name in target_names }\n\n        print(\"  - Xử lý các batch trên TPU...\")\n        for images_batch, labels_batch in tqdm(test_dataset, desc=f\"Analyzing {model_name}\"):\n            heatmap_batch, preds_batch = get_grad_cam_batched(model, images_batch)\n            y_pred_probs_batch = tf.nn.softmax(preds_batch).numpy()\n            y_pred_batch = np.argmax(y_pred_probs_batch, axis=1)\n            y_true_batch = np.argmax(labels_batch.numpy(), axis=1)\n\n            for i in range(images_batch.shape[0]):\n                y_pred, y_true = y_pred_batch[i], y_true_batch[i]\n                true_class_name = target_names[y_true]\n                \n                if y_pred == y_true:\n                    results_by_class[true_class_name]['correct_heatmaps'].append(heatmap_batch[i].numpy())\n                    results_by_class[true_class_name]['correct_confidences'].append(y_pred_probs_batch[i, y_pred])\n                    results_by_class[true_class_name]['correct_images'].append(images_batch[i].numpy())\n                else:\n                    results_by_class[true_class_name]['incorrect_heatmaps'].append(heatmap_batch[i].numpy())\n                    results_by_class[true_class_name]['incorrect_confidences'].append(y_pred_probs_batch[i, y_pred])\n                    results_by_class[true_class_name]['incorrect_images'].append(images_batch[i].numpy())\n\n        print(\"  - Đang lưu ảnh Grad-CAM và ảnh spectrogram cho các mẫu tiêu biểu...\")\n        for class_name in target_names:\n            class_output_path = os.path.join(output_base_path, class_name)\n            os.makedirs(class_output_path, exist_ok=True)\n            class_results = results_by_class[class_name]\n\n            if class_results['correct_confidences']:\n                best_idx = np.argmax(class_results['correct_confidences'])\n                image = class_results['correct_images'][best_idx]\n                heatmap = class_results['correct_heatmaps'][best_idx]\n                overlay = overlay_grad_cam(image[:, :, 0], heatmap)\n                gradcam_filename = f\"{model_name}_{class_name}_exemplar_correct_gradcam.png\"\n                plt.imsave(os.path.join(class_output_path, gradcam_filename), overlay)\n                spectrogram_filename = f\"{model_name}_{class_name}_exemplar_correct_spectrogram.png\"\n                plt.imsave(os.path.join(class_output_path, spectrogram_filename), image[:, :, 0], cmap='viridis')\n\n            if class_results['incorrect_confidences']:\n                worst_idx = np.argmax(class_results['incorrect_confidences'])\n                image = class_results['incorrect_images'][worst_idx]\n                heatmap = class_results['incorrect_heatmaps'][worst_idx]\n                overlay = overlay_grad_cam(image[:, :, 0], heatmap)\n                gradcam_filename = f\"{model_name}_{class_name}_exemplar_incorrect_gradcam.png\"\n                plt.imsave(os.path.join(class_output_path, gradcam_filename), overlay)\n                spectrogram_filename = f\"{model_name}_{class_name}_exemplar_incorrect_spectrogram.png\"\n                plt.imsave(os.path.join(class_output_path, spectrogram_filename), image[:, :, 0], cmap='viridis')\n\n    # --- VÒNG LẶP CHÍNH ĐỂ PHÂN TÍCH 5 FOLDS ---\n    teacher_models_main_path = os.path.join(grad_cam_main_path, \"teacher_models\")\n    os.makedirs(teacher_models_main_path, exist_ok=True)\n\n    for fold_number in range(1, N_SPLITS + 1):\n        print(f\"\\\\n---> Bắt đầu phân tích Grad-CAM cho Fold {fold_number}/{N_SPLITS}...\")\n        model_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_fold_{fold_number}.keras')\n        \n        if not os.path.exists(model_path):\n            print(f\"Bỏ qua Fold {fold_number}, không tìm thấy file: {model_path}\")\n            continue\n        \n        try:\n            with strategy.scope():\n                teacher_model = tf.keras.models.load_model(\n                    model_path,\n                    custom_objects={\n                        'focal_loss_fixed': focal_loss_from_logits_optimized(alpha=alpha_weights_list),\n                        'MacroF1Score': MacroF1Score \n                    }\n                )\n            \n            model_name = f\"fold_{fold_number}\"\n            fold_output_path = os.path.join(teacher_models_main_path, model_name)\n            os.makedirs(fold_output_path, exist_ok=True)\n            \n            # Gọi hàm phân tích với dataset đã được chuẩn bị\n            run_grad_cam_analysis_final(teacher_model, model_name, fold_output_path, test_ds_batched)\n        \n        except Exception as e:\n            print(f\"!!! Lỗi khi phân tích Grad-CAM cho Fold {fold_number}: {e}\")\n\n    print(\"\\\\n--- Toàn bộ quá trình phân tích Grad-CAM đã hoàn tất ---\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- BƯỚC TỐI ƯU & CHUYỂN ĐỔI CẢ 5 MÔ HÌNH SANG TFLITE (POST-TRAINING) ---\n\nprint(\"--- Bắt đầu quy trình chuyển đổi 5-Fold sang TFLite ---\")\n\n# Kiểm tra xem quá trình huấn luyện đã hoàn tất và có đủ kết quả chưa\nif 'fold_f1s' in locals() and len(fold_f1s) == N_SPLITS:\n    \n    # Lấy thông tin chia fold một lần để tái sử dụng\n    skf_split = list(skf.split(train_val_df, y_labels_for_split, groups_for_split))\n\n    # === BẮT ĐẦU VÒNG LẶP QUA 5 FOLDS ===\n    for fold_index in range(N_SPLITS):\n        fold_number = fold_index + 1\n        print(\"=\" * 60)\n        print(f\"--- Bắt đầu chuyển đổi cho Fold {fold_number} ---\")\n        \n        # 1. Xác định đường dẫn cho fold hiện tại\n        SAVED_MODEL_PATH = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_fold_{fold_number}')\n        TFLITE_MODEL_PATH = os.path.join(KAGGLE_OUTPUT_PATH, f'model_fold_{fold_number}_quantized.tflite')\n\n        if not os.path.exists(SAVED_MODEL_PATH):\n            print(f\"Lỗi: Không tìm thấy thư mục model tại '{SAVED_MODEL_PATH}'. Bỏ qua fold này.\")\n            continue\n\n        # 2. Tạo Representative Dataset từ tập validation của CHÍNH FOLD NÀY\n        print(f\"Đang tạo representative dataset cho Fold {fold_number}...\")\n        _, val_indices = skf_split[fold_index]\n        val_df_for_calib = train_val_df.iloc[val_indices]\n\n        def representative_data_gen():\n            for _, row in val_df_for_calib.sample(n=min(150, len(val_df_for_calib)), random_state=SEED).iterrows():\n                spectrogram = np.load(row['filepath']).astype(np.float32)\n                \n                image_tensor = tf.convert_to_tensor(spectrogram)\n                image_3d = tf.stack([image_tensor]*3, axis=-1)\n                image_resized = tf.image.resize(image_3d, [INPUT_SHAPE[0], INPUT_SHAPE[1]])\n                min_val = tf.reduce_min(image_resized)\n                max_val = tf.reduce_max(image_resized)\n                image_scaled_01 = (image_resized - min_val) / (max_val - min_val + 1e-7)\n                image_scaled_255 = image_scaled_01 * 255.0\n                image_preprocessed = preprocess_input(image_scaled_255)\n                \n                yield [tf.expand_dims(image_preprocessed, axis=0)]\n\n        # 3. Chuyển đổi và Lượng tử hóa\n        print(f\"Đang chuyển đổi mô hình của Fold {fold_number}...\")\n        converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_PATH)\n        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n        converter.representative_dataset = representative_data_gen\n        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n        \n        tflite_quant_model = converter.convert()\n\n        # 4. Lưu file TFLite\n        with open(TFLITE_MODEL_PATH, 'wb') as f:\n            f.write(tflite_quant_model)\n        \n        print(f\"Đã lưu thành công model TFLite cho Fold {fold_number} tại: {TFLITE_MODEL_PATH}\")\n        print(f\"Kích thước file: {len(tflite_quant_model) / (1024 * 1024):.2f} MB\")\n\n    print(\"=\" * 60)\n    print(\"\\\\n Hoàn tất chuyển đổi cho cả 5 mô hình!\")\n\nelse:\n    print(\"Lỗi: Không tìm thấy kết quả của 5 fold ('fold_f1s'). Vui lòng chạy ô huấn luyện trước khi chạy ô này.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}