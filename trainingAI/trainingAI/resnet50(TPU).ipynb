{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.18","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":12870874,"sourceType":"datasetVersion","datasetId":8141736}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# CÀI ĐẶT & CẤU HÌNH (SETUP & CONFIGURATION)\n\n# 0.1. Cài đặt các thư viện cần thiết\n!pip install -q fpdf2 noisereduce librosa tensorflow scikit-learn matplotlib seaborn pytz PyDrive2\n\n# 0.2. Import thư viện\nimport os\nimport glob\nimport random\nimport datetime\nimport pytz\nimport shutil\nimport joblib\nimport zipfile\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\nfrom fpdf import FPDF\nfrom tqdm import tqdm\nimport librosa\nimport noisereduce as nr\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D, AveragePooling2D\nfrom tensorflow.keras.applications import ResNet50V2\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom pydrive2.auth import GoogleAuth\nfrom pydrive2.drive import GoogleDrive\nfrom kaggle_secrets import UserSecretsClient\nfrom oauth2client.service_account import ServiceAccountCredentials\nfrom tensorflow.keras.regularizers import l2\nfrom kaggle_datasets import KaggleDatasets\ntry:\n    # Cố gắng kết nối với TPU bằng cách chỉ định tpu='local'\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\n    print('Đã tìm thấy TPU Resolver.')\n    \n    # Kết nối và khởi tạo hệ thống TPU\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    print('Đã khởi tạo hệ thống TPU.')\n\n    # Tạo strategy\n    strategy = tf.distribute.TPUStrategy(tpu)\n    print('THÀNH CÔNG: Đã tạo TPUStrategy!')\n    print(f'Số lượng nhân (replicas): {strategy.num_replicas_in_sync}')\n    \nexcept (ValueError, RuntimeError) as e:\n    # Nếu vẫn không tìm thấy TPU, tự động chuyển về chiến lược mặc định\n    print(f'Lỗi kết nối TPU: {e}')\n    print('Không tìm thấy TPU. Sử dụng chiến lược mặc định cho GPU/CPU.')\n    strategy = tf.distribute.get_strategy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T04:52:31.822187Z","iopub.execute_input":"2025-08-27T04:52:31.822409Z","iopub.status.idle":"2025-08-27T04:53:47.614851Z","shell.execute_reply.started":"2025-08-27T04:52:31.822384Z","shell.execute_reply":"2025-08-27T04:53:47.609087Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\nWARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1756270405.633710      10 common_lib.cc:612] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:230\n","output_type":"stream"},{"name":"stdout","text":"Đã tìm thấy TPU Resolver.\nINFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1756270423.501540      10 service.cc:148] XLA service 0x5a7224f9d550 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1756270423.501616      10 service.cc:156]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1756270423.501622      10 service.cc:156]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1756270423.501625      10 service.cc:156]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1756270423.501628      10 service.cc:156]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1756270423.501630      10 service.cc:156]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1756270423.501633      10 service.cc:156]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1756270423.501636      10 service.cc:156]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1756270423.501639      10 service.cc:156]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nĐã khởi tạo hệ thống TPU.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\nTHÀNH CÔNG: Đã tạo TPUStrategy!\nSố lượng nhân (replicas): 8\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# THIẾT LẬP CẤU HÌNH \n\n# --- Các cấu hình cơ bản ---\nSEED = 42\ndef set_seed(seed_value):\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    #os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    tf.random.set_seed(seed_value)\nset_seed(SEED)\n\nKAGGLE_PROCESSED_DATA_PATH = \"/kaggle/input/ngt-spectrogram-id/\"\nKAGGLE_OUTPUT_PATH = \"/kaggle/working/output_results\"\nos.makedirs(KAGGLE_OUTPUT_PATH, exist_ok=True)\n\nCLASSES_TO_TRAIN = ['covid', 'asthma', 'healthy', 'tuberculosis']\nALL_CLASSES = ['healthy', 'asthma', 'covid', 'tuberculosis']\nN_SPLITS = 5\nTEST_SPLIT_RATIO = 0.15\nUSE_DATA_AUGMENTATION = False # Bật/tắt augmentation ở đây\nUSE_FOCAL_LOSS = True\n\nMODEL_ID = f'ResNet50V2_CV_TPU'\nEPOCHS = 50\nEARLY_STOPPING_PATIENCE = 7\nMIN_DELTA = 1e-4\nSHUFFLE_BUFFER_SIZE = 512 \n\n# --- ĐỊNH NGHĨA BATCH SIZE ---\n# BATCH_SIZE này là batch size cho mỗi nhân TPU (per-replica)\nBATCH_SIZE = 16\n# Tính toán GLOBAL_BATCH_SIZE để dùng trong pipeline\n# Biến 'strategy' được lấy từ ô code đầu tiên\nGLOBAL_BATCH_SIZE = BATCH_SIZE * strategy.num_replicas_in_sync\nprint(f\"Batch size mỗi nhân: {BATCH_SIZE}\")\nprint(f\"Global batch size (tổng cộng): {GLOBAL_BATCH_SIZE}\")\n\nLEARNING_RATE = 3e-5\n# INPUT_SHAPE sẽ được cập nhật lại ở ô chuẩn bị dữ liệu\nINPUT_SHAPE = (256, 126, 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T04:53:47.616945Z","iopub.execute_input":"2025-08-27T04:53:47.617153Z","iopub.status.idle":"2025-08-27T04:53:47.630990Z","shell.execute_reply.started":"2025-08-27T04:53:47.617132Z","shell.execute_reply":"2025-08-27T04:53:47.625781Z"}},"outputs":[{"name":"stdout","text":"Batch size mỗi nhân: 16\nGlobal batch size (tổng cộng): 128\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# KHỞI TẠO CÁC HÀM CẦN THIẾT (PHIÊN BẢN ĐÚNG)\n\ndef get_patient_id(filepath, class_name):\n    filename = os.path.basename(filepath)\n    if class_name.lower() in ['asthma', 'covid', 'healthy']:\n        return filename.split('_')[0]\n    elif class_name.lower() == 'tuberculosis':\n        return '_'.join(filename.split('_')[:-1]).replace('.npy', '')\n    else:\n        return filename.split('_')[0]\n\ndef parse_tfrecord_fn(example):\n    \"\"\"Hàm đọc và xử lý một mẫu từ file TFRecord.\"\"\"\n    feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'label': tf.io.FixedLenFeature([], tf.int64),\n    }\n    example = tf.io.parse_single_example(example, feature_description)\n    image = tf.io.parse_tensor(example['image'], out_type=tf.float32)\n    image = tf.reshape(image, (256, 126))\n    image = tf.stack([image, image, image], axis=-1)\n    image.set_shape(INPUT_SHAPE)\n    image_shape = tf.shape(image)\n    image_flat = tf.reshape(image, (1, -1))\n    def _scale(data):\n        scaled_data = scaler.transform(data)\n        return np.nan_to_num(scaled_data).astype(np.float32)\n    scaled_flat = tf.numpy_function(_scale, [image_flat], tf.float32)\n    image_scaled = tf.reshape(scaled_flat, image_shape)\n    label_encoded = tf.cast(example['label'], tf.int32)\n    label_onehot = tf.one_hot(label_encoded, depth=len(ALL_CLASSES))\n    return image_scaled, label_onehot\n\ndef augment(spectrogram, label):\n    spectrogram = spec_augment(spectrogram)\n    return spectrogram, label\n\ndef focal_loss_from_logits_optimized(active_indices, gamma=2.0, alpha=0.25):\n    \"\"\"Hàm Focal Loss phiên bản tối ưu.\"\"\"\n    def focal_loss_fixed(y_true, y_pred):\n        y_true = tf.cast(y_true, 'float32')\n        y_true_filtered = tf.gather(y_true, active_indices, axis=-1)\n        y_pred_filtered = tf.gather(y_pred, active_indices, axis=-1)\n        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true_filtered, logits=y_pred_filtered)\n        probs = tf.nn.softmax(y_pred_filtered)\n        pt = tf.reduce_sum(y_true_filtered * probs, axis=-1)\n        focal_term = (1.0 - pt) ** gamma\n        loss = alpha * focal_term * cross_entropy\n        return loss\n    return focal_loss_fixed\n\ndef spec_augment(spectrogram, time_masking_para=40, frequency_masking_para=30,\n                 num_time_masks=1, num_freq_masks=1):\n    \"\"\"\n    Hàm SpecAugment đã được sửa lỗi để làm việc với tensor 4D (batch, freq, time, channels).\n    \"\"\"\n    spectrogram_aug = spectrogram\n    \n    # Lấy ra các chiều để làm việc từ shape 4D\n    # tf.shape(spectrogram) = [batch, freq, time, channels]\n    freq_bins = tf.shape(spectrogram)[1]\n    time_steps = tf.shape(spectrogram)[2]\n\n    # --- 1. Frequency Masking ---\n    for _ in range(num_freq_masks):\n        f = tf.random.uniform(shape=(), minval=0, maxval=frequency_masking_para, dtype=tf.int32)\n        f0 = tf.random.uniform(shape=(), minval=0, maxval=freq_bins - f, dtype=tf.int32)\n\n        # Tạo mặt nạ 1D cho chiều tần số\n        freq_mask_1d = tf.concat([\n            tf.ones(shape=(f0,), dtype=spectrogram.dtype),\n            tf.zeros(shape=(f,), dtype=spectrogram.dtype),\n            tf.ones(shape=(freq_bins - f0 - f,), dtype=spectrogram.dtype)\n        ], axis=0)\n        \n        # Reshape mặt nạ để broadcast qua cả 4 chiều\n        # Shape sẽ là (1, freq, 1, 1) để broadcast qua batch, time, và channels\n        freq_mask_4d = tf.reshape(freq_mask_1d, (1, freq_bins, 1, 1))\n        spectrogram_aug = spectrogram_aug * freq_mask_4d\n\n    # --- 2. Time Masking ---\n    for _ in range(num_time_masks):\n        t = tf.random.uniform(shape=(), minval=0, maxval=time_masking_para, dtype=tf.int32)\n        t0 = tf.random.uniform(shape=(), minval=0, maxval=time_steps - t, dtype=tf.int32)\n\n        # Tạo mặt nạ 1D cho chiều thời gian\n        time_mask_1d = tf.concat([\n            tf.ones(shape=(t0,), dtype=spectrogram.dtype),\n            tf.zeros(shape=(t,), dtype=spectrogram.dtype),\n            tf.ones(shape=(time_steps - t0 - t,), dtype=spectrogram.dtype)\n        ], axis=0)\n\n        # Reshape mặt nạ để broadcast qua cả 4 chiều\n        # Shape sẽ là (1, 1, time, 1) để broadcast qua batch, freq, và channels\n        time_mask_4d = tf.reshape(time_mask_1d, (1, 1, time_steps, 1))\n        spectrogram_aug = spectrogram_aug * time_mask_4d\n        \n    return spectrogram_aug\n\n\ndef create_model(input_shape, num_classes):\n    # 1. Khởi tạo mô hình gốc\n    base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n    \n    # 2. Đóng băng các lớp ban đầu\n    for layer in base_model.layers[:100]:\n        layer.trainable = False\n    base_model.trainable = True \n    \n    # 3. Xây dựng phần đầu ra\n    inputs = Input(shape=input_shape)\n    x = base_model(inputs, training=True) \n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.5)(x)\n    outputs = Dense(num_classes, activation='linear', kernel_regularizer=l2(0.001))(x) \n    \n    return Model(inputs, outputs)\n\ndef load_data_from_df(df):\n    X, y = [], []\n    for _, row in df.iterrows():\n        X.append(np.load(row['filepath']))\n        y.append(row['label'])\n    return np.array(X), np.array(y)\n\ndef get_grad_cam(model, img_array, last_conv_layer_name, pred_index=None):\n    grad_model = Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(tf.cast(img_array, tf.float32))\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\ndef overlay_grad_cam(spec, heatmap, alpha=0.6):\n    heatmap_resized = tf.image.resize(heatmap[..., np.newaxis], (spec.shape[0], spec.shape[1]))\n    heatmap_resized = np.uint8(255 * heatmap_resized)\n    jet = plt.cm.get_cmap(\"jet\")\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap_resized.squeeze()]\n    spec_display = np.stack([spec]*3, axis=-1)\n    spec_display = (spec_display - spec_display.min()) / (spec_display.max() - spec_display.min())\n    superimposed_img = jet_heatmap * alpha + spec_display\n    superimposed_img = np.clip(superimposed_img, 0, 1)\n    return superimposed_img\n\nclass PDFReport(FPDF):\n    def header(self):\n        self.set_font('Arial', 'B', 12)\n        self.cell(0, 10, 'BAO CAO KET QUA HUAN LUYEN MO HINH AI', 0, 1, 'C')\n        self.ln(10)\n    def footer(self):\n        self.set_y(-15)\n        self.set_font('Arial', 'I', 8)\n        self.cell(0, 10, f'Trang {self.page_no()}', 0, 0, 'C')\n    def chapter_title(self, title):\n        self.set_font('Arial', 'B', 12)\n        self.cell(0, 10, title, 0, 1, 'L')\n        self.ln(5)\n    def chapter_body(self, content):\n        self.set_font('Arial', '', 10)\n        safe_content = content.encode('latin-1', 'replace').decode('latin-1')\n        self.multi_cell(0, 5, safe_content)\n        self.ln()\n    def add_image_section(self, title, img_path):\n        self.chapter_title(title)\n        if os.path.exists(img_path):\n            self.image(img_path, x=None, y=None, w=180)\n            self.ln(5)\n        else:\n            self.chapter_body(f\"Khong tim thay hinh anh: {img_path}\")\n\ndef authenticate_gdrive():\n    user_secrets = UserSecretsClient()\n    secret_value = user_secrets.get_secret(\"google_service_account_key\")\n    with open(\"service_account.json\", \"w\") as f:\n        f.write(secret_value)\n    scope = [\"https://www.googleapis.com/auth/drive\"]\n    gauth = GoogleAuth()\n    gauth.credentials = ServiceAccountCredentials.from_json_keyfile_name(\"service_account.json\", scope)\n    drive = GoogleDrive(gauth)\n    return drive\n\ndef upload_folder_to_drive(drive, folder_path, parent_folder_id):\n    folder_name = os.path.basename(folder_path)\n    print(f\"Đang tạo thư mục '{folder_name}' trên Google Drive...\")\n    folder_metadata = {'title': folder_name, 'mimeType': 'application/vnd.google-apps.folder', 'parents': [{'id': parent_folder_id}]}\n    folder = drive.CreateFile(folder_metadata)\n    folder.Upload()\n    \n    print(f\"Bắt đầu tải nội dung của '{folder_name}'...\")\n    for item in tqdm(os.listdir(folder_path), desc=f\"Uploading {folder_name}\"):\n        item_path = os.path.join(folder_path, item)\n        if os.path.isfile(item_path):\n            gfile = drive.CreateFile({'title': item, 'parents': [{'id': folder['id']}]})\n            gfile.SetContentFile(item_path)\n            gfile.Upload(param={'supportsTeamDrives': True})\n        elif os.path.isdir(item_path):\n            upload_folder_to_drive(drive, item_path, folder['id'])\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy()\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef serialize_example(image, label):\n    \"\"\"Creates a tf.train.Example message ready to be written to a file.\"\"\"\n    feature = {\n        'image': _bytes_feature(tf.io.serialize_tensor(image)),\n        'label': _int64_feature(label)\n    }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T04:53:47.632806Z","iopub.execute_input":"2025-08-27T04:53:47.633240Z","iopub.status.idle":"2025-08-27T04:53:47.672324Z","shell.execute_reply.started":"2025-08-27T04:53:47.633218Z","shell.execute_reply":"2025-08-27T04:53:47.667057Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# CHUẨN BỊ DỮ LIỆU VÀ TẠO TFRECORD\n\n# --- BƯỚC 1: TẢI VÀ PHÂN CHIA DỮ LIỆU BAN ĐẦU ---\nprint(\"Bắt đầu chuẩn bị và phân chia dữ liệu...\")\nall_files_to_split = []\nfor class_name in ALL_CLASSES:\n    source_dir = os.path.join(KAGGLE_PROCESSED_DATA_PATH, class_name)\n    if os.path.exists(source_dir):\n        files = glob.glob(os.path.join(source_dir, '*.npy'))\n        for f in files:\n            all_files_to_split.append({'filepath': f, 'label': class_name})\n\nall_data_df = pd.DataFrame(all_files_to_split)\nall_data_df['patient_id'] = all_data_df.apply(lambda row: get_patient_id(row['filepath'], row['label']), axis=1)\n\nprint(\"Tách tập Test cuối cùng (Hold-out set)...\")\npatient_ids = all_data_df['patient_id'].unique()\nnp.random.shuffle(patient_ids)\ntest_patient_count = int(len(patient_ids) * TEST_SPLIT_RATIO)\ntest_patients = patient_ids[:test_patient_count]\ntrain_val_patients = patient_ids[test_patient_count:]\n\ntest_df = all_data_df[all_data_df['patient_id'].isin(test_patients)].reset_index(drop=True)\ntrain_val_df = all_data_df[all_data_df['patient_id'].isin(train_val_patients)].reset_index(drop=True)\n\nprint(f\"Đã tách: {len(train_val_df)} mẫu cho Train/Validation (CV) và {len(test_df)} mẫu cho Test cuối cùng.\")\n\n# --- BƯỚC 2: KHỞI TẠO LABEL ENCODER VÀ STANDARD SCALER ---\nle = LabelEncoder().fit(ALL_CLASSES)\n# Cập nhật INPUT_SHAPE từ một file mẫu\nsample_spec = np.load(train_val_df['filepath'][0])\nINPUT_SHAPE = (sample_spec.shape[0], sample_spec.shape[1], 3)\nprint(f\"Kích thước input được cập nhật: {INPUT_SHAPE}\")\n\nprint(\"Đang fit StandardScaler...\")\nscaler_fit_sample_df = train_val_df.sample(n=min(len(train_val_df), 500), random_state=SEED)\nscaler_fit_data = []\nfor filepath in scaler_fit_sample_df['filepath']:\n    spec = np.load(filepath)\n    # QUAN TRỌNG: Stack 3 kênh TRƯỚC KHI flatten, để khớp với pipeline\n    spec_3_channels = np.stack([spec, spec, spec], axis=-1)\n    scaler_fit_data.append(spec_3_channels.flatten())\nscaler = StandardScaler().fit(scaler_fit_data)\nprint(\"Fit StandardScaler hoàn tất.\")\n\n# --- BƯỚC 3: CHUYỂN ĐỔI DỮ LIỆU SANG ĐỊNH DẠNG TFRECORD ---\nTFRECORD_OUTPUT_PATH = \"/kaggle/working/tfrecords\"\nos.makedirs(TFRECORD_OUTPUT_PATH, exist_ok=True)\nprint(f\"Bắt đầu chuyển đổi dữ liệu sang TFRecord tại: {TFRECORD_OUTPUT_PATH}\")\n\nall_dfs = {'train_val': train_val_df, 'test': test_df}\n\nfor df_name, df in all_dfs.items():\n    print(f\"--- Đang xử lý tập {df_name} ---\")\n    tfrecord_path = os.path.join(TFRECORD_OUTPUT_PATH, f\"{df_name}.tfrec\")\n    \n    with tf.io.TFRecordWriter(tfrecord_path) as writer:\n        # Sử dụng tqdm tiêu chuẩn để tránh lỗi ImportError\n        for _, row in tqdm(df.iterrows(), total=len(df), desc=f\"Creating {df_name}.tfrec\"):\n            spectrogram = np.load(row['filepath']).astype(np.float32)\n            label_encoded = le.transform([row['label']])[0]\n            \n            example = serialize_example(spectrogram, label_encoded)\n            writer.write(example)\n            \nprint(\"\\nChuyển đổi sang TFRecord hoàn tất!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T04:53:47.674263Z","iopub.execute_input":"2025-08-27T04:53:47.674481Z","iopub.status.idle":"2025-08-27T04:57:15.300765Z","shell.execute_reply.started":"2025-08-27T04:53:47.674460Z","shell.execute_reply":"2025-08-27T04:57:15.294056Z"}},"outputs":[{"name":"stdout","text":"Bắt đầu chuẩn bị và phân chia dữ liệu...\nTách tập Test cuối cùng (Hold-out set)...\nĐã tách: 28054 mẫu cho Train/Validation (CV) và 5030 mẫu cho Test cuối cùng.\nKích thước input được cập nhật: (256, 126, 3)\nĐang fit StandardScaler...\nFit StandardScaler hoàn tất.\nBắt đầu chuyển đổi dữ liệu sang TFRecord tại: /kaggle/working/tfrecords\n--- Đang xử lý tập train_val ---\n","output_type":"stream"},{"name":"stderr","text":"Creating train_val.tfrec: 100%|██████████| 28054/28054 [02:51<00:00, 163.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"--- Đang xử lý tập test ---\n","output_type":"stream"},{"name":"stderr","text":"Creating test.tfrec: 100%|██████████| 5030/5030 [00:30<00:00, 162.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nChuyển đổi sang TFRecord hoàn tất!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# VÒNG LẶP HUẤN LUYỆN \n#tf.debugging.enable_check_numerics()\nAUTOTUNE = tf.data.AUTOTUNE\n    \nactive_indices = [le.transform([c])[0] for c in CLASSES_TO_TRAIN]\n\n# --- LẤY ĐƯỜNG DẪN LOCAL TỚI DỮ LIỆU TFRECORD ---\n# Trỏ trực tiếp đến thư mục output đã được tạo bởi ô code trước đó\nLOCAL_TFRECORD_PATH = TFRECORD_OUTPUT_PATH\nTRAIN_VAL_TFREC = os.path.join(LOCAL_TFRECORD_PATH, 'train_val.tfrec')\nprint(f\"Đang đọc dữ liệu TFRecord từ đường dẫn local: {TRAIN_VAL_TFREC}\")\n\n# Tính toán các chỉ số cần thiết MỘT LẦN DUY NHẤT\nactive_indices = [le.transform([c])[0] for c in CLASSES_TO_TRAIN]\nskf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\ncv_data_to_split = train_val_df[train_val_df['label'].isin(CLASSES_TO_TRAIN)]\nX_cv_paths = cv_data_to_split['filepath'].values\ny_cv_labels = le.transform(cv_data_to_split['label'])\ngroups_cv = cv_data_to_split['patient_id'].values\nfold_accuracies, fold_losses = [], []\n\n\n# --- Bắt đầu Cross-Validation ---\nfor fold, (train_indices, val_indices) in enumerate(skf.split(X_cv_paths, y_cv_labels, groups_cv)):\n    fold_number = fold + 1\n    print(\"-\" * 50 + f\"\\nBắt đầu Fold {fold_number}/{N_SPLITS}\\n\" + \"-\" * 50)\n    \n    # --- TẠO PIPELINE DỮ LIỆU TỪ TFRECORD ---\n    train_indices_tf = tf.constant(train_indices, dtype=tf.int64)\n    val_indices_tf = tf.constant(val_indices, dtype=tf.int64)\n\n    full_ds = tf.data.TFRecordDataset(TRAIN_VAL_TFREC).enumerate()\n    train_ds = full_ds.filter(lambda i, data: tf.reduce_any(i == train_indices_tf)).map(lambda i, data: data)\n    val_ds = full_ds.filter(lambda i, data: tf.reduce_any(i == val_indices_tf)).map(lambda i, data: data)\n    \n    train_ds = train_ds.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n    val_ds = val_ds.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n    \n    train_ds = train_ds.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n    if USE_DATA_AUGMENTATION:\n        train_ds = train_ds.map(augment, num_parallel_calls=AUTOTUNE)\n    val_ds = val_ds.cache().batch(GLOBAL_BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\n    # --- TẠO VÀ BIÊN DỊCH MODEL TRONG STRATEGY.SCOPE ---\n    with strategy.scope():\n        model = create_model(INPUT_SHAPE, len(ALL_CLASSES))\n        optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, clipvalue=1.0)\n        loss_function = focal_loss_from_logits_optimized(active_indices=active_indices) if USE_FOCAL_LOSS else tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n        model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-8, verbose=1)\n    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, \n                        callbacks=[EarlyStopping(monitor='val_loss', patience=EARLY_STOPPING_PATIENCE, min_delta=MIN_DELTA, restore_best_weights=True), reduce_lr],\n                        verbose=1)\n    \n    # Phần code vẽ biểu đồ và đánh giá\n    plt.figure(figsize=(15, 6))\n    plt.suptitle(f'Training Metrics for Fold {fold_number}', fontsize=16)\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'], label='Training Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Accuracy vs. Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.grid(True)\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Loss vs. Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n    plt.grid(True)\n    \n    plot_filename = f'fold_{fold_number}_metrics.png'\n    plot_filepath = os.path.join(KAGGLE_OUTPUT_PATH, plot_filename)\n    plt.savefig(plot_filepath)\n    plt.close()\n    \n    print(f\"Đã lưu biểu đồ cho Fold {fold_number} tại: {plot_filepath}\")\n    \n    loss, accuracy = model.evaluate(val_ds, verbose=0)\n    print(f\"Fold {fold_number} - Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}\")\n    fold_losses.append(loss)\n    fold_accuracies.append(accuracy)\n\nprint(\"=\" * 50 + \"\\nKết quả Cross-Validation:\\n\" + f\"Validation Accuracy trung bình: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\\n\" + f\"Validation Loss trung bình: {np.mean(fold_losses):.4f} +/- {np.std(fold_losses):.4f}\\n\" + \"=\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T04:57:15.302542Z","iopub.execute_input":"2025-08-27T04:57:15.302816Z"}},"outputs":[{"name":"stdout","text":"Đang đọc dữ liệu TFRecord từ đường dẫn local: /kaggle/working/tfrecords/train_val.tfrec\n--------------------------------------------------\nBắt đầu Fold 1/5\n--------------------------------------------------\nWARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7a9468427d00> and will run it as-is.\nCause: could not parse the source code of <function <lambda> at 0x7a9468427d00>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\nMatch 0:\nlambda i, data: data\n\nMatch 1:\nlambda i, data: tf.reduce_any(i == train_indices_tf)\n\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nWARNING: AutoGraph could not transform <function <lambda> at 0x7a9468427d00> and will run it as-is.\nCause: could not parse the source code of <function <lambda> at 0x7a9468427d00>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\nMatch 0:\nlambda i, data: data\n\nMatch 1:\nlambda i, data: tf.reduce_any(i == train_indices_tf)\n\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nWARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7a94684275b0> and will run it as-is.\nCause: could not parse the source code of <function <lambda> at 0x7a94684275b0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\nMatch 0:\nlambda i, data: data\n\nMatch 1:\nlambda i, data: tf.reduce_any(i == train_indices_tf)\n\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nWARNING: AutoGraph could not transform <function <lambda> at 0x7a94684275b0> and will run it as-is.\nCause: could not parse the source code of <function <lambda> at 0x7a94684275b0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\nMatch 0:\nlambda i, data: data\n\nMatch 1:\nlambda i, data: tf.reduce_any(i == train_indices_tf)\n\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nWARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7a9e76243880> and will run it as-is.\nCause: could not parse the source code of <function <lambda> at 0x7a9e76243880>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\nMatch 0:\nlambda i, data: data\n\nMatch 1:\nlambda i, data: tf.reduce_any(i == val_indices_tf)\n\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nWARNING: AutoGraph could not transform <function <lambda> at 0x7a9e76243880> and will run it as-is.\nCause: could not parse the source code of <function <lambda> at 0x7a9e76243880>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\nMatch 0:\nlambda i, data: data\n\nMatch 1:\nlambda i, data: tf.reduce_any(i == val_indices_tf)\n\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nWARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7a9e762436d0> and will run it as-is.\nCause: could not parse the source code of <function <lambda> at 0x7a9e762436d0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\nMatch 0:\nlambda i, data: data\n\nMatch 1:\nlambda i, data: tf.reduce_any(i == val_indices_tf)\n\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nWARNING: AutoGraph could not transform <function <lambda> at 0x7a9e762436d0> and will run it as-is.\nCause: could not parse the source code of <function <lambda> at 0x7a9e762436d0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\nMatch 0:\nlambda i, data: data\n\nMatch 1:\nlambda i, data: tf.reduce_any(i == val_indices_tf)\n\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1756270639.955740      10 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1756270668.739944      10 encapsulate_tpu_computations_pass.cc:266] Subgraph fingerprint:12919805009671706515\nI0000 00:00:1756270672.551973     966 tpu_compilation_cache_interface.cc:442] TPU host compilation cache miss: cache_key(10086872593214157428), session_name()\nI0000 00:00:1756270689.405870     966 tpu_compile_op_common.cc:245] Compilation of 10086872593214157428 with session name  took 16.853834308s and succeeded\nI0000 00:00:1756270689.456917     966 tpu_compilation_cache_interface.cc:476] TPU host compilation cache: compilation complete for cache_key(10086872593214157428), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_data_12919805009671706515\", property.function_library_fingerprint = 8059175274092058519, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"16,256,126,3,;16,4,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1756270689.456955     966 tpu_compilation_cache_interface.cc:542] After adding entry for key 10086872593214157428 with session_name  cache is 1 entries (67628296 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"    175/Unknown \u001b[1m62s\u001b[0m 189ms/step - accuracy: 0.7766 - loss: 0.1153","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1756270722.328629     949 tpu_compilation_cache_interface.cc:442] TPU host compilation cache miss: cache_key(1474413540789118273), session_name()\nI0000 00:00:1756270737.200290     949 tpu_compile_op_common.cc:245] Compilation of 1474413540789118273 with session name  took 14.871617711s and succeeded\nI0000 00:00:1756270737.248308     949 tpu_compilation_cache_interface.cc:476] TPU host compilation cache: compilation complete for cache_key(1474413540789118273), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_data_12919805009671706515\", property.function_library_fingerprint = 8059175274092058519, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"8,256,126,3,;8,4,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1756270737.248354     949 tpu_compilation_cache_interface.cc:542] After adding entry for key 1474413540789118273 with session_name  cache is 2 entries (132371760 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"    176/Unknown \u001b[1m77s\u001b[0m 273ms/step - accuracy: 0.7765 - loss: 0.1153","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\nI0000 00:00:1756270742.028668      10 encapsulate_tpu_computations_pass.cc:266] Subgraph fingerprint:10395212107791225878\nI0000 00:00:1756270743.073092     936 tpu_compilation_cache_interface.cc:442] TPU host compilation cache miss: cache_key(17292937946307723510), session_name()\nI0000 00:00:1756270747.394427     936 tpu_compile_op_common.cc:245] Compilation of 17292937946307723510 with session name  took 4.321277754s and succeeded\nI0000 00:00:1756270747.406013     936 tpu_compilation_cache_interface.cc:476] TPU host compilation cache: compilation complete for cache_key(17292937946307723510), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_data_10395212107791225878\", property.function_library_fingerprint = 12061867487176611346, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"16,256,126,3,;16,4,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1756270747.406043     936 tpu_compilation_cache_interface.cc:542] After adding entry for key 17292937946307723510 with session_name  cache is 3 entries (150959834 bytes),  marked for eviction 0 entries (0 bytes).\nI0000 00:00:1756270756.479835     964 tpu_compilation_cache_interface.cc:442] TPU host compilation cache miss: cache_key(5419055036563578360), session_name()\nI0000 00:00:1756270760.542709     964 tpu_compile_op_common.cc:245] Compilation of 5419055036563578360 with session name  took 4.062824029s and succeeded\nI0000 00:00:1756270760.553926     964 tpu_compilation_cache_interface.cc:476] TPU host compilation cache: compilation complete for cache_key(5419055036563578360), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_data_10395212107791225878\", property.function_library_fingerprint = 12061867487176611346, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"11,256,126,3,;11,4,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1756270760.553953     964 tpu_compilation_cache_interface.cc:542] After adding entry for key 5419055036563578360 with session_name  cache is 4 entries (169620750 bytes),  marked for eviction 0 entries (0 bytes).\n/usr/local/lib/python3.10/site-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 411ms/step - accuracy: 0.7764 - loss: 0.1154 - val_accuracy: 0.4489 - val_loss: 0.5913 - learning_rate: 3.0000e-05\nEpoch 2/50\n\u001b[1m175/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.4490 - loss: 0.2174","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 211ms/step - accuracy: 0.4510 - loss: 0.2166 - val_accuracy: 0.3092 - val_loss: 0.2066 - learning_rate: 3.0000e-05\nEpoch 3/50\n\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.6558 - loss: 0.1377","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 211ms/step - accuracy: 0.6566 - loss: 0.1374 - val_accuracy: 0.4605 - val_loss: 0.6883 - learning_rate: 3.0000e-05\nEpoch 4/50\n\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.6105 - loss: 0.2073","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 212ms/step - accuracy: 0.6114 - loss: 0.2068 - val_accuracy: 0.4626 - val_loss: 0.4577 - learning_rate: 3.0000e-05\nEpoch 5/50\n\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.6904 - loss: 0.1306","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 212ms/step - accuracy: 0.6911 - loss: 0.1304 - val_accuracy: 0.4558 - val_loss: 0.2634 - learning_rate: 3.0000e-05\nEpoch 6/50\n\u001b[1m175/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.7242 - loss: 0.1315","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 213ms/step - accuracy: 0.7254 - loss: 0.1309 - val_accuracy: 0.4682 - val_loss: 0.3151 - learning_rate: 3.0000e-05\nEpoch 7/50\n\u001b[1m117/176\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 199ms/step - accuracy: 0.6259 - loss: 0.1532","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# HUẤN LUYỆN MÔ HÌNH CUỐI CÙNG\nprint(\"Bắt đầu huấn luyện lại mô hình cuối cùng trên toàn bộ dữ liệu Train+Validation...\")\nfinal_train_df = train_val_df[train_val_df['label'].isin(CLASSES_TO_TRAIN)]\n\n# Tạo pipeline tf.data cho việc huấn luyện cuối cùng\nfinal_train_paths = final_train_df['filepath'].values\nfinal_train_labels = le.transform(final_train_df['label'])\nfinal_train_labels_onehot = tf.keras.utils.to_categorical(final_train_labels, num_classes=len(ALL_CLASSES))\n\nfinal_train_ds = tf.data.Dataset.from_tensor_slices((final_train_paths, final_train_labels_onehot))\nfinal_train_ds = final_train_ds.map(parse_and_process, num_parallel_calls=AUTOTUNE)\nfinal_train_ds = final_train_ds.shuffle(buffer_size=len(final_train_paths))\nfinal_train_ds = final_train_ds.batch(BATCH_SIZE)\nif USE_DATA_AUGMENTATION:\n    final_train_ds = final_train_ds.map(augment, num_parallel_calls=AUTOTUNE)\nfinal_train_ds = final_train_ds.prefetch(buffer_size=AUTOTUNE)\n\n\nfinal_model = create_model(INPUT_SHAPE, len(ALL_CLASSES))\n\n# Optimizer sạch, không có mixed precision\nfinal_optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, clipnorm=1.0)\n\nfinal_model.compile(optimizer=final_optimizer, \n                    loss='categorical_crossentropy' if not USE_FOCAL_LOSS else focal_loss(), \n                    metrics=['accuracy'], \n                    jit_compile=True)\n\nrun_timestamp = datetime.datetime.now(pytz.timezone('Asia/Ho_Chi_Minh')).strftime(\"%Y-%m-%d_%H-%M-%S\")\nmodel_checkpoint_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_final_model_{run_timestamp}.h5')\nfinal_history = final_model.fit(final_train_ds, epochs=EPOCHS, \n                                callbacks=[EarlyStopping(monitor='loss', patience=EARLY_STOPPING_PATIENCE), \n                                           ModelCheckpoint(filepath=model_checkpoint_path, save_best_only=True, monitor='loss')], \n                                verbose=1)\nprint(\"Huấn luyện mô hình cuối cùng hoàn tất.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ĐÁNH GIÁ MÔ HÌNH VÀ VẼ CÁC SƠ ĐỒ\nprint(\"\\nĐang đánh giá mô hình cuối cùng trên tập Test (Hold-out)...\")\nfinal_model.load_weights(model_checkpoint_path)\nfinal_test_df = test_df[test_df['label'].isin(CLASSES_TO_TRAIN)]\n\n\n\nX_test, y_test_labels = load_data_from_df(final_test_df)\ny_test_encoded = le.transform(y_test_labels)\ny_test_onehot = tf.keras.utils.to_categorical(y_test_encoded, num_classes=len(ALL_CLASSES))\nX_test = np.stack([X_test]*3, axis=-1)\nX_test_flat = X_test.reshape(X_test.shape[0], -1)\nX_test_scaled = scaler.transform(X_test_flat)\nX_test = np.nan_to_num(X_test_scaled).reshape(X_test.shape)\nprint(\"Tải dữ liệu test hoàn tất!\")\n\nloss, accuracy = final_model.evaluate(X_test, y_test_onehot, verbose=0)\nprint(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n\ny_pred_probs = final_model.predict(X_test)\ny_pred_encoded = np.argmax(y_pred_probs, axis=1)\n\ntrained_class_indices = np.unique(y_test_encoded)\ntarget_names_trained = le.inverse_transform(trained_class_indices)\n\nreport = classification_report(y_test_encoded, y_pred_encoded, target_names=target_names_trained, labels=trained_class_indices)\nprint(\"\\nClassification Report:\\n\", report)\n\nreport_figs_path = os.path.join(KAGGLE_OUTPUT_PATH, \"report_figures\")\nos.makedirs(report_figs_path, exist_ok=True)\n\nplt.figure(figsize=(8, 6))\nplt.plot(final_history.history['accuracy'], label='Training Accuracy')\nplt.title('Biểu đồ Accuracy của mô hình cuối cùng')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\naccuracy_plot_path = os.path.join(report_figs_path, f'final_accuracy_plot_{run_timestamp}.png')\nplt.savefig(accuracy_plot_path)\nplt.close()\n\nplt.figure(figsize=(8, 6))\nplt.plot(final_history.history['loss'], label='Training Loss')\nplt.title('Biểu đồ Loss của mô hình cuối cùng')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\nloss_plot_path = os.path.join(report_figs_path, f'final_loss_plot_{run_timestamp}.png')\nplt.savefig(loss_plot_path)\nplt.close()\n\ncm = confusion_matrix(y_test_encoded, y_pred_encoded, labels=trained_class_indices)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names_trained, yticklabels=target_names_trained)\nplt.title('Ma trận nhầm lẫn trên tập Test cuối cùng')\nplt.ylabel('Nhãn thật')\nplt.xlabel('Nhãn dự đoán')\ncm_plot_path = os.path.join(report_figs_path, f'confusion_matrix_{run_timestamp}.png')\nplt.savefig(cm_plot_path)\nplt.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# VẼ GRAD-CAM\nlast_conv_layer_name = None\nfor layer in reversed(final_model.layers):\n    if isinstance(layer, tf.keras.layers.GlobalAveragePooling2D):\n        pooling_index = final_model.layers.index(layer)\n        last_conv_layer_name = final_model.layers[pooling_index - 1].name\n        break\nif last_conv_layer_name is None:\n    raise ValueError(\"Không thể tự động tìm thấy lớp phù hợp cho Grad-CAM.\")\nprint(f\"Đã tự động xác định lớp Grad-CAM: {last_conv_layer_name}\")\n\ngradcam_path = os.path.join(report_figs_path, \"grad_cam\")\nos.makedirs(gradcam_path, exist_ok=True)\nprint(\"Tạo hình ảnh Grad-CAM...\")\nresults_list = []\nfor i in range(len(y_test_encoded)):\n    true_label_encoded = y_test_encoded[i]\n    pred_label_encoded = y_pred_encoded[i]\n    confidence = y_pred_probs[i][pred_label_encoded]\n    is_correct = (true_label_encoded == pred_label_encoded)\n    results_list.append({'index': i, 'true_label': true_label_encoded, 'pred_label': pred_label_encoded, 'confidence': confidence, 'is_correct': is_correct})\nresults_df = pd.DataFrame(results_list)\n\nfor class_index, class_name in zip(trained_class_indices, target_names_trained):\n    correct_samples = results_df[(results_df['is_correct'] == True) & (results_df['true_label'] == class_index)].nlargest(3, 'confidence')\n    incorrect_samples = results_df[(results_df['is_correct'] == False) & (results_df['true_label'] == class_index)].nlargest(3, 'confidence')\n    for _, row in correct_samples.iterrows():\n        idx = int(row['index'])\n        img_array, spec = X_test[idx][np.newaxis, ...], X_test[idx, :, :, 0]\n        heatmap = get_grad_cam(final_model, img_array, last_conv_layer_name, pred_index=class_index)\n        overlay = overlay_grad_cam(spec, heatmap)\n        plt.imshow(overlay)\n        plt.title(f\"Đúng: {class_name}, Tin cậy: {row['confidence']:.2f}\")\n        plt.axis('off')\n        plt.savefig(os.path.join(gradcam_path, f\"correct_{class_name}_{idx}_{run_timestamp}.png\"))\n        plt.close()\n    for _, row in incorrect_samples.iterrows():\n        idx = int(row['index'])\n        pred_class_name = le.inverse_transform([int(row['pred_label'])])[0]\n        img_array, spec = X_test[idx][np.newaxis, ...], X_test[idx, :, :, 0]\n        heatmap = get_grad_cam(final_model, img_array, last_conv_layer_name, pred_index=class_index)\n        overlay = overlay_grad_cam(spec, heatmap)\n        plt.imshow(overlay)\n        plt.title(f\"Thật: {class_name}, Sai -> {pred_class_name}, Tin cậy: {row['confidence']:.2f}\")\n        plt.axis('off')\n        plt.savefig(os.path.join(gradcam_path, f\"incorrect_{class_name}_as_{pred_class_name}_{idx}_{run_timestamp}.png\"))\n        plt.close()\n\ncorrect_heatmaps = {label: [] for label in target_names_trained}\nincorrect_heatmaps = {label: [] for label in target_names_trained}\nfor i, row in tqdm(results_df.iterrows(), total=len(results_df), desc=\"Calculating Avg Grad-CAMs\"):\n    idx = int(row['index'])\n    true_label_index = int(row['true_label'])\n    class_name = le.inverse_transform([true_label_index])[0]\n    img_array = X_test[idx][np.newaxis, ...]\n    heatmap = get_grad_cam(final_model, img_array, last_conv_layer_name, pred_index=true_label_index)\n    if row['is_correct']:\n        if class_name in correct_heatmaps: correct_heatmaps[class_name].append(heatmap)\n    else:\n        if class_name in incorrect_heatmaps: incorrect_heatmaps[class_name].append(heatmap)\n\nfor class_name in target_names_trained:\n    if correct_heatmaps.get(class_name):\n        avg_heatmap_correct = np.mean(correct_heatmaps[class_name], axis=0)\n        overlay = overlay_grad_cam(np.zeros(INPUT_SHAPE[:2]), avg_heatmap_correct)\n        plt.imshow(overlay)\n        plt.title(f\"Grad-CAM TB - Đúng cho lớp {class_name}\")\n        plt.axis('off')\n        plt.savefig(os.path.join(gradcam_path, f\"avg_correct_{class_name}_{run_timestamp}.png\"))\n        plt.close()\n    if incorrect_heatmaps.get(class_name):\n        avg_heatmap_incorrect = np.mean(incorrect_heatmaps[class_name], axis=0)\n        overlay = overlay_grad_cam(np.zeros(INPUT_SHAPE[:2]), avg_heatmap_incorrect)\n        plt.imshow(overlay)\n        plt.title(f\"Grad-CAM TB - Sai cho lớp {class_name}\")\n        plt.axis('off')\n        plt.savefig(os.path.join(gradcam_path, f\"avg_incorrect_{class_name}_{run_timestamp}.png\"))\n        plt.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TẠO BÁO CÁO PDF\nprint(\"Tạo báo cáo PDF...\")\npdf = PDFReport()\npdf.add_page()\npdf.chapter_title(\"1. Tom tat cau hinh va Ket qua\")\nconfig_summary = f\"\"\"\n- Model ID: {MODEL_ID}\n- Thoi gian chay: {datetime.datetime.now(pytz.timezone('Asia/Ho_Chi_Minh')).strftime(\"%Y-%m-%d %H:%M:%S\")}\n- Cac lop huan luyen: {', '.join(CLASSES_TO_TRAIN)}\n- K-Fold Cross-Validation: {N_SPLITS} folds\n\n--- KET QUA CROSS-VALIDATION ---\n- Validation Accuracy trung binh: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\n- Validation Loss trung binh: {np.mean(fold_losses):.4f} +/- {np.std(fold_losses):.4f}\n\n--- KET QUA TREN TAP TEST CUOI CUNG ---\n- Test Loss: {loss:.4f}\n- Test Accuracy: {accuracy:.4f}\n\n--- CAU HINH CHI TIET ---\n- SEED: {SEED}\n- Epochs: {EPOCHS} (Patience: {EARLY_STOPPING_PATIENCE})\n- Batch Size: {BATCH_SIZE}\n- Learning Rate: {LEARNING_RATE}\n- Ham Loss: {'Focal Loss' if USE_FOCAL_LOSS else 'Categorical Crossentropy'}\n- Tang cuong du lieu: {'Co (SpecAugment)' if USE_DATA_AUGMENTATION else 'Khong'}\n- Kich thuoc Input: {INPUT_SHAPE}\n\"\"\"\npdf.chapter_body(config_summary)\npdf.add_image_section(\"2. Bieu do Huan luyen cua Mo hinh Cuoi cung\", accuracy_plot_path)\npdf.add_image_section(\"\", loss_plot_path)\npdf.chapter_title(\"3. Danh gia chi tiet tren tap Test\")\npdf.chapter_body(\"Bao cao phan loai chi tiet:\")\npdf.set_font('Courier', '', 8)\npdf.chapter_body(report)\npdf.add_image_section(\"Ma tran nham lan:\", cm_plot_path)\n\npdf.add_page()\npdf.chapter_title(\"4. Phan tich Grad-CAM\")\nfor class_name in target_names_trained:\n    pdf.chapter_body(f\"Lop: {class_name}\")\n    correct_imgs = sorted(glob.glob(os.path.join(gradcam_path, f\"correct_{class_name}_*_{run_timestamp}.png\")))\n    incorrect_imgs = sorted(glob.glob(os.path.join(gradcam_path, f\"incorrect_{class_name}_*_{run_timestamp}.png\")))\n    \n    x_pos, y_pos = pdf.get_x(), pdf.get_y()\n    for i, img_path in enumerate(correct_imgs[:3]):\n        if os.path.exists(img_path): pdf.image(img_path, x=x_pos + i * 60, y=y_pos, w=55)\n    if correct_imgs: y_pos += 45\n    for i, img_path in enumerate(incorrect_imgs[:3]):\n        if os.path.exists(img_path): pdf.image(img_path, x=x_pos + i * 60, y=y_pos, w=55)\n    if incorrect_imgs: y_pos += 45\n    pdf.set_y(y_pos)\n    \n    avg_correct_path = os.path.join(gradcam_path, f\"avg_correct_{class_name}_{run_timestamp}.png\")\n    avg_incorrect_path = os.path.join(gradcam_path, f\"avg_incorrect_{class_name}_{run_timestamp}.png\")\n    if os.path.exists(avg_correct_path):\n        pdf.image(avg_correct_path, w=80)\n    if os.path.exists(avg_incorrect_path):\n        pdf.image(avg_incorrect_path, w=80)\n    pdf.ln(10)\n\nreport_filename = f\"report_{MODEL_ID}_{run_timestamp}.pdf\"\nreport_filepath = os.path.join(KAGGLE_OUTPUT_PATH, report_filename)\npdf.output(report_filepath)\nprint(f\"Đã tạo báo cáo PDF tại: {report_filepath}\")\n\nprint(\"\\nBắt đầu quá trình tải kết quả lên Google Drive...\")\ndrive = authenticate_gdrive()\nupload_folder_to_drive(drive, KAGGLE_OUTPUT_PATH, DRIVE_RESULTS_FOLDER_ID)\nprint(\"Hoàn tất! Toàn bộ kết quả đã được lưu về Google Drive.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}