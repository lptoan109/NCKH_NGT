{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12850756,"sourceType":"datasetVersion","datasetId":8127872}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =============================================================================\n# PHẦN 0: CÀI ĐẶT & CẤU HÌNH (SETUP & CONFIGURATION)\n# =============================================================================\n\n# 0.1. Cài đặt các thư viện cần thiết\n!pip install -q fpdf2 noisereduce librosa tensorflow scikit-learn matplotlib seaborn pytz PyDrive2\n\n# 0.2. Import thư viện\nimport os\nimport glob\nimport random\nimport datetime\nimport pytz\nimport shutil\nimport joblib\nimport zipfile\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\nfrom fpdf import FPDF\nfrom tqdm.notebook import tqdm\nimport librosa\nimport noisereduce as nr\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.applications import ResNet50V2\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom pydrive2.auth import GoogleAuth\nfrom pydrive2.drive import GoogleDrive\nfrom kaggle_secrets import UserSecretsClient\nfrom oauth2client.service_account import ServiceAccountCredentials\nfrom tensorflow.keras.regularizers import l2\n\n# 0.4. Thiết lập SEED để đảm bảo kết quả tái lặp\nSEED = 42\ndef set_seed(seed_value):\n    \"\"\"Cố định seed cho các thư viện để đảm bảo kết quả nhất quán.\"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    tf.random.set_seed(seed_value)\nset_seed(SEED)\n\n# 0.5. Thiết lập phông chữ (đã được đơn giản hóa)\nfont_path = None # Sẽ sử dụng font mặc định\n\n# 0.6. Cấu hình các đường dẫn và tham số\n# --- CẤU HÌNH KAGGLE DATASET (QUAN TRỌNG) ---\nKAGGLE_PROCESSED_DATA_PATH = \"/kaggle/input/ngt-dataset/\" \n\n# --- CẤU HÌNH KẾT NỐI GOOGLE DRIVE (TÙY CHỌN, ĐỂ LƯU KẾT QUẢ) ---\nDRIVE_RESULTS_FOLDER_ID = '13DW3yr_AVDDbu-Onv58LKLE3TaPuJRDq' \n\n# --- Đường dẫn trên máy ảo Kaggle (Không cần sửa) ---\nKAGGLE_OUTPUT_PATH = \"/kaggle/working/output_results\"\nos.makedirs(KAGGLE_OUTPUT_PATH, exist_ok=True)\n\n# --- Các thông số cấu hình thử nghiệm ---\nCLASSES_TO_TRAIN = ['covid', 'tuberculosis']\nALL_CLASSES = ['healthy', 'asthma', 'covid', 'tuberculosis']\nN_SPLITS = 5\nTEST_SPLIT_RATIO = 0.15\nUSE_DATA_AUGMENTATION = True\nUSE_FOCAL_LOSS = True\nMODEL_ID = f'ResNet50V2_CV_{\"_\".join(CLASSES_TO_TRAIN)}'\nEPOCHS = 50\nBATCH_SIZE = 64\nLEARNING_RATE = 5e-5\nEARLY_STOPPING_PATIENCE = 7\nMIN_DELTA = 1e-4\n\n# Các tham số không đổi\nSAMPLE_RATE = 16000\nN_MELS = 128\nN_FFT = 2048\nHOP_LENGTH = 512\nSILENCE_THRESHOLD_DB = 20\nIMG_SIZE = (128, 157)\nINPUT_SHAPE = (IMG_SIZE[0], IMG_SIZE[1], 3)\n\n\n# =============================================================================\n# GIAI ĐOẠN 1: CHUẨN BỊ DỮ LIỆU CHO CROSS-VALIDATION\n# =============================================================================\n\ndef get_patient_id(filepath, class_name):\n    filename = os.path.basename(filepath)\n    if class_name.lower() in ['asthma', 'covid', 'healthy']:\n        return filename.split('_')[0]\n    elif class_name.lower() == 'tuberculosis':\n        return '_'.join(filename.split('_')[:-1]).replace('.npy', '')\n    else:\n        return filename.split('_')[0]\n\nprint(\"Bắt đầu chuẩn bị và phân chia dữ liệu...\")\nall_files_to_split = []\nfor class_name in ALL_CLASSES:\n    source_dir = os.path.join(KAGGLE_PROCESSED_DATA_PATH, class_name)\n    if os.path.exists(source_dir):\n        files = glob.glob(os.path.join(source_dir, '*.npy'))\n        for f in files:\n            all_files_to_split.append({'filepath': f, 'label': class_name})\n\nall_data_df = pd.DataFrame(all_files_to_split)\nall_data_df['patient_id'] = all_data_df.apply(lambda row: get_patient_id(row['filepath'], row['label']), axis=1)\n\nprint(\"Tách tập Test cuối cùng (Hold-out set)...\")\npatient_ids = all_data_df['patient_id'].unique()\nnp.random.shuffle(patient_ids)\ntest_patient_count = int(len(patient_ids) * TEST_SPLIT_RATIO)\ntest_patients = patient_ids[:test_patient_count]\ntrain_val_patients = patient_ids[test_patient_count:]\n\ntest_df = all_data_df[all_data_df['patient_id'].isin(test_patients)].reset_index(drop=True)\ntrain_val_df = all_data_df[all_data_df['patient_id'].isin(train_val_patients)].reset_index(drop=True)\n\nprint(f\"Đã tách: {len(train_val_df)} mẫu cho Train/Validation (CV) và {len(test_df)} mẫu cho Test cuối cùng.\")\n\nle = LabelEncoder().fit(ALL_CLASSES)\nsample_spec = np.load(train_val_df['filepath'][0])\nINPUT_SHAPE = (sample_spec.shape[0], sample_spec.shape[1], 3)\nprint(f\"Kích thước input được cập nhật: {INPUT_SHAPE}\")\n\nprint(\"Đang fit StandardScaler...\")\nscaler_fit_sample_df = train_val_df.sample(n=min(len(train_val_df), 500), random_state=SEED)\nscaler_fit_data = []\nfor filepath in scaler_fit_sample_df['filepath']:\n    spec = np.load(filepath)\n    spec_3_channels = np.stack([spec]*3, axis=-1)\n    scaler_fit_data.append(spec_3_channels.flatten())\nscaler = StandardScaler().fit(scaler_fit_data)\nprint(\"Fit StandardScaler hoàn tất.\")\n\n\n# =============================================================================\n# GIAI ĐOẠN 2: HUẤN LUYỆN VÀ ĐÁNH GIÁ CHÉO (PHIÊN BẢN ỔN ĐỊNH)\n# =============================================================================\n\ndef parse_and_process(filepath, label_onehot):\n    \"\"\"Hàm đọc file, stack kênh, chuẩn hóa và làm sạch.\"\"\"\n    def _read_npy(path):\n        return np.load(path.decode()).astype(np.float32)\n    \n    spec = tf.numpy_function(_read_npy, [filepath], tf.float32)\n    spec = tf.stack([spec, spec, spec], axis=-1)\n    spec.set_shape(INPUT_SHAPE)\n    \n    spec_shape = tf.shape(spec)\n    spec_flat = tf.reshape(spec, (1, -1))\n    \n    def _scale(data):\n        scaled_data = scaler.transform(data)\n        # Luôn làm sạch dữ liệu ngay sau khi scale\n        return np.nan_to_num(scaled_data)\n    \n    scaled_flat = tf.numpy_function(_scale, [spec_flat], tf.float32)\n    spec_scaled = tf.reshape(scaled_flat, spec_shape)\n    \n    return spec_scaled, label_onehot\n\ndef augment(spectrogram, label):\n    \"\"\"Hàm áp dụng augmentation.\"\"\"\n    spectrogram = spec_augment(spectrogram)\n    return spectrogram, label\n    \ndef focal_loss(gamma=2.0, alpha=0.25):\n    def focal_loss_fixed(y_true, y_pred):\n        y_true = tf.cast(y_true, 'float32')\n        active_indices = [le.transform([c])[0] for c in CLASSES_TO_TRAIN]\n        y_true_filtered = tf.gather(y_true, active_indices, axis=-1)\n        y_pred_filtered = tf.gather(y_pred, active_indices, axis=-1)\n        y_pred_filtered = tf.clip_by_value(y_pred_filtered, 1e-7, 1.0 - 1e-7)\n        cross_entropy = -y_true_filtered * tf.math.log(y_pred_filtered)\n        focal_term = alpha * tf.pow(1.0 - y_pred_filtered, gamma)\n        loss = focal_term * cross_entropy\n        return tf.reduce_sum(loss, axis=-1)\n    return focal_loss_fixed\n\ndef spec_augment(spectrogram, time_masking_para=40, frequency_masking_para=15,\n                 num_time_masks=1, num_freq_masks=1):\n    spectrogram_aug = spectrogram\n    for _ in range(num_freq_masks):\n        freq_max = tf.shape(spectrogram_aug)[1]\n        f = tf.random.uniform(shape=(), minval=0, maxval=frequency_masking_para, dtype=tf.int32)\n        f0 = tf.random.uniform(shape=(), minval=0, maxval=freq_max - f, dtype=tf.int32)\n        mask_3d = tf.concat([\n            tf.ones(shape=(tf.shape(spectrogram_aug)[0], f0, tf.shape(spectrogram_aug)[2])),\n            tf.zeros(shape=(tf.shape(spectrogram_aug)[0], f, tf.shape(spectrogram_aug)[2])),\n            tf.ones(shape=(tf.shape(spectrogram_aug)[0], freq_max - f0 - f, tf.shape(spectrogram_aug)[2]))\n        ], axis=1)\n        mask_4d = tf.expand_dims(mask_3d, axis=-1)\n        spectrogram_aug = spectrogram_aug * mask_4d\n    for _ in range(num_time_masks):\n        time_max = tf.shape(spectrogram_aug)[2]\n        t = tf.random.uniform(shape=(), minval=0, maxval=time_masking_para, dtype=tf.int32)\n        t0 = tf.random.uniform(shape=(), minval=0, maxval=time_max - t, dtype=tf.int32)\n        mask_3d = tf.concat([\n            tf.ones(shape=(tf.shape(spectrogram_aug)[0], tf.shape(spectrogram_aug)[1], t0)),\n            tf.zeros(shape=(tf.shape(spectrogram_aug)[0], tf.shape(spectrogram_aug)[1], t)),\n            tf.ones(shape=(tf.shape(spectrogram_aug)[0], tf.shape(spectrogram_aug)[1], time_max - t0 - t))\n        ], axis=2)\n        mask_4d = tf.expand_dims(mask_3d, axis=-1)\n        spectrogram_aug = spectrogram_aug * mask_4d\n    return spectrogram_aug\n\ndef create_model(input_shape, num_classes):\n    \n    # 1. Khởi tạo mô hình\n    base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n    \n    # 2. Đóng băng các lớp ban đầu (ví dụ: 100 lớp đầu tiên)\n    # ResNet-50V2 có khoảng 190 lớp. Đóng băng một nửa là mức khởi điểm tốt.\n    FREEZE_UNTIL_LAYER = 100\n    for layer in base_model.layers[:FREEZE_UNTIL_LAYER]:\n        layer.trainable = False\n        \n    # 3. Đảm bảo phần còn lại của mô hình được huấn luyện\n    # Cần set trainable = True cho base_model sau khi đóng băng các layer cụ thể\n    base_model.trainable = True \n    \n    # 4. Xây dựng lớp đầu ra (đã có L2 Regularization)\n    inputs = Input(shape=input_shape)\n    # training=True là cần thiết để đảm bảo các lớp Batch Normalization hoạt động đúng (cho phần không bị đóng băng)\n    x = base_model(inputs, training=True) \n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.5)(x)\n    \n    outputs = Dense(num_classes, \n                    activation='softmax',\n                    kernel_regularizer=l2(0.001)\n                   )(x) \n    return Model(inputs, outputs)\n\n# --- Vòng lặp Cross-Validation ---\nskf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\ncv_data_to_split = train_val_df[train_val_df['label'].isin(CLASSES_TO_TRAIN)]\nX_cv_paths = cv_data_to_split['filepath'].values\ny_cv_labels = le.transform(cv_data_to_split['label'])\ngroups_cv = cv_data_to_split['patient_id'].values\nfold_accuracies, fold_losses = [], []\n\nAUTOTUNE = tf.data.AUTOTUNE\n\nfor fold, (train_indices, val_indices) in enumerate(skf.split(X_cv_paths, y_cv_labels, groups_cv)):\n    fold_number = fold + 1\n    print(\"-\" * 50 + f\"\\nBắt đầu Fold {fold_number}/{N_SPLITS}\\n\" + \"-\" * 50)\n    \n    train_paths, val_paths = X_cv_paths[train_indices], X_cv_paths[val_indices]\n    train_labels, val_labels = y_cv_labels[train_indices], y_cv_labels[val_indices]\n    \n    train_labels_onehot = tf.keras.utils.to_categorical(train_labels, num_classes=len(ALL_CLASSES))\n    val_labels_onehot = tf.keras.utils.to_categorical(val_labels, num_classes=len(ALL_CLASSES))\n    \n    # Tạo pipeline tf.data cho tập train\n    train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels_onehot))\n    train_ds = train_ds.map(parse_and_process, num_parallel_calls=AUTOTUNE)\n    train_ds = train_ds.cache()\n    train_ds = train_ds.shuffle(buffer_size=len(train_paths))\n    train_ds = train_ds.batch(BATCH_SIZE)\n    if USE_DATA_AUGMENTATION:\n        train_ds = train_ds.map(augment, num_parallel_calls=AUTOTUNE)\n    train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n\n    # Tạo pipeline tf.data cho tập validation\n    val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels_onehot))\n    val_ds = val_ds.map(parse_and_process, num_parallel_calls=AUTOTUNE)\n    val_ds = val_ds.cache()\n    val_ds = val_ds.batch(BATCH_SIZE)\n    val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n                                  \n    model = create_model(INPUT_SHAPE, len(ALL_CLASSES))\n    \n    # Optimizer SẠCH, chỉ giữ lại clipnorm để ổn định\n    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, clipnorm=1.0)\n    \n    model.compile(optimizer=optimizer, \n                  loss='categorical_crossentropy' if not USE_FOCAL_LOSS else focal_loss(), \n                  metrics=['accuracy'], \n                  jit_compile=True)\n\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n                              factor=0.5, \n                              patience=5, \n                              min_lr=1e-8, \n                              verbose=1)\n\n    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, \n                        callbacks=[EarlyStopping(monitor='val_loss', patience=EARLY_STOPPING_PATIENCE, min_delta=MIN_DELTA, restore_best_weights=True),\n                                    reduce_lr\n                                  ],\n                        verbose=1)\n    \n    loss, accuracy = model.evaluate(val_ds, verbose=0)\n    print(f\"Fold {fold_number} - Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}\")\n    fold_losses.append(loss)\n    fold_accuracies.append(accuracy)\n\nprint(\"=\" * 50 + \"\\nKết quả Cross-Validation:\\n\" + f\"Validation Accuracy trung bình: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\\n\" + f\"Validation Loss trung bình: {np.mean(fold_losses):.4f} +/- {np.std(fold_losses):.4f}\\n\" + \"=\" * 50)\n\n# =============================================================================\n# GIAI ĐOẠN 3: HUẤN LUYỆN LẠI, ĐÁNH GIÁ CUỐI CÙNG VÀ BÁO CÁO\n# =============================================================================\n\nprint(\"Bắt đầu huấn luyện lại mô hình cuối cùng trên toàn bộ dữ liệu Train+Validation...\")\nfinal_train_df = train_val_df[train_val_df['label'].isin(CLASSES_TO_TRAIN)]\n\n# Tạo pipeline tf.data cho việc huấn luyện cuối cùng\nfinal_train_paths = final_train_df['filepath'].values\nfinal_train_labels = le.transform(final_train_df['label'])\nfinal_train_labels_onehot = tf.keras.utils.to_categorical(final_train_labels, num_classes=len(ALL_CLASSES))\n\nfinal_train_ds = tf.data.Dataset.from_tensor_slices((final_train_paths, final_train_labels_onehot))\nfinal_train_ds = final_train_ds.map(parse_and_process, num_parallel_calls=AUTOTUNE)\nfinal_train_ds = final_train_ds.cache()\nfinal_train_ds = final_train_ds.shuffle(buffer_size=len(final_train_paths))\nfinal_train_ds = final_train_ds.batch(BATCH_SIZE)\nif USE_DATA_AUGMENTATION:\n    final_train_ds = final_train_ds.map(augment, num_parallel_calls=AUTOTUNE)\nfinal_train_ds = final_train_ds.prefetch(buffer_size=AUTOTUNE)\n\n\nfinal_model = create_model(INPUT_SHAPE, len(ALL_CLASSES))\n\n# Optimizer sạch, không có mixed precision\nfinal_optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, clipnorm=1.0)\n\nfinal_model.compile(optimizer=final_optimizer, \n                    loss='categorical_crossentropy' if not USE_FOCAL_LOSS else focal_loss(), \n                    metrics=['accuracy'], \n                    jit_compile=True)\n\nrun_timestamp = datetime.datetime.now(pytz.timezone('Asia/Ho_Chi_Minh')).strftime(\"%Y-%m-%d_%H-%M-%S\")\nmodel_checkpoint_path = os.path.join(KAGGLE_OUTPUT_PATH, f'{MODEL_ID}_final_model_{run_timestamp}.h5')\nfinal_history = final_model.fit(final_train_ds, epochs=EPOCHS, \n                                callbacks=[EarlyStopping(monitor='loss', patience=EARLY_STOPPING_PATIENCE), \n                                           ModelCheckpoint(filepath=model_checkpoint_path, save_best_only=True, monitor='loss')], \n                                verbose=1)\nprint(\"Huấn luyện mô hình cuối cùng hoàn tất.\")\n\nprint(\"\\nĐang đánh giá mô hình cuối cùng trên tập Test (Hold-out)...\")\nfinal_model.load_weights(model_checkpoint_path)\nfinal_test_df = test_df[test_df['label'].isin(CLASSES_TO_TRAIN)]\n\ndef load_data_from_df(df):\n    X, y = [], []\n    for _, row in df.iterrows():\n        X.append(np.load(row['filepath']))\n        y.append(row['label'])\n    return np.array(X), np.array(y)\n\nX_test, y_test_labels = load_data_from_df(final_test_df)\ny_test_encoded = le.transform(y_test_labels)\ny_test_onehot = tf.keras.utils.to_categorical(y_test_encoded, num_classes=len(ALL_CLASSES))\nX_test = np.stack([X_test]*3, axis=-1)\nX_test_flat = X_test.reshape(X_test.shape[0], -1)\nX_test_scaled = scaler.transform(X_test_flat)\nX_test = np.nan_to_num(X_test_scaled).reshape(X_test.shape)\nprint(\"Tải dữ liệu test hoàn tất!\")\n\nloss, accuracy = final_model.evaluate(X_test, y_test_onehot, verbose=0)\nprint(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n\ny_pred_probs = final_model.predict(X_test)\ny_pred_encoded = np.argmax(y_pred_probs, axis=1)\n\ntrained_class_indices = np.unique(y_test_encoded)\ntarget_names_trained = le.inverse_transform(trained_class_indices)\n\nreport = classification_report(y_test_encoded, y_pred_encoded, target_names=target_names_trained, labels=trained_class_indices)\nprint(\"\\nClassification Report:\\n\", report)\n\nreport_figs_path = os.path.join(KAGGLE_OUTPUT_PATH, \"report_figures\")\nos.makedirs(report_figs_path, exist_ok=True)\n\nplt.figure(figsize=(8, 6))\nplt.plot(final_history.history['accuracy'], label='Training Accuracy')\nplt.title('Biểu đồ Accuracy của mô hình cuối cùng')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\naccuracy_plot_path = os.path.join(report_figs_path, f'final_accuracy_plot_{run_timestamp}.png')\nplt.savefig(accuracy_plot_path)\nplt.close()\n\nplt.figure(figsize=(8, 6))\nplt.plot(final_history.history['loss'], label='Training Loss')\nplt.title('Biểu đồ Loss của mô hình cuối cùng')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\nloss_plot_path = os.path.join(report_figs_path, f'final_loss_plot_{run_timestamp}.png')\nplt.savefig(loss_plot_path)\nplt.close()\n\ncm = confusion_matrix(y_test_encoded, y_pred_encoded, labels=trained_class_indices)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names_trained, yticklabels=target_names_trained)\nplt.title('Ma trận nhầm lẫn trên tập Test cuối cùng')\nplt.ylabel('Nhãn thật')\nplt.xlabel('Nhãn dự đoán')\ncm_plot_path = os.path.join(report_figs_path, f'confusion_matrix_{run_timestamp}.png')\nplt.savefig(cm_plot_path)\nplt.close()\n\ndef get_grad_cam(model, img_array, last_conv_layer_name, pred_index=None):\n    grad_model = Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(tf.cast(img_array, tf.float32))\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\ndef overlay_grad_cam(spec, heatmap, alpha=0.6):\n    heatmap_resized = tf.image.resize(heatmap[..., np.newaxis], (spec.shape[0], spec.shape[1]))\n    heatmap_resized = np.uint8(255 * heatmap_resized)\n    jet = plt.cm.get_cmap(\"jet\")\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap_resized.squeeze()]\n    spec_display = np.stack([spec]*3, axis=-1)\n    spec_display = (spec_display - spec_display.min()) / (spec_display.max() - spec_display.min())\n    superimposed_img = jet_heatmap * alpha + spec_display\n    superimposed_img = np.clip(superimposed_img, 0, 1)\n    return superimposed_img\n\nlast_conv_layer_name = None\nfor layer in reversed(final_model.layers):\n    if isinstance(layer, tf.keras.layers.GlobalAveragePooling2D):\n        pooling_index = final_model.layers.index(layer)\n        last_conv_layer_name = final_model.layers[pooling_index - 1].name\n        break\nif last_conv_layer_name is None:\n    raise ValueError(\"Không thể tự động tìm thấy lớp phù hợp cho Grad-CAM.\")\nprint(f\"Đã tự động xác định lớp Grad-CAM: {last_conv_layer_name}\")\n\ngradcam_path = os.path.join(report_figs_path, \"grad_cam\")\nos.makedirs(gradcam_path, exist_ok=True)\nprint(\"Tạo hình ảnh Grad-CAM...\")\nresults_list = []\nfor i in range(len(y_test_encoded)):\n    true_label_encoded = y_test_encoded[i]\n    pred_label_encoded = y_pred_encoded[i]\n    confidence = y_pred_probs[i][pred_label_encoded]\n    is_correct = (true_label_encoded == pred_label_encoded)\n    results_list.append({'index': i, 'true_label': true_label_encoded, 'pred_label': pred_label_encoded, 'confidence': confidence, 'is_correct': is_correct})\nresults_df = pd.DataFrame(results_list)\n\nfor class_index, class_name in zip(trained_class_indices, target_names_trained):\n    correct_samples = results_df[(results_df['is_correct'] == True) & (results_df['true_label'] == class_index)].nlargest(3, 'confidence')\n    incorrect_samples = results_df[(results_df['is_correct'] == False) & (results_df['true_label'] == class_index)].nlargest(3, 'confidence')\n    for _, row in correct_samples.iterrows():\n        idx = int(row['index'])\n        img_array, spec = X_test[idx][np.newaxis, ...], X_test[idx, :, :, 0]\n        heatmap = get_grad_cam(final_model, img_array, last_conv_layer_name, pred_index=class_index)\n        overlay = overlay_grad_cam(spec, heatmap)\n        plt.imshow(overlay)\n        plt.title(f\"Đúng: {class_name}, Tin cậy: {row['confidence']:.2f}\")\n        plt.axis('off')\n        plt.savefig(os.path.join(gradcam_path, f\"correct_{class_name}_{idx}_{run_timestamp}.png\"))\n        plt.close()\n    for _, row in incorrect_samples.iterrows():\n        idx = int(row['index'])\n        pred_class_name = le.inverse_transform([int(row['pred_label'])])[0]\n        img_array, spec = X_test[idx][np.newaxis, ...], X_test[idx, :, :, 0]\n        heatmap = get_grad_cam(final_model, img_array, last_conv_layer_name, pred_index=class_index)\n        overlay = overlay_grad_cam(spec, heatmap)\n        plt.imshow(overlay)\n        plt.title(f\"Thật: {class_name}, Sai -> {pred_class_name}, Tin cậy: {row['confidence']:.2f}\")\n        plt.axis('off')\n        plt.savefig(os.path.join(gradcam_path, f\"incorrect_{class_name}_as_{pred_class_name}_{idx}_{run_timestamp}.png\"))\n        plt.close()\n\ncorrect_heatmaps = {label: [] for label in target_names_trained}\nincorrect_heatmaps = {label: [] for label in target_names_trained}\nfor i, row in tqdm(results_df.iterrows(), total=len(results_df), desc=\"Calculating Avg Grad-CAMs\"):\n    idx = int(row['index'])\n    true_label_index = int(row['true_label'])\n    class_name = le.inverse_transform([true_label_index])[0]\n    img_array = X_test[idx][np.newaxis, ...]\n    heatmap = get_grad_cam(final_model, img_array, last_conv_layer_name, pred_index=true_label_index)\n    if row['is_correct']:\n        if class_name in correct_heatmaps: correct_heatmaps[class_name].append(heatmap)\n    else:\n        if class_name in incorrect_heatmaps: incorrect_heatmaps[class_name].append(heatmap)\n\nfor class_name in target_names_trained:\n    if correct_heatmaps.get(class_name):\n        avg_heatmap_correct = np.mean(correct_heatmaps[class_name], axis=0)\n        overlay = overlay_grad_cam(np.zeros(INPUT_SHAPE[:2]), avg_heatmap_correct)\n        plt.imshow(overlay)\n        plt.title(f\"Grad-CAM TB - Đúng cho lớp {class_name}\")\n        plt.axis('off')\n        plt.savefig(os.path.join(gradcam_path, f\"avg_correct_{class_name}_{run_timestamp}.png\"))\n        plt.close()\n    if incorrect_heatmaps.get(class_name):\n        avg_heatmap_incorrect = np.mean(incorrect_heatmaps[class_name], axis=0)\n        overlay = overlay_grad_cam(np.zeros(INPUT_SHAPE[:2]), avg_heatmap_incorrect)\n        plt.imshow(overlay)\n        plt.title(f\"Grad-CAM TB - Sai cho lớp {class_name}\")\n        plt.axis('off')\n        plt.savefig(os.path.join(gradcam_path, f\"avg_incorrect_{class_name}_{run_timestamp}.png\"))\n        plt.close()\n\n# =============================================================================\n# GIAI ĐOẠN 4: TẠO BÁO CÁO VÀ TẢI KẾT QUẢ LÊN GOOGLE DRIVE\n# =============================================================================\nclass PDFReport(FPDF):\n    def header(self):\n        self.set_font('Arial', 'B', 12)\n        self.cell(0, 10, 'BAO CAO KET QUA HUAN LUYEN MO HINH AI', 0, 1, 'C')\n        self.ln(10)\n    def footer(self):\n        self.set_y(-15)\n        self.set_font('Arial', 'I', 8)\n        self.cell(0, 10, f'Trang {self.page_no()}', 0, 0, 'C')\n    def chapter_title(self, title):\n        self.set_font('Arial', 'B', 12)\n        self.cell(0, 10, title, 0, 1, 'L')\n        self.ln(5)\n    def chapter_body(self, content):\n        self.set_font('Arial', '', 10)\n        safe_content = content.encode('latin-1', 'replace').decode('latin-1')\n        self.multi_cell(0, 5, safe_content)\n        self.ln()\n    def add_image_section(self, title, img_path):\n        self.chapter_title(title)\n        if os.path.exists(img_path):\n            self.image(img_path, x=None, y=None, w=180)\n            self.ln(5)\n        else:\n            self.chapter_body(f\"Khong tim thay hinh anh: {img_path}\")\n\ndef authenticate_gdrive():\n    user_secrets = UserSecretsClient()\n    secret_value = user_secrets.get_secret(\"google_service_account_key\")\n    with open(\"service_account.json\", \"w\") as f:\n        f.write(secret_value)\n    scope = [\"https://www.googleapis.com/auth/drive\"]\n    gauth = GoogleAuth()\n    gauth.credentials = ServiceAccountCredentials.from_json_keyfile_name(\"service_account.json\", scope)\n    drive = GoogleDrive(gauth)\n    return drive\n\nprint(\"Tạo báo cáo PDF...\")\npdf = PDFReport()\npdf.add_page()\npdf.chapter_title(\"1. Tom tat cau hinh va Ket qua\")\nconfig_summary = f\"\"\"\n- Model ID: {MODEL_ID}\n- Thoi gian chay: {datetime.datetime.now(pytz.timezone('Asia/Ho_Chi_Minh')).strftime(\"%Y-%m-%d %H:%M:%S\")}\n- Cac lop huan luyen: {', '.join(CLASSES_TO_TRAIN)}\n- K-Fold Cross-Validation: {N_SPLITS} folds\n\n--- KET QUA CROSS-VALIDATION ---\n- Validation Accuracy trung binh: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\n- Validation Loss trung binh: {np.mean(fold_losses):.4f} +/- {np.std(fold_losses):.4f}\n\n--- KET QUA TREN TAP TEST CUOI CUNG ---\n- Test Loss: {loss:.4f}\n- Test Accuracy: {accuracy:.4f}\n\n--- CAU HINH CHI TIET ---\n- SEED: {SEED}\n- Epochs: {EPOCHS} (Patience: {EARLY_STOPPING_PATIENCE})\n- Batch Size: {BATCH_SIZE}\n- Learning Rate: {LEARNING_RATE}\n- Ham Loss: {'Focal Loss' if USE_FOCAL_LOSS else 'Categorical Crossentropy'}\n- Tang cuong du lieu: {'Co (SpecAugment)' if USE_DATA_AUGMENTATION else 'Khong'}\n- Kich thuoc Input: {INPUT_SHAPE}\n\"\"\"\npdf.chapter_body(config_summary)\npdf.add_image_section(\"2. Bieu do Huan luyen cua Mo hinh Cuoi cung\", accuracy_plot_path)\npdf.add_image_section(\"\", loss_plot_path)\npdf.chapter_title(\"3. Danh gia chi tiet tren tap Test\")\npdf.chapter_body(\"Bao cao phan loai chi tiet:\")\npdf.set_font('Courier', '', 8)\npdf.chapter_body(report)\npdf.add_image_section(\"Ma tran nham lan:\", cm_plot_path)\n\npdf.add_page()\npdf.chapter_title(\"4. Phan tich Grad-CAM\")\nfor class_name in target_names_trained:\n    pdf.chapter_body(f\"Lop: {class_name}\")\n    correct_imgs = sorted(glob.glob(os.path.join(gradcam_path, f\"correct_{class_name}_*_{run_timestamp}.png\")))\n    incorrect_imgs = sorted(glob.glob(os.path.join(gradcam_path, f\"incorrect_{class_name}_*_{run_timestamp}.png\")))\n    \n    x_pos, y_pos = pdf.get_x(), pdf.get_y()\n    for i, img_path in enumerate(correct_imgs[:3]):\n        if os.path.exists(img_path): pdf.image(img_path, x=x_pos + i * 60, y=y_pos, w=55)\n    if correct_imgs: y_pos += 45\n    for i, img_path in enumerate(incorrect_imgs[:3]):\n        if os.path.exists(img_path): pdf.image(img_path, x=x_pos + i * 60, y=y_pos, w=55)\n    if incorrect_imgs: y_pos += 45\n    pdf.set_y(y_pos)\n    \n    avg_correct_path = os.path.join(gradcam_path, f\"avg_correct_{class_name}_{run_timestamp}.png\")\n    avg_incorrect_path = os.path.join(gradcam_path, f\"avg_incorrect_{class_name}_{run_timestamp}.png\")\n    if os.path.exists(avg_correct_path):\n        pdf.image(avg_correct_path, w=80)\n    if os.path.exists(avg_incorrect_path):\n        pdf.image(avg_incorrect_path, w=80)\n    pdf.ln(10)\n\nreport_filename = f\"report_{MODEL_ID}_{run_timestamp}.pdf\"\nreport_filepath = os.path.join(KAGGLE_OUTPUT_PATH, report_filename)\npdf.output(report_filepath)\nprint(f\"Đã tạo báo cáo PDF tại: {report_filepath}\")\n\ndef upload_folder_to_drive(drive, folder_path, parent_folder_id):\n    folder_name = os.path.basename(folder_path)\n    print(f\"Đang tạo thư mục '{folder_name}' trên Google Drive...\")\n    folder_metadata = {'title': folder_name, 'mimeType': 'application/vnd.google-apps.folder', 'parents': [{'id': parent_folder_id}]}\n    folder = drive.CreateFile(folder_metadata)\n    folder.Upload()\n    \n    print(f\"Bắt đầu tải nội dung của '{folder_name}'...\")\n    for item in tqdm(os.listdir(folder_path), desc=f\"Uploading {folder_name}\"):\n        item_path = os.path.join(folder_path, item)\n        if os.path.isfile(item_path):\n            gfile = drive.CreateFile({'title': item, 'parents': [{'id': folder['id']}]})\n            gfile.SetContentFile(item_path)\n            gfile.Upload(param={'supportsTeamDrives': True})\n        elif os.path.isdir(item_path):\n            upload_folder_to_drive(drive, item_path, folder['id'])\n\nprint(\"\\nBắt đầu quá trình tải kết quả lên Google Drive...\")\ndrive = authenticate_gdrive()\nupload_folder_to_drive(drive, KAGGLE_OUTPUT_PATH, DRIVE_RESULTS_FOLDER_ID)\nprint(\"Hoàn tất! Toàn bộ kết quả đã được lưu về Google Drive.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T14:52:41.779141Z","iopub.execute_input":"2025-08-24T14:52:41.779432Z"}},"outputs":[{"name":"stdout","text":"Bắt đầu chuẩn bị và phân chia dữ liệu...\nTách tập Test cuối cùng (Hold-out set)...\nĐã tách: 23633 mẫu cho Train/Validation (CV) và 4204 mẫu cho Test cuối cùng.\nKích thước input được cập nhật: (128, 644, 3)\nĐang fit StandardScaler...\nFit StandardScaler hoàn tất.\n--------------------------------------------------\nBắt đầu Fold 1/5\n--------------------------------------------------\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/trainer.py:212: UserWarning: Model doesn't support `jit_compile=True`. Proceeding with `jit_compile=False`.\n  warnings.warn(\n2025-08-24 14:52:52.724537: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_4}}\nI0000 00:00:1756047346.218005     108 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846ms/step - accuracy: 0.5555 - loss: 0.1466","output_type":"stream"},{"name":"stderr","text":"2025-08-24 14:58:17.224492: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_4}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 1s/step - accuracy: 0.5558 - loss: 0.1463 - val_accuracy: 0.5246 - val_loss: 0.0932 - learning_rate: 5.0000e-05\nEpoch 2/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 960ms/step - accuracy: 0.7837 - loss: 0.0363 - val_accuracy: 0.5264 - val_loss: 0.0942 - learning_rate: 5.0000e-05\nEpoch 3/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 954ms/step - accuracy: 0.8135 - loss: 0.0308 - val_accuracy: 0.5346 - val_loss: 0.1027 - learning_rate: 5.0000e-05\nEpoch 4/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 958ms/step - accuracy: 0.8948 - loss: 0.0276 - val_accuracy: 0.5264 - val_loss: 0.1011 - learning_rate: 5.0000e-05\nEpoch 5/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 952ms/step - accuracy: 0.9218 - loss: 0.0196 - val_accuracy: 0.5271 - val_loss: 0.1101 - learning_rate: 5.0000e-05\nEpoch 6/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847ms/step - accuracy: 0.9454 - loss: 0.0157\nEpoch 6: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 954ms/step - accuracy: 0.9454 - loss: 0.0157 - val_accuracy: 0.5346 - val_loss: 0.1306 - learning_rate: 5.0000e-05\nEpoch 7/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 963ms/step - accuracy: 0.9573 - loss: 0.0137 - val_accuracy: 0.5350 - val_loss: 0.1212 - learning_rate: 2.5000e-05\nEpoch 8/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 952ms/step - accuracy: 0.9618 - loss: 0.0108 - val_accuracy: 0.5440 - val_loss: 0.1167 - learning_rate: 2.5000e-05\nFold 1 - Validation Loss: 0.0932, Validation Accuracy: 0.5246\n--------------------------------------------------\nBắt đầu Fold 2/5\n--------------------------------------------------\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/trainer.py:212: UserWarning: Model doesn't support `jit_compile=True`. Proceeding with `jit_compile=False`.\n  warnings.warn(\n2025-08-24 15:19:08.307004: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_4}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 56/175\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 889ms/step - accuracy: 0.4465 - loss: 0.1867","output_type":"stream"}],"execution_count":null}]}