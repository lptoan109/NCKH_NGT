{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e78ed4bb",
   "metadata": {},
   "source": [
    "# üéØ Optimized CRCNN Model for Cough Classification\n",
    "\n",
    "## Ki·∫øn tr√∫c CRCNN (Convolutional Recurrent Convolutional Neural Network)\n",
    "\n",
    "M√¥ h√¨nh CRCNN k·∫øt h·ª£p s·ª©c m·∫°nh c·ªßa:\n",
    "1. **Convolutional layers** - Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng kh√¥ng gian t·ª´ spectrogram\n",
    "2. **Recurrent layers (GRU)** - M√¥ h√¨nh h√≥a chu·ªói th·ªùi gian\n",
    "3. **Attention mechanism** - T·∫≠p trung v√†o c√°c ph·∫ßn quan tr·ªçng\n",
    "4. **Residual connections** - C·∫£i thi·ªán gradient flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da5e913d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA A100-SXM4-80GB\n",
      "CUDA Version: 12.8\n",
      "Available GPU Memory: 79.25 GB\n",
      "\n",
      "‚úì Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Check CUDA availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"Available GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: CUDA not available, using CPU\")\n",
    "\n",
    "print(\"\\n‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31b6dc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "‚úì Data loaded successfully!\n",
      "\n",
      "Dataset shapes:\n",
      "  X_train: (44124, 1, 256, 126), y_train: (44124,)\n",
      "  X_val:   (4903, 1, 256, 126), y_val: (4903,)\n",
      "  X_test:  (4903, 1, 256, 126), y_test: (4903,)\n",
      "\n",
      "Number of classes: 4\n",
      "Class names: ['asthma', 'covid', 'healthy', 'tuberculosis']\n",
      "‚úì Data loaded successfully!\n",
      "\n",
      "Dataset shapes:\n",
      "  X_train: (44124, 1, 256, 126), y_train: (44124,)\n",
      "  X_val:   (4903, 1, 256, 126), y_val: (4903,)\n",
      "  X_test:  (4903, 1, 256, 126), y_test: (4903,)\n",
      "\n",
      "Number of classes: 4\n",
      "Class names: ['asthma', 'covid', 'healthy', 'tuberculosis']\n"
     ]
    }
   ],
   "source": [
    "# Data directory\n",
    "DATA_DIR = '../processed_data'\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "X_train = np.load(f'{DATA_DIR}/X_train.npy')\n",
    "y_train = np.load(f'{DATA_DIR}/y_train.npy')\n",
    "X_val = np.load(f'{DATA_DIR}/X_val.npy')\n",
    "y_val = np.load(f'{DATA_DIR}/y_val.npy')\n",
    "X_test = np.load(f'{DATA_DIR}/X_test.npy')\n",
    "y_test = np.load(f'{DATA_DIR}/y_test.npy')\n",
    "\n",
    "# Load label mapping\n",
    "with open(f'{DATA_DIR}/label_mapping.json', 'r') as f:\n",
    "    label_info = json.load(f)\n",
    "    label_to_idx = label_info['label_to_idx']\n",
    "    idx_to_label = {int(k): v for k, v in label_info['idx_to_label'].items()}\n",
    "    num_classes = label_info['num_classes']\n",
    "\n",
    "print(f\"‚úì Data loaded successfully!\")\n",
    "print(f\"\\nDataset shapes:\")\n",
    "print(f\"  X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"  X_val:   {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"  X_test:  {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print(f\"\\nNumber of classes: {num_classes}\")\n",
    "print(f\"Class names: {list(label_to_idx.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36a5c42",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Optimized CRCNN Architecture\n",
    "\n",
    "CRCNN model ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·∫∑c bi·ªát cho audio classification v·ªõi c√°c c·∫£i ti·∫øn:\n",
    "\n",
    "### 1. Convolutional Blocks v·ªõi Residual Connections\n",
    "- 3 conv blocks: [64, 128, 256] channels\n",
    "- BatchNorm + ReLU + Dropout\n",
    "- Skip connections ƒë·ªÉ tr√°nh vanishing gradients\n",
    "\n",
    "### 2. Bidirectional GRU (thay v√¨ LSTM)\n",
    "- Nhanh h∆°n, √≠t parameter h∆°n ‚Üí gi·∫£m overfitting\n",
    "- 2 layers v·ªõi dropout\n",
    "- M√¥ h√¨nh h√≥a sequence t·ª´ c·∫£ 2 h∆∞·ªõng\n",
    "\n",
    "### 3. Attention Mechanism\n",
    "- T·ª± ƒë·ªông focus v√†o c√°c ph·∫ßn quan tr·ªçng c·ªßa audio\n",
    "- T·ªët h∆°n vi·ªác ch·ªâ d√πng output cu·ªëi c√πng\n",
    "\n",
    "### 4. Strong Regularization\n",
    "- Dropout 0.5-0.6 ·ªü nhi·ªÅu layers\n",
    "- Weight decay trong optimizer\n",
    "- Layer Normalization thay v√¨ ch·ªâ BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6aceab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì OPTIMIZED CRCNN model class defined successfully\n",
      "  ‚Ä¢ Residual connections in conv blocks\n",
      "  ‚Ä¢ GRU instead of LSTM (faster, less overfitting)\n",
      "  ‚Ä¢ Attention mechanism for temporal modeling\n",
      "  ‚Ä¢ Layer normalization for stability\n",
      "  ‚Ä¢ Proper dimension handling\n",
      "  ‚Ä¢ Weight initialization\n"
     ]
    }
   ],
   "source": [
    "class ImprovedCRCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    ‚≠ê IMPROVED CRCNN for Cough Classification ‚≠ê\n",
    "    \n",
    "    T·ªëi ∆∞u cho high accuracy v√† anti-overfitting:\n",
    "    - Residual connections trong conv blocks\n",
    "    - Bidirectional GRU (kh√¥ng ph·∫£i LSTM)\n",
    "    - Multi-head attention mechanism\n",
    "    - Strong regularization (dropout 0.5-0.6)\n",
    "    - Layer normalization\n",
    "    - Gradient checkpointing support\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_channels=1, num_classes=4, \n",
    "                 conv_channels=[64, 128, 256], \n",
    "                 rnn_hidden_size=256, rnn_layers=2,\n",
    "                 dropout=0.5, attention_heads=4):\n",
    "        super(ImprovedCRCNN, self).__init__()\n",
    "        \n",
    "        self.input_channels = input_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # === CONVOLUTIONAL BLOCKS v·ªõi RESIDUAL CONNECTIONS ===\n",
    "        self.conv_blocks = nn.ModuleList()\n",
    "        self.residual_projs = nn.ModuleList()\n",
    "        \n",
    "        in_ch = input_channels\n",
    "        for i, out_ch in enumerate(conv_channels):\n",
    "            # Main conv path v·ªõi 2 conv layers\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout2d(dropout * 0.3),  # Dropout th·∫•p h∆°n cho conv\n",
    "                \n",
    "                nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "            )\n",
    "            self.conv_blocks.append(block)\n",
    "            \n",
    "            # Projection cho residual n·∫øu channels thay ƒë·ªïi\n",
    "            if in_ch != out_ch:\n",
    "                self.residual_projs.append(\n",
    "                    nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "                )\n",
    "            else:\n",
    "                self.residual_projs.append(None)\n",
    "            \n",
    "            in_ch = out_ch\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout_2d = nn.Dropout2d(dropout * 0.4)\n",
    "        \n",
    "        # Adaptive pooling ƒë·ªÉ ƒë·∫£m b·∫£o k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 32))  # (1, 32) cho temporal dim\n",
    "        \n",
    "        # === FEATURE PROJECTION tr∆∞·ªõc RNN ===\n",
    "        self.feature_channels = conv_channels[-1]\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        \n",
    "        self.pre_rnn_proj = nn.Sequential(\n",
    "            nn.Linear(self.feature_channels, rnn_hidden_size),\n",
    "            nn.LayerNorm(rnn_hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout * 0.5)\n",
    "        )\n",
    "        \n",
    "        # === BIDIRECTIONAL GRU ===\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=rnn_hidden_size,\n",
    "            hidden_size=rnn_hidden_size,\n",
    "            num_layers=rnn_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout * 0.5 if rnn_layers > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # === MULTI-HEAD ATTENTION ===\n",
    "        self.attention_heads = attention_heads\n",
    "        gru_output_size = rnn_hidden_size * 2  # Bidirectional\n",
    "        \n",
    "        # Multi-head attention\n",
    "        self.attention_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(gru_output_size, 64),\n",
    "                nn.Tanh(),\n",
    "                nn.Dropout(dropout * 0.3),\n",
    "                nn.Linear(64, 1)\n",
    "            ) for _ in range(attention_heads)\n",
    "        ])\n",
    "        \n",
    "        # === CLASSIFICATION HEAD ===\n",
    "        classifier_input_size = gru_output_size * attention_heads\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            # First block\n",
    "            nn.Linear(classifier_input_size, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            # Second block\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout * 0.6),  # Dropout cao h∆°n ·ªü cu·ªëi\n",
    "            \n",
    "            # Output\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Kh·ªüi t·∫°o weights t·ªët h∆°n\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.LayerNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.GRU):\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'weight_ih' in name:\n",
    "                        nn.init.xavier_uniform_(param.data)\n",
    "                    elif 'weight_hh' in name:\n",
    "                        nn.init.orthogonal_(param.data)\n",
    "                    elif 'bias' in name:\n",
    "                        nn.init.constant_(param.data, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch, channels, height, width) - spectrogram\n",
    "        Returns:\n",
    "            output: (batch, num_classes) - logits\n",
    "        \"\"\"\n",
    "        # === CONVOLUTIONAL FEATURE EXTRACTION ===\n",
    "        for i, (conv_block, res_proj) in enumerate(zip(self.conv_blocks, self.residual_projs)):\n",
    "            identity = x\n",
    "            \n",
    "            # Main path\n",
    "            x = conv_block(x)\n",
    "            \n",
    "            # Residual connection\n",
    "            if res_proj is not None:\n",
    "                identity = res_proj(identity)\n",
    "            \n",
    "            x = x + identity\n",
    "            x = self.relu(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.dropout_2d(x)\n",
    "        \n",
    "        # === RESHAPE cho RNN ===\n",
    "        # Adaptive pooling: (batch, channels, H, W) -> (batch, channels, 1, 32)\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        # Reshape: (batch, channels, 1, time) -> (batch, time, channels)\n",
    "        batch_size, channels, _, time_steps = x.size()\n",
    "        x = x.squeeze(2).permute(0, 2, 1)  # (batch, time, channels)\n",
    "        \n",
    "        # Project features\n",
    "        x = self.pre_rnn_proj(x)  # (batch, time, rnn_hidden_size)\n",
    "        \n",
    "        # === GRU TEMPORAL MODELING ===\n",
    "        gru_out, _ = self.gru(x)  # (batch, time, rnn_hidden_size * 2)\n",
    "        \n",
    "        # === MULTI-HEAD ATTENTION ===\n",
    "        attended_features = []\n",
    "        for attention_layer in self.attention_layers:\n",
    "            # Compute attention weights\n",
    "            attention_scores = attention_layer(gru_out)  # (batch, time, 1)\n",
    "            attention_weights = torch.softmax(attention_scores, dim=1)\n",
    "            \n",
    "            # Apply attention\n",
    "            attended = torch.sum(gru_out * attention_weights, dim=1)  # (batch, hidden*2)\n",
    "            attended_features.append(attended)\n",
    "        \n",
    "        # Concatenate all attention heads\n",
    "        context = torch.cat(attended_features, dim=1)  # (batch, hidden*2*heads)\n",
    "        \n",
    "        # === CLASSIFICATION ===\n",
    "        output = self.classifier(context)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def get_model_size(self):\n",
    "        \"\"\"T√≠nh k√≠ch th∆∞·ªõc model\"\"\"\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        \n",
    "        return {\n",
    "            'total_params': total_params,\n",
    "            'trainable_params': trainable_params,\n",
    "            'size_mb': total_params * 4 / (1024 ** 2)  # Assuming float32\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ ImprovedCRCNN model defined successfully!\")\n",
    "print(\"üì¶ Architecture: Conv(Residual) ‚Üí GRU(Bidirectional) ‚Üí Multi-Head Attention ‚Üí Classifier\")\n",
    "print(\"üõ°Ô∏è  Anti-overfitting: Dropout 0.5-0.6, BatchNorm, LayerNorm, Residual connections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56e1fabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for PyTorch...\n",
      "Data shapes after preprocessing:\n",
      "  X_train_tensor: torch.Size([44124, 1, 256, 126])\n",
      "  X_val_tensor: torch.Size([4903, 1, 256, 126])\n",
      "  X_test_tensor: torch.Size([4903, 1, 256, 126])\n",
      "‚úì Data loaders created with batch size: 32\n",
      "  Train batches: 1379\n",
      "  Validation batches: 154\n",
      "  Test batches: 154\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing and conversion to PyTorch tensors\n",
    "def prepare_data_for_pytorch(X, y):\n",
    "    \"\"\"Convert numpy arrays to PyTorch tensors and handle data format\"\"\"\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    y_tensor = torch.LongTensor(y)\n",
    "    \n",
    "    # Ensure X has the right shape: (batch, channels, height, width)\n",
    "    if len(X_tensor.shape) == 3:\n",
    "        # Add channel dimension: (batch, height, width) -> (batch, 1, height, width)\n",
    "        X_tensor = X_tensor.unsqueeze(1)\n",
    "    elif len(X_tensor.shape) == 4 and X_tensor.shape[1] != 1:\n",
    "        # If channels are last: (batch, height, width, channels) -> (batch, channels, height, width)\n",
    "        X_tensor = X_tensor.permute(0, 3, 1, 2)\n",
    "    \n",
    "    return X_tensor, y_tensor\n",
    "\n",
    "# Prepare data\n",
    "print(\"Preparing data for PyTorch...\")\n",
    "X_train_tensor, y_train_tensor = prepare_data_for_pytorch(X_train, y_train)\n",
    "X_val_tensor, y_val_tensor = prepare_data_for_pytorch(X_val, y_val)\n",
    "X_test_tensor, y_test_tensor = prepare_data_for_pytorch(X_test, y_test)\n",
    "\n",
    "print(f\"Data shapes after preprocessing:\")\n",
    "print(f\"  X_train_tensor: {X_train_tensor.shape}\")\n",
    "print(f\"  X_val_tensor: {X_val_tensor.shape}\")\n",
    "print(f\"  X_test_tensor: {X_test_tensor.shape}\")\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"‚úì Data loaders created with batch size: {batch_size}\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153c1938",
   "metadata": {},
   "source": [
    "## \udfa8 Data Augmentation - SpecAugment\n",
    "\n",
    "SpecAugment l√† k·ªπ thu·∫≠t augmentation m·∫°nh m·∫Ω cho audio:\n",
    "- **Time Masking**: Che c√°c time steps ng·∫´u nhi√™n\n",
    "- **Frequency Masking**: Che c√°c frequency bins ng·∫´u nhi√™n  \n",
    "- **Gaussian Noise**: Th√™m nhi·ªÖu ƒë·ªÉ tƒÉng robustness\n",
    "\n",
    "Gi√∫p model h·ªçc ƒë∆∞·ª£c features t·ªïng qu√°t h∆°n, kh√¥ng b·ªã overfit tr√™n training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72b1ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì STRONG SpecAugment configured:\n",
      "  ‚Ä¢ Time masking: up to 40 frames, 2 masks, 70% prob\n",
      "  ‚Ä¢ Freq masking: up to 20 bins, 2 masks, 70% prob\n",
      "  ‚Ä¢ Gaussian noise: std=0.1, 50% prob\n",
      "  ‚Ä¢ Applied during training only\n"
     ]
    }
   ],
   "source": [
    "class SpecAugment(nn.Module):\n",
    "    \"\"\"\n",
    "    SpecAugment - Data Augmentation for Spectrograms\n",
    "    \n",
    "    Paper: SpecAugment: A Simple Data Augmentation Method for ASR\n",
    "    https://arxiv.org/abs/1904.08779\n",
    "    \"\"\"\n",
    "    def __init__(self, time_mask_param=30, freq_mask_param=15, \n",
    "                 num_time_masks=2, num_freq_masks=2, \n",
    "                 p=0.5, noise_std=0.05):\n",
    "        super().__init__()\n",
    "        self.time_mask_param = time_mask_param\n",
    "        self.freq_mask_param = freq_mask_param\n",
    "        self.num_time_masks = num_time_masks\n",
    "        self.num_freq_masks = num_freq_masks\n",
    "        self.p = p  # Probability of applying augmentation\n",
    "        self.noise_std = noise_std\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch, channels, freq, time)\n",
    "        \"\"\"\n",
    "        if not self.training:\n",
    "            return x\n",
    "        \n",
    "        batch, channels, freq, time = x.shape\n",
    "        x = x.clone()\n",
    "        \n",
    "        # Apply to each sample in batch v·ªõi probability p\n",
    "        for i in range(batch):\n",
    "            if torch.rand(1).item() < self.p:\n",
    "                # Time masking\n",
    "                for _ in range(self.num_time_masks):\n",
    "                    if time > self.time_mask_param:\n",
    "                        t = torch.randint(1, self.time_mask_param, (1,)).item()\n",
    "                        t0 = torch.randint(0, time - t, (1,)).item()\n",
    "                        x[i, :, :, t0:t0+t] = 0\n",
    "                \n",
    "                # Frequency masking\n",
    "                for _ in range(self.num_freq_masks):\n",
    "                    if freq > self.freq_mask_param:\n",
    "                        f = torch.randint(1, self.freq_mask_param, (1,)).item()\n",
    "                        f0 = torch.randint(0, freq - f, (1,)).item()\n",
    "                        x[i, :, f0:f0+f, :] = 0\n",
    "        \n",
    "        # Add Gaussian noise (optional, lower probability)\n",
    "        if torch.rand(1).item() < self.p * 0.5:\n",
    "            noise = torch.randn_like(x) * self.noise_std\n",
    "            x = x + noise\n",
    "            \n",
    "        return x\n",
    "\n",
    "# Initialize augmentation\n",
    "augmentation = SpecAugment(\n",
    "    time_mask_param=30,      # Mask up to 30 time steps\n",
    "    freq_mask_param=15,      # Mask up to 15 frequency bins\n",
    "    num_time_masks=2,        # Apply 2 time masks\n",
    "    num_freq_masks=2,        # Apply 2 freq masks\n",
    "    p=0.5,                   # 50% probability per sample\n",
    "    noise_std=0.05           # Small noise\n",
    ").to(device)\n",
    "\n",
    "print(\"‚úÖ SpecAugment configured:\")\n",
    "print(f\"  ‚Ä¢ Time masking: up to {augmentation.time_mask_param} frames, {augmentation.num_time_masks} masks\")\n",
    "print(f\"  ‚Ä¢ Freq masking: up to {augmentation.freq_mask_param} bins, {augmentation.num_freq_masks} masks\")\n",
    "print(f\"  ‚Ä¢ Application probability: {augmentation.p * 100}%\")\n",
    "print(f\"  ‚Ä¢ Gaussian noise: std={augmentation.noise_std}\")\n",
    "print(\"  ‚Ä¢ Only applied during training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6df51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üöÄ INITIALIZING OPTIMIZED CRCNN MODEL\n",
      "================================================================================\n",
      "\n",
      "üìä CRCNN Model Information:\n",
      "  Architecture: Conv ‚Üí GRU ‚Üí Attention ‚Üí Classifier\n",
      "  Total parameters: 3,687,045\n",
      "  Trainable parameters: 3,687,045\n",
      "  Input channels: 1\n",
      "  Number of classes: 4\n",
      "  RNN hidden size: 256\n",
      "  RNN layers: 2\n",
      "  Attention mechanism: True\n",
      "\n",
      "üß™ Testing model with sample input...\n",
      "  Sample input shape: torch.Size([2, 1, 256, 126])\n",
      "  Sample output shape: torch.Size([2, 4])\n",
      "  Output logits range: [-2.406, 0.018]\n",
      "‚úì Model forward pass successful!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# INITIALIZE MODEL\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üöÄ INITIALIZING IMPROVED CRCNN MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get input shape\n",
    "input_channels = X_train_tensor.shape[1]  # Should be 1 for grayscale spectrograms\n",
    "\n",
    "# Create model v·ªõi best hyperparameters\n",
    "model = ImprovedCRCNN(\n",
    "    input_channels=input_channels,\n",
    "    num_classes=num_classes,\n",
    "    conv_channels=[64, 128, 256],    # Progressive feature extraction\n",
    "    rnn_hidden_size=256,             # GRU hidden size\n",
    "    rnn_layers=2,                    # 2-layer bidirectional GRU\n",
    "    dropout=0.5,                     # Strong dropout for anti-overfitting\n",
    "    attention_heads=4                # Multi-head attention\n",
    ").to(device)\n",
    "\n",
    "# Model information\n",
    "model_info = model.get_model_size()\n",
    "print(f\"\\nüìä Model Information:\")\n",
    "print(f\"  Total parameters: {model_info['total_params']:,}\")\n",
    "print(f\"  Trainable parameters: {model_info['trainable_params']:,}\")\n",
    "print(f\"  Model size: {model_info['size_mb']:.2f} MB\")\n",
    "print(f\"  Input channels: {input_channels}\")\n",
    "print(f\"  Output classes: {num_classes}\")\n",
    "\n",
    "# Test forward pass\n",
    "print(f\"\\nüß™ Testing model forward pass...\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_input = X_train_tensor[:2].to(device)\n",
    "    sample_output = model(sample_input)\n",
    "    \n",
    "print(f\"  Input shape: {sample_input.shape}\")\n",
    "print(f\"  Output shape: {sample_output.shape}\")\n",
    "print(f\"  Output range: [{sample_output.min():.3f}, {sample_output.max():.3f}]\")\n",
    "print(f\"‚úÖ Model initialized successfully!\")\n",
    "\n",
    "model.train()\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275d3e8c",
   "metadata": {},
   "source": [
    "## üéì Training Loop v·ªõi Early Stopping\n",
    "\n",
    "Training loop ƒë∆∞·ª£c t·ªëi ∆∞u ƒë·ªÉ:\n",
    "- Track c·∫£ train v√† validation metrics\n",
    "- Early stopping khi validation accuracy kh√¥ng c·∫£i thi·ªán (patience=10)\n",
    "- Save best model checkpoint\n",
    "- Visualize training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceff09b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights for imbalanced data:\n",
      "  asthma: 1.328\n",
      "  covid: 0.750\n",
      "  healthy: 1.724\n",
      "  tuberculosis: 0.750\n",
      "\n",
      "üîß ANTI-OVERFITTING CONFIGURATION:\n",
      "  ‚úì Label Smoothing: 0.15 (increased from 0.1)\n",
      "  ‚úì Learning Rate: 0.0005 (reduced from 0.001)\n",
      "  ‚úì Weight Decay: 0.02 (increased from 0.01)\n",
      "  ‚úì Scheduler: CosineAnnealingWarmRestarts (better than OneCycleLR for overfitting)\n",
      "  ‚úì Dropout: 0.5 (already in model)\n",
      "  ‚úì Class-balanced loss with weights\n",
      "  ‚úì Mixed Precision: DISABLED (for stability)\n",
      "\n",
      "‚úì SIMPLIFIED & ROBUST training functions defined successfully\n",
      "  ‚Ä¢ NO GradScaler errors (mixed precision disabled)\n",
      "  ‚Ä¢ Gradient clipping (max_norm=1.0) - ALWAYS works\n",
      "  ‚Ä¢ CosineAnnealingWarmRestarts scheduler\n",
      "  ‚Ä¢ Class-balanced loss with label smoothing (0.15)\n",
      "  ‚Ä¢ Lower LR (0.0005) + Higher weight decay (0.02)\n",
      "  ‚Ä¢ Non-blocking data transfer\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# TRAINING CONFIGURATION - OPTIMIZED FOR HIGH ACCURACY & ANTI-OVERFITTING\n",
    "# ============================================\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Compute class weights for imbalanced data\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "\n",
    "print(\"üìä Class Distribution:\")\n",
    "for i, (label, weight) in enumerate(zip(idx_to_label.values(), class_weights)):\n",
    "    count = np.sum(y_train == i)\n",
    "    print(f\"  Class {i} ({label}): {count} samples, weight={weight:.3f}\")\n",
    "\n",
    "# Loss function v·ªõi class weights v√† label smoothing\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    weight=class_weights_tensor, \n",
    "    label_smoothing=0.1  # Label smoothing to prevent overconfidence\n",
    ")\n",
    "\n",
    "# Optimizer: AdamW v·ªõi weight decay\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=0.001,              # Initial learning rate\n",
    "    weight_decay=0.01,     # Weight decay for L2 regularization\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# Learning rate scheduler: ReduceLROnPlateau\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',           # Maximize validation accuracy\n",
    "    factor=0.5,           # Reduce LR by half\n",
    "    patience=5,           # Wait 5 epochs before reducing\n",
    "    verbose=True,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "print(\"\\n‚öôÔ∏è  TRAINING CONFIGURATION:\")\n",
    "print(f\"  Loss: CrossEntropyLoss (class-weighted, label_smoothing=0.1)\")\n",
    "print(f\"  Optimizer: AdamW (lr=0.001, weight_decay=0.01)\")\n",
    "print(f\"  Scheduler: ReduceLROnPlateau (factor=0.5, patience=5)\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Gradient clipping: 1.0\")\n",
    "print(f\"\\nüõ°Ô∏è  ANTI-OVERFITTING STRATEGIES:\")\n",
    "print(f\"  ‚úÖ Dropout: 0.5-0.6 in model\")\n",
    "print(f\"  ‚úÖ Weight Decay: 0.01\")\n",
    "print(f\"  ‚úÖ Label Smoothing: 0.1\")\n",
    "print(f\"  ‚úÖ SpecAugment: Time & Freq masking\")\n",
    "print(f\"  ‚úÖ Class-balanced loss\")\n",
    "print(f\"  ‚úÖ Early stopping (patience=10)\")\n",
    "print(f\"  ‚úÖ Gradient clipping\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# TRAINING & VALIDATION FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, augmentation=None):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    train_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    for inputs, targets in train_bar:\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "        \n",
    "        # Apply augmentation\n",
    "        if augmentation is not None:\n",
    "            inputs = augmentation(inputs)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass v·ªõi gradient clipping\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        train_bar.set_postfix({\n",
    "            'Loss': f'{running_loss/(train_bar.n+1):.3f}',\n",
    "            'Acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
    "        for inputs, targets in val_bar:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Statistics\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            # Save for metrics\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            val_bar.set_postfix({\n",
    "                'Loss': f'{val_loss/(val_bar.n+1):.3f}',\n",
    "                'Acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = val_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc, all_preds, all_targets\n",
    "\n",
    "print(\"\\n‚úÖ Training functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daa9ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì OPTIMIZED training loop function defined successfully\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# TRAINING LOOP v·ªõi Early Stopping\n",
    "# ============================================\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler,\n",
    "                num_epochs=80, early_stopping_patience=10, \n",
    "                save_path='best_crcnn_cough.pth'):\n",
    "    \"\"\"\n",
    "    Complete training loop v·ªõi monitoring v√† early stopping\n",
    "    \"\"\"\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'learning_rates': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéì STARTING TRAINING\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Total epochs: {num_epochs}\")\n",
    "    print(f\"Early stopping patience: {early_stopping_patience}\")\n",
    "    print(f\"Model checkpoints will be saved to: {save_path}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = datetime.now()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Training phase\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, \n",
    "            augmentation=augmentation\n",
    "        )\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss, val_acc, val_preds, val_targets = validate_epoch(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_acc)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['learning_rates'].append(current_lr)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        epoch_time = (datetime.now() - epoch_start_time).total_seconds()\n",
    "        train_val_gap = train_acc - val_acc\n",
    "        \n",
    "        print(f\"\\nüìä Results:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "        print(f\"  Train-Val Gap: {train_val_gap:+.2f}%\")\n",
    "        print(f\"  Learning Rate: {current_lr:.2e}\")\n",
    "        print(f\"  Epoch Time: {epoch_time:.1f}s\")\n",
    "        \n",
    "        # Check for overfitting warning\n",
    "        if train_val_gap > 10:\n",
    "            print(f\"  ‚ö†Ô∏è  Warning: Possible overfitting (gap > 10%)\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            improvement = val_acc - best_val_acc\n",
    "            best_val_acc = val_acc\n",
    "            \n",
    "            # Save checkpoint\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'history': history,\n",
    "                'class_names': list(idx_to_label.values())\n",
    "            }\n",
    "            torch.save(checkpoint, save_path)\n",
    "            \n",
    "            print(f\"  ‚úÖ New best model saved! (+{improvement:.2f}% improvement)\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  No improvement ({patience_counter}/{early_stopping_patience})\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"‚èπÔ∏è  Early stopping triggered!\")\n",
    "            print(f\"   Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "            print(f\"   Stopping at epoch {epoch+1}\")\n",
    "            print(\"=\"*80)\n",
    "            break\n",
    "        \n",
    "        print(\"\")  # Empty line for readability\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ TRAINING COMPLETED!\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"Total epochs trained: {len(history['train_loss'])}\")\n",
    "    print(f\"Model saved to: {save_path}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return history, best_val_acc\n",
    "\n",
    "print(\"‚úÖ Training loop function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0649bc6d",
   "metadata": {},
   "source": [
    "## üöÄ Start Training\n",
    "\n",
    "B√¢y gi·ªù ch√∫ng ta s·∫Ω b·∫Øt ƒë·∫ßu train model v·ªõi t·∫•t c·∫£ c√°c optimization ƒë√£ setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34aa752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# START TRAINING\n",
    "# ============================================\n",
    "\n",
    "# Training hyperparameters\n",
    "NUM_EPOCHS = 80\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "MODEL_SAVE_PATH = 'best_crcnn_cough_model.pth'\n",
    "\n",
    "# Start training\n",
    "history, best_val_acc = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "    save_path=MODEL_SAVE_PATH\n",
    ")\n",
    "\n",
    "print(f\"\\nüéâ Training finished!\")\n",
    "print(f\"üìà Best validation accuracy achieved: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556c31e5",
   "metadata": {},
   "source": [
    "## üìä Visualize Training History\n",
    "\n",
    "Visualize training v√† validation metrics ƒë·ªÉ ki·ªÉm tra overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d5779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# VISUALIZE TRAINING HISTORY\n",
    "# ============================================\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0, 0].plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "    axes[0, 0].plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[0, 0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].legend(fontsize=11)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    axes[0, 1].plot(epochs, history['train_acc'], 'b-', label='Train Acc', linewidth=2)\n",
    "    axes[0, 1].plot(epochs, history['val_acc'], 'r-', label='Val Acc', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    axes[0, 1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].legend(fontsize=11)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning rate plot\n",
    "    axes[1, 0].plot(epochs, history['learning_rates'], 'g-', linewidth=2)\n",
    "    axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('Learning Rate', fontsize=12)\n",
    "    axes[1, 0].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_yscale('log')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Train-Val gap (overfitting indicator)\n",
    "    gap = [t - v for t, v in zip(history['train_acc'], history['val_acc'])]\n",
    "    axes[1, 1].plot(epochs, gap, 'purple', linewidth=2)\n",
    "    axes[1, 1].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "    axes[1, 1].axhline(y=10, color='r', linestyle='--', alpha=0.3, label='Overfitting threshold')\n",
    "    axes[1, 1].fill_between(epochs, 0, gap, alpha=0.3, color='purple')\n",
    "    axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Train - Val Accuracy (%)', fontsize=12)\n",
    "    axes[1, 1].set_title('Overfitting Indicator (Train-Val Gap)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].legend(fontsize=11)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä TRAINING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total epochs: {len(epochs)}\")\n",
    "    print(f\"Best train accuracy: {max(history['train_acc']):.2f}%\")\n",
    "    print(f\"Best validation accuracy: {max(history['val_acc']):.2f}%\")\n",
    "    print(f\"Final train-val gap: {gap[-1]:.2f}%\")\n",
    "    print(f\"Average train-val gap: {np.mean(gap):.2f}%\")\n",
    "    \n",
    "    if max(gap) > 10:\n",
    "        print(f\"\\n‚ö†Ô∏è  Warning: Max train-val gap was {max(gap):.2f}% (overfitting detected)\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ Model shows good generalization (max gap: {max(gap):.2f}%)\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Plot the history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3e0b73",
   "metadata": {},
   "source": [
    "## üß™ Evaluate on Test Set\n",
    "\n",
    "Load best model v√† evaluate tr√™n test set ƒë·ªÉ c√≥ k·∫øt qu·∫£ cu·ªëi c√πng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22107125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EVALUATE ON TEST SET\n",
    "# ============================================\n",
    "\n",
    "def evaluate_model(model, test_loader, device, model_path=None):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    \n",
    "    # Load best model if path provided\n",
    "    if model_path and os.path.exists(model_path):\n",
    "        print(f\"Loading best model from {model_path}...\")\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"‚úÖ Model loaded (Best val acc: {checkpoint['best_val_acc']:.2f}%)\\n\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "    \n",
    "    print(\"Evaluating on test set...\")\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc=\"Testing\"):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_acc = accuracy_score(all_targets, all_preds) * 100\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéØ TEST SET RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"üìã Classification Report:\")\n",
    "    print(\"-\" * 60)\n",
    "    class_names = list(idx_to_label.values())\n",
    "    report = classification_report(all_targets, all_preds, \n",
    "                                   target_names=class_names,\n",
    "                                   digits=4)\n",
    "    print(report)\n",
    "    \n",
    "    return all_preds, all_targets, all_probs, test_acc\n",
    "\n",
    "# Evaluate\n",
    "test_preds, test_targets, test_probs, test_accuracy = evaluate_model(\n",
    "    model, test_loader, device, model_path=MODEL_SAVE_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adb90d6",
   "metadata": {},
   "source": [
    "## üìà Confusion Matrix v√† Detailed Metrics\n",
    "\n",
    "Visualize confusion matrix v√† per-class metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0133f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFUSION MATRIX & VISUALIZATION\n",
    "# ============================================\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Confusion matrix (counts)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'}, ax=axes[0], \n",
    "                annot_kws={'size': 12})\n",
    "    axes[0].set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Confusion matrix (normalized)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Greens',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Percentage'}, ax=axes[1],\n",
    "                annot_kws={'size': 12})\n",
    "    axes[1].set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print per-class accuracy\n",
    "    print(\"\\nüìä Per-Class Accuracy:\")\n",
    "    print(\"-\" * 50)\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_acc = cm[i, i] / cm[i].sum() * 100\n",
    "        print(f\"  {class_name:20s}: {class_acc:6.2f}% ({cm[i, i]}/{cm[i].sum()})\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Plot confusion matrix\n",
    "class_names = list(idx_to_label.values())\n",
    "plot_confusion_matrix(test_targets, test_preds, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e2310",
   "metadata": {},
   "source": [
    "## üíæ Model Summary\n",
    "\n",
    "T·ªïng k·∫øt th√¥ng tin v·ªÅ model ƒë√£ train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6521fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FINAL MODEL SUMMARY\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ MODEL TRAINING & EVALUATION COMPLETED!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Model info\n",
    "model_info = model.get_model_size()\n",
    "print(f\"\\nüì¶ Model Architecture: ImprovedCRCNN\")\n",
    "print(f\"   ‚Ä¢ Total parameters: {model_info['total_params']:,}\")\n",
    "print(f\"   ‚Ä¢ Trainable parameters: {model_info['trainable_params']:,}\")\n",
    "print(f\"   ‚Ä¢ Model size: {model_info['size_mb']:.2f} MB\")\n",
    "\n",
    "print(f\"\\nüèóÔ∏è  Architecture Components:\")\n",
    "print(f\"   ‚Ä¢ Conv blocks: [64, 128, 256] channels with residual connections\")\n",
    "print(f\"   ‚Ä¢ Bidirectional GRU: 2 layers, hidden_size=256\")\n",
    "print(f\"   ‚Ä¢ Multi-head attention: 4 heads\")\n",
    "print(f\"   ‚Ä¢ Classifier: 512 ‚Üí 256 ‚Üí {num_classes} classes\")\n",
    "\n",
    "print(f\"\\nüõ°Ô∏è  Anti-Overfitting Techniques:\")\n",
    "print(f\"   ‚úÖ Dropout: 0.5-0.6\")\n",
    "print(f\"   ‚úÖ SpecAugment: Time & Frequency masking\")\n",
    "print(f\"   ‚úÖ Label Smoothing: 0.1\")\n",
    "print(f\"   ‚úÖ Weight Decay: 0.01 (AdamW)\")\n",
    "print(f\"   ‚úÖ Batch Normalization + Layer Normalization\")\n",
    "print(f\"   ‚úÖ Gradient Clipping: 1.0\")\n",
    "print(f\"   ‚úÖ Class-balanced loss\")\n",
    "print(f\"   ‚úÖ Early Stopping: patience=10\")\n",
    "\n",
    "print(f\"\\nüìä Performance:\")\n",
    "print(f\"   ‚Ä¢ Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Total epochs trained: {len(history['train_loss'])}\")\n",
    "\n",
    "print(f\"\\nüíæ Saved Files:\")\n",
    "print(f\"   ‚Ä¢ Model checkpoint: {MODEL_SAVE_PATH}\")\n",
    "print(f\"   ‚Ä¢ Training history plot: training_history.png\")\n",
    "print(f\"   ‚Ä¢ Confusion matrix: confusion_matrix.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ All done! Model is ready for deployment.\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580b5dd4",
   "metadata": {},
   "source": [
    "## üöÄ How to Use This Model for Inference\n",
    "\n",
    "ƒê·ªÉ s·ª≠ d·ª•ng model n√†y cho inference tr√™n audio m·ªõi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9960ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# INFERENCE FUNCTION\n",
    "# ============================================\n",
    "\n",
    "def predict_cough(audio_spectrogram, model, device, class_names):\n",
    "    \"\"\"\n",
    "    Predict cough type from audio spectrogram\n",
    "    \n",
    "    Args:\n",
    "        audio_spectrogram: numpy array of shape (height, width) or (1, height, width)\n",
    "        model: trained CRCNN model\n",
    "        device: torch device\n",
    "        class_names: list of class names\n",
    "        \n",
    "    Returns:\n",
    "        predicted_class: predicted class name\n",
    "        probabilities: dict of class probabilities\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Prepare input\n",
    "    if len(audio_spectrogram.shape) == 2:\n",
    "        audio_spectrogram = audio_spectrogram[np.newaxis, np.newaxis, :, :]  # Add batch and channel dims\n",
    "    elif len(audio_spectrogram.shape) == 3:\n",
    "        audio_spectrogram = audio_spectrogram[np.newaxis, :, :, :]  # Add batch dim\n",
    "    \n",
    "    # Convert to tensor\n",
    "    input_tensor = torch.FloatTensor(audio_spectrogram).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        predicted_idx = torch.argmax(probs, dim=1).item()\n",
    "        \n",
    "    # Get results\n",
    "    predicted_class = class_names[predicted_idx]\n",
    "    probabilities = {class_names[i]: probs[0, i].item() for i in range(len(class_names))}\n",
    "    \n",
    "    return predicted_class, probabilities\n",
    "\n",
    "\n",
    "# Example usage\n",
    "print(\"=\"*60)\n",
    "print(\"üîÆ INFERENCE EXAMPLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Test with a random sample from test set\n",
    "sample_idx = np.random.randint(0, len(X_test_tensor))\n",
    "sample_spectrogram = X_test_tensor[sample_idx].cpu().numpy()\n",
    "true_label = idx_to_label[y_test_tensor[sample_idx].item()]\n",
    "\n",
    "# Predict\n",
    "predicted_class, probabilities = predict_cough(\n",
    "    sample_spectrogram, model, device, list(idx_to_label.values())\n",
    ")\n",
    "\n",
    "print(f\"\\nSample #{sample_idx}\")\n",
    "print(f\"True label: {true_label}\")\n",
    "print(f\"Predicted: {predicted_class}\")\n",
    "print(f\"\\nProbabilities:\")\n",
    "for class_name, prob in sorted(probabilities.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {class_name:20s}: {prob*100:6.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Inference function ready to use!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e036a58",
   "metadata": {},
   "source": [
    "## üìù Key Takeaways & Best Practices\n",
    "\n",
    "### üéØ ƒêi·ªÉm m·∫°nh c·ªßa CRCNN model n√†y:\n",
    "\n",
    "1. **Ki·∫øn tr√∫c Hybrid**: K·∫øt h·ª£p CNN (spatial features) + GRU (temporal features) + Attention\n",
    "2. **Residual Connections**: Gi√∫p training s√¢u h∆°n, gradient flow t·ªët h∆°n\n",
    "3. **Multi-head Attention**: Focus v√†o c√°c ph·∫ßn quan tr·ªçng c·ªßa audio\n",
    "4. **Strong Regularization**: Dropout cao, Weight Decay, Label Smoothing\n",
    "\n",
    "### üõ°Ô∏è C√°c k·ªπ thu·∫≠t ch·ªëng overfitting ƒë√£ √°p d·ª•ng:\n",
    "\n",
    "- ‚úÖ **Dropout 0.5-0.6** ·ªü nhi·ªÅu layers\n",
    "- ‚úÖ **SpecAugment** cho audio augmentation\n",
    "- ‚úÖ **Label Smoothing 0.1** ƒë·ªÉ tr√°nh overconfidence\n",
    "- ‚úÖ **Weight Decay 0.01** trong AdamW optimizer\n",
    "- ‚úÖ **Early Stopping** v·ªõi patience=10\n",
    "- ‚úÖ **Gradient Clipping** ƒë·ªÉ ·ªïn ƒë·ªãnh training\n",
    "- ‚úÖ **Class-balanced loss** cho imbalanced data\n",
    "- ‚úÖ **Batch + Layer Normalization** k·∫øt h·ª£p\n",
    "\n",
    "### üìä Expected Performance:\n",
    "\n",
    "- **Training Accuracy**: 85-95%\n",
    "- **Validation Accuracy**: 80-90%\n",
    "- **Test Accuracy**: 80-90%\n",
    "- **Train-Val Gap**: < 10% (good generalization)\n",
    "\n",
    "### üí° Tips ƒë·ªÉ c·∫£i thi·ªán th√™m:\n",
    "\n",
    "1. **Thu th·∫≠p th√™m data**: C√†ng nhi·ªÅu data, model c√†ng t·ªët\n",
    "2. **Data augmentation**: Th√™m pitch shifting, time stretching\n",
    "3. **Ensemble models**: K·∫øt h·ª£p nhi·ªÅu models kh√°c nhau\n",
    "4. **Hyperparameter tuning**: Grid search cho best params\n",
    "5. **Transfer learning**: Pre-train tr√™n dataset l·ªõn h∆°n\n",
    "\n",
    "### üöÄ Production Deployment:\n",
    "\n",
    "```python\n",
    "# 1. Save model cho production\n",
    "torch.save(model.state_dict(), 'crcnn_cough_production.pth')\n",
    "\n",
    "# 2. Load v√† inference\n",
    "model = ImprovedCRCNN(...)\n",
    "model.load_state_dict(torch.load('crcnn_cough_production.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 3. Convert sang ONNX cho faster inference (optional)\n",
    "# torch.onnx.export(model, dummy_input, 'crcnn_cough.onnx')\n",
    "```\n",
    "\n",
    "---\n",
    "**Created by**: CRCNN Optimization Team  \n",
    "**Last Updated**: 2024  \n",
    "**License**: MIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "root",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
